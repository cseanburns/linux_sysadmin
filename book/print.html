<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Linux Systems Administration</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="Entry level book on Linux systems administration.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Linux Systems Administration</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/cseanburns/linux_sysadmin" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="linux-systems-administration"><a class="header" href="#linux-systems-administration">Linux Systems Administration</a></h1>
<p>Author: C. Sean Burns<br />
Date: 2024-08-23<br />
Email: <a href="sean.burns@uky.edu">sean.burns@uky.edu</a><br />
Website: <a href="https://cseanburns.net">cseanburns.net</a><br />
GitHub: <a href="https://github.com/cseanburns">@cseanburns</a></p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>This book was written for my Linux Systems Administration course.
The book and course's goals are to provide students with the skills to use Linux for systems administration, and to teach students:</p>
<ol>
<li>how to use the command line in order to become more efficient computer users and more comfortable with using computers in general;</li>
<li>how to use command line utilities and programs and to learn what can be accomplished using those programs;</li>
<li>how to administer users and manage software on a Linux server;</li>
<li>how to secure a Linux server; and</li>
<li>the basics of cloud computing;</li>
</ol>
<p>And finally, this book/course ends on walking students through the process of building a <a href="https://en.wikipedia.org/wiki/LAMP_(software_bundle)">LAMP stack</a>.</p>
<h2 id="how-to-use-this-book"><a class="header" href="#how-to-use-this-book">How to Use this Book</a></h2>
<h3 id="text-and-video"><a class="header" href="#text-and-video">Text and Video</a></h3>
<p>All sections of this book will be accompanied by a video demonstrating the practices described in those sections.
Your are <strong>highly encouraged</strong> to <strong>read through the text first</strong> and <strong>then watch the video</strong>.
Revisit the text to help cement the ideas in place and to work through tasks.</p>
<h3 id="markup"><a class="header" href="#markup">Markup</a></h3>
<p>There are two markup styles that I want to bring to your attention:</p>
<h4 id="code-blocks"><a class="header" href="#code-blocks">Code Blocks</a></h4>
<p>Text that looks like <strong>code blocks</strong> indicate some kind of command or series of commands.
Do not simply copy and paste these commands into your terminal.
You can cause errors if you copy and paste multiple lines of code into your terminal.
Rather, you should type these commands out.
For example, you might copy and paste the following command and be okay in doing so:</p>
<pre><code>ls ~
</code></pre>
<p>But copying and pasting multiple lines can cause problems.
Here's an example of a series of commands in a code block that can cause problems if you copy and paste them into your terminal:</p>
<pre><code>cd /important/directory
rm -rf *
echo "All files in /important/directory have been deleted."
</code></pre>
<p>In the above example,
a mistake in copying and/or pasting the <code>cd /important/directory</code> command will result in the deletion of other directories and their files.
It's therefore important to <strong>understand before executing</strong> some code.
Typing out the code and seeing the results printed to the terminal will help foster that understanding.</p>
<h4 id="asides"><a class="header" href="#asides">Asides</a></h4>
<p>I occasionally insert <strong>asides</strong> into the text.
These asides generally contain notes or extra comments about the main content.
Asides look like this:</p>
<blockquote>
<p>This is an aside.
Asides will contain extra information, notes, or comments.</p>
</blockquote>
<h3 id="theme"><a class="header" href="#theme">Theme</a></h3>
<p>At the top of the page is an icon of a paint brush.
The default theme is darker text on a light background, but you can change the theme per your preferences.</p>
<h3 id="search"><a class="header" href="#search">Search</a></h3>
<p>Next to the paintbrush is an icon of a magnifying glass.
Use this to search this work.</p>
<h3 id="printing"><a class="header" href="#printing">Printing</a></h3>
<p>I intend this book to be a live document, and therefore it'll be regularly updated.
But feel free to print it, if you want.
You can use the print function to save the entire book as a PDF file.
See the printer icon at the top right of the screen to get started.</p>
<h2 id="about-this-book"><a class="header" href="#about-this-book">About This Book</a></h2>
<p>This book works as a live document since I use it for my fall semester Linux Systems Administration course.
I will update the content as I teach it in order to address changes in the technology and to edit for clarity.</p>
<p>This book is not a comprehensive introduction to the Linux operating system nor to systems administration.
It is designed for an entry level course on these topics.
It is focused on a select and small range of those topics that have the specific pedagogical aims described above.</p>
<p>The content in this book is open access and licensed under the <a href="https://github.com/cseanburns/linux_sysadmin/blob/master/LICENSE">GNU GPL v3.0</a>.
Feel free to fork this work on <a href="https://github.com/cseanburns/linux_sysadmin">GitHub</a> and modify it for your own needs.</p>
<p>I use <a href="https://github.com/rust-lang/mdBook">mdBook</a> to build <a href="https://www.markdownguide.org/">markdown</a> source files into this final output.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="history-of-unix-and-linux"><a class="header" href="#history-of-unix-and-linux">History of Unix and Linux</a></h1>
<p>An outline of the history of Unix and Linux.</p>
<h2 id="location-bell-labs-part-of-att-new-jersey-late-1960s-through-early-1970s"><a class="header" href="#location-bell-labs-part-of-att-new-jersey-late-1960s-through-early-1970s">Location: Bell Labs, part of AT&amp;T (New Jersey), late 1960s through early 1970s</a></h2>
<p>In the late 1960s through the early 1970s at Bell Labs,
part of AT&amp;T in New Jersey,
the journey began with an operating system called Multics.
Multics was a pioneering time-sharing system,
allowing more than one person to use it at once.
Despite its innovative approach,
Multics was fraught with issues and was slowly abandoned.
In the midst of this abandonment,
<a href="http://cs.bell-labs.co/who/ken/">Ken Thompson</a>
stumbled upon an old PDP-7 and started
writing what would become UNIX.
During this time,
he created the <a href="https://en.wikipedia.org/wiki/Ed_(text_editor)">ed</a> line editor,
pronounced e.d.,
but generally sounded out.
This specific version of UNIX would
later be known as Research Unix.
The project caught the attention of
<a href="https://www.bell-labs.com/usr/dmr/www/">Dennis Ritchie</a>,
the creator of the C programming language,
who joined Thompson's efforts, and
together they laid the groundwork for
a revolution in computing.</p>
<h2 id="location-berkeley-ca-university-of-california-berkeley-early-to-mid-1970s"><a class="header" href="#location-berkeley-ca-university-of-california-berkeley-early-to-mid-1970s">Location: Berkeley, CA (University of California, Berkeley), early to mid 1970s</a></h2>
<p>In the early to mid-1970s at the
University of California, Berkeley,
the evolution of UNIX continued.
While not classified as 'free software,'
UNIX's code was low-cost and easily shared among
tech enthusiasts.
Ken Thompson visited Berkeley,
where he helped install Version 6 of <a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">UNIX</a>,
marking a significant moment in the system's history.
At Berkeley, several contributors,
including <a href="https://en.wikipedia.org/wiki/Bill_Joy">Bill Joy</a>,
played vital roles in its development.
Joy was particularly influential,
creating the <a href="https://sites.google.com/a/bostic.com/keithbostic/vi/">vi</a> text editor,
a descendant of the popular <a href="https://www.vim.org/">Vim</a> editor,
and many other essential programs.
He also co-founded Sun Microsystems.
This installation and collaborative effort at
Berkeley eventually led to the creation of the
Berkeley Software Distribution, or <a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">BSD</a>,
a landmark in the history of UNIX
and computing as a whole.</p>
<h2 id="att"><a class="header" href="#att">AT&amp;T</a></h2>
<p>Until its breakup in 1984,
AT&amp;T operated under a unique agreement with the
U.S. government that restricted the company from
profiting off patents not directly related
to its telecommunications businesses.
This arrangement helped shield AT&amp;T from
monopolistic charges,
but it also came with a significant limitation:
they could not commercialize UNIX.
The landscape changed dramatically after the
breakup of AT&amp;T.
The constraints lifted,
allowing System V UNIX to emerge as
the standard bearer of commercial UNIX.
This transition marked a turning point
in the history of computing,
positioning UNIX as a central player
in the commercial technology market.</p>
<h2 id="location-boston-ma-mit-early-1980s-through-early-1990s"><a class="header" href="#location-boston-ma-mit-early-1980s-through-early-1990s">Location: Boston, MA (MIT), early 1980s through early 1990s</a></h2>
<p>In Boston, MA, at MIT during the early 1980s
through the early 1990s,
a significant shift in the software industry
was taking place.
In the late 1970s,
<a href="https://en.wikipedia.org/wiki/Richard_Stallman">Richard Stallman</a> observed the growing
trend of software becoming commercialized.
This commercialization led to hardware vendors
ceasing to share the code they developed
to make their hardware work.
This paradigm change was further solidified by the
Copyright Act of 1976,
making software code eligible for copyright protection.
Stallman, who thrived in a hacker culture,
began to battle against this new direction.
He responded by creating the <a href="https://www.gnu.org/gnu/gnu.html">GNU project</a>,
embracing the free software philosophy,
and developing influential tools such as GNU Emacs,
a popular text editor,
and many other programs.
The GNU project was an ambitious attempt
to create a completely free software operating
system that was Unix-like,
called GNU.
By the early 1990s,
Stallman and others had developed all
the utilities needed for a full operating system,
except for a kernel,
which they named <a href="https://www.gnu.org/software/hurd/">GNU Hurd</a>.
This encompassing project included
the creation of the Bash shell,
written by <a href="https://opuslogica.com/">Brian Fox</a>,
reflecting a profound commitment
to free and open software.</p>
<p>The GNU philosophy includes several
propositions that define free software:</p>
<blockquote>
<p>The four freedoms, per GNU Project:
0. The freedom to run the program as you wish,
for any purpose (freedom 0).</p>
<ol>
<li>The freedom to study how the program works,
and change it so it does your computing as you wish (freedom 1).
Access to the source code is a precondition for this.</li>
<li>The freedom to redistribute copies so you can help others (freedom 2).</li>
<li>The freedom to distribute copies of your modified
versions to others (freedom 3).
By doing this you can give the whole community a chance
to benefit from your changes.
Access to the source code is a precondition for this.</li>
</ol>
</blockquote>
<p><a href="https://www.gnu.org/philosophy/free-sw.html">The Four Freedoms</a></p>
<h2 id="the-unix-wars-and-the-lawsuit-late-1980s-through-the-early-1990s"><a class="header" href="#the-unix-wars-and-the-lawsuit-late-1980s-through-the-early-1990s">The Unix wars and the lawsuit, late 1980s through the early 1990s</a></h2>
<p>During the late 1980s through the early 1990s,
the so-called "Unix wars" and an
ensuing lawsuit marked a contentious period
in the history of computing.
Following its breakup,
AT&amp;T began to commercialize Unix,
leading to distinct differences between
AT&amp;T Unix and BSD Unix.
The former was aimed at commercial markets,
while the latter was targeted at
researchers and academics.
These contrasting objectives led to legal friction,
culminating in UNIX Systems Laboratories, Inc.
(USL, part of AT&amp;T) suing
Berkeley Software Design, Inc.
(BSDi, part of the University of California, Berkeley)
for copyright and trademark violations.
Ultimately, USL lost the case,
but not before the lawsuit had created significant
obstacles for BSD Unix.
The legal battle delayed the adoption of BSD Unix,
leaving a lasting impact on the
development and dissemination of Unix systems.</p>
<h2 id="linux-linus-torvalds-university-of-helsinki-finland-early-1990s"><a class="header" href="#linux-linus-torvalds-university-of-helsinki-finland-early-1990s">Linux, Linus Torvalds, University of Helsinki, Finland, early 1990s</a></h2>
<p>In the early 1990s at the University of Helsinki
in Finland,
a significant development in the
world of computing unfolded.
On August 25, 1991,
<a href="https://www.cs.helsinki.fi/u/torvalds/">Linus Torvalds</a> announced that he had
started working on a free operating system kernel
specifically for the 386 CPU architecture and
his hardware.
This <a href="https://www.kernel.org/">kernel</a> would later be famously named Linux.
It's essential to understand that Linux
technically refers only to the kernel,
which handles startup, devices,
memory, resources, and more,
but does not provide user land
utilities—the kind of software
that people use on their computers.</p>
<p>Torvalds' motivation for this project was
both to learn about OS development and
to have access to a Unix-like system.
He already had access to an Unix-like
system called <a href="https://www.minix3.org/">MINIX</a>,
but MINIX was limited by technical and
copyright restrictions.
Interestingly, Torvalds has stated that if a
BSD or GNU Hurd operating system were
available at that time,
he might not have created the Linux kernel at all.
However, he and others took the
GNU utilities and created what is
now widely referred to as Linux or GNU/Linux.
This amalgamation of Torvalds' kernel and
GNU utilities marked a critical point
in the evolution of free and open-source software,
fostering a global community of developers and users.</p>
<h2 id="distributions-early-1990s-through-today"><a class="header" href="#distributions-early-1990s-through-today">Distributions, early 1990s through today</a></h2>
<p>Soon after the development of Linux in the early 1990s,
a trend began to emerge that continues to this day.
Enthusiasts and developers started creating
their own Linux and GNU-based operating systems,
customizing them to suit various needs and preferences.
They would then distribute these customized
versions to others,
sharing their innovations and insights with a
wider community.
As a result of this practice,
these Linux operating systems became
known as "distributions."
This phenomenon has led to a rich ecosystem of
Linux distributions,
catering to different user bases,
industries, and interests, and
has played a central role in the
continued growth and
diversification of open-source computing.</p>
<p>The two oldest distributions that are still in
active development include:</p>
<ul>
<li><a href="http://www.slackware.com/">Slackware</a></li>
<li><a href="https://www.debian.org/">Debian</a></li>
</ul>
<h2 id="short-history-of-bsd-1970s-through-today"><a class="header" href="#short-history-of-bsd-1970s-through-today">Short History of BSD, 1970s through today</a></h2>
<p>The history of Berkeley Software Distribution (BSD)
spans from the 1970s to today and is closely
intertwined with the evolution of Unix.
Early Unix version numbers 1-6
eventually led to the development of BSD versions 1-4.
By the time of BSD 4.3,
all versions still contained some AT&amp;T code.
A desire to remove this proprietary code led to the
creation of BSD Net/1.</p>
<p>The effort continued until all AT&amp;T
code was successfully removed by BSD Net/2.
This version was then ported to the Intel 386
processor, resulting in 386BSD,
made available in 1992,
a year after the Linux kernel was released.</p>
<p>386BSD eventually split into two distinct projects:
<a href="https://www.netbsd.org/">NetBSD</a> and <a href="https://www.freebsd.org/">FreeBSD</a>.
Later, NetBSD itself split into another project,
giving rise to <a href="https://www.openbsd.org/">OpenBSD</a>.
All three of these BSDs are still in
active development today,
and each has a unique focus:</p>
<ul>
<li><strong>NetBSD</strong> is known for its focus on portability, finding
applications in various environments such as MacOS and even
NASA projects.</li>
<li><strong>FreeBSD</strong> is recognized for its wide applicability and has
been utilized by notable companies and products like WhatsApp,
Netflix, PlayStation 4, and MacOS.</li>
<li><strong>OpenBSD</strong> emphasizes security and has contributed several
essential applications in this domain.</li>
</ul>
<p>This intricate journey of BSD,
marked by splits, adaptations, and varied focuses,
has cemented its place in the history of
operating systems,
allowing it to cater to a wide range of
applications and audiences.</p>
<blockquote>
<p>MacOS is based on <a href="http://www.puredarwin.org/">Darwin</a>,
is <a href="https://www.opengroup.org/membership/forums/platform/unix">technically UNIX</a>, and is
partly based on FreeBSD with some code
coming from the other BSDs.
See <a href="https://apple.stackexchange.com/questions/401832/why-is-macos-often-referred-to-as-darwin">Why is macOS often referred to as 'Darwin'?</a>
for a short history.</p>
</blockquote>
<h2 id="short-history-of-gnu-1980s-through-today"><a class="header" href="#short-history-of-gnu-1980s-through-today">Short History of GNU, 1980s through today</a></h2>
<p>The history of GNU,
particularly the GNU Hurd kernel,
traces back to the 1980s and continues to evolve today.
The GNU Hurd, despite its long development process,
remains in a pre-production state.
The latest release of this kernel was version 0.9,
which came out in December 2016.
Even though it has not yet reached full maturity,
a complete operating system based on the GNU Hurd
can be downloaded and run.
For example,
<a href="https://www.debian.org/ports/hurd/">Debian GNU/Hurd</a>
represents one such implementation.
This ongoing work on the GNU Hurd exemplifies
the free and open-source community's
commitment to innovation and collaboration,
maintaining a spirit of exploration that has
driven the software landscape for decades.</p>
<h2 id="free-and-open-source-licenses"><a class="header" href="#free-and-open-source-licenses">Free and Open Source Licenses</a></h2>
<p>In the free software and open source landscape,
there are several important free and/or open source
licenses that are used.
The two biggest software licenses are
based on the software used by GNU/Linux
and the software based on the BSDs.
They each take very different approaches to free
and/or open source software.
The biggest difference is this:</p>
<ul>
<li>Software based on software licensed under the GPL
must also be licensed under the GPL.
This is referred to as <a href="https://www.gnu.org/licenses/copyleft.en.html">copyleft</a> software,
and the idea is to propagate free software.
<ul>
<li><a href="https://www.gnu.org/licenses/gpl-3.0.en.html">GNU General Public License (GPL)</a></li>
</ul>
</li>
<li>Software based on software licensed under the BSD
license may be closed source and
primarily must only attribute the original source code and author.
<ul>
<li><a href="https://opensource.org/licenses/BSD-3-Clause">BSD License</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-linux"><a class="header" href="#what-is-linux">What is Linux?</a></h1>
<h2 id="the-linux-kernel"><a class="header" href="#the-linux-kernel">The Linux Kernel</a></h2>
<p>Technically, <a href="https://kernel.org/">Linux is a kernel</a>, and
a kernel is a part of an operating system that
oversees CPU activity like multitasking, as well as networking,
memory management, device management, file systems, and more.
The kernel alone does not make an operating system.
It needs user land applications and programs,
the kind we use on a daily basis, to form a whole,
as well as ways for these user land utilities to
interact with the kernel.</p>
<h2 id="linux-and-gnu"><a class="header" href="#linux-and-gnu">Linux and GNU</a></h2>
<p>The earliest versions of the Linux kernel were combined
with tools, utilities, and programs from the <a href="https://www.gnu.org/software/software.html">GNU project</a>
to form a complete operating system,
without necessarily a graphical user interface.
This association continues to this day.
Additional non-GNU, but
free and open source programs under different licenses,
have been added to form a more functional and user friendly system.
However, since the Linux kernel needs user land applications
to form an operating system, and
since user land applications from GNU cannot work without a kernel,
some argue that the operating system
should be called <a href="https://en.wikipedia.org/wiki/GNU/Linux_naming_controversy">GNU/Linux</a>
and not just Linux.
This has not gained wide acceptance, though.
Regardless, credit is due to both camps for their contribution,
as well as many others who have made substantial contributions
to the operating system.</p>
<h2 id="linux-uses"><a class="header" href="#linux-uses">Linux Uses</a></h2>
<p>We are using Linux as a server in this course, which
means we will use Linux to provide various services.
Our first focus is to learn to use Linux itself, but
by the end of the course,
we will also learn how to provide web and database services.
Linux can be used to provide <a href="https://en.wikipedia.org/wiki/Server_(computing)">other services</a> that
we won't cover in this course, such as:</p>
<ul>
<li>file servers</li>
<li>mail servers</li>
<li>print servers</li>
<li>game servers</li>
<li>computing servers</li>
</ul>
<p>Although it's a small overall percentage,
many people use Linux as their main
desktop/laptop operating system.
I belong in this camp.
Linux has been my main OS since the early 2000s.
While our work on the Linux server means that we will
almost entirely work on the command line,
this does not mean that my Linux
desktop environment is all command line.
In fact, there are many graphical user environments,
often called <a href="https://en.wikipedia.org/wiki/Desktop_environment">desktop environments</a>,
available to Linux users.
Since I'm currently using the Ubuntu Desktop distribution,
my default desktop environment is called <a href="https://www.gnome.org/">Gnome</a>.
<a href="https://kde.org/">KDE</a> is another popular desktop environment, but
there are many other attractive and useful ones.
And it's easy to install and switch between
multiple ones on the same OS.</p>
<p>Linux has become quite a pervasive operating system.
Linux powers the hundreds of the
fastest supercomputers in the world.
It, or other Unix-like operating systems,
are the foundation of most web servers.
The Linux kernel also forms the basis of the Android
operating system and of Chrome OS.
The only place where Linux does not dominate is
in the desktop/laptop space.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-systems-administration"><a class="header" href="#what-is-systems-administration">What is Systems Administration?</a></h1>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>What is systems administration or who is a systems administrator (or <strong>sysadmin</strong>)?
Let's start off with some definitions provided by the <a href="https://www.nist.gov/">National Institute of Standards and Technology</a>:</p>
<blockquote>
<p>An individual, group, or organization responsible for setting up and maintaining a system or specific system elements,
implements approved secure baseline configurations, incorporates secure configuration settings for IT products, and
conducts/assists with configuration monitoring activities as needed.</p>
</blockquote>
<p>Or:</p>
<blockquote>
<p>Individual or group responsible for overseeing the day-to-day operability of a computer system or network.
This position normally carries special privileges including access to the protection state and software of a system.</p>
</blockquote>
<p>See: <a href="https://csrc.nist.gov/glossary/term/system_administrator">Systems Administrator @NIST</a></p>
<h2 id="specialized-positions"><a class="header" href="#specialized-positions">Specialized Positions</a></h2>
<p>In addition to the above definitions, which broadly define the role, there are a number of related or specialized positions.
We'll touch on the first three in this course:</p>
<ul>
<li>Web server administrator:
<ul>
<li>"web server administrators are system architects responsible for the
overall design, implementation, and maintenance of Web servers. They may or
may not be responsible for Web content, which is traditionally the
responsibility of the Webmaster (<a href="https://csrc.nist.gov/glossary/term/web_server_administrator">Web Server Administrator" @NIST</a>).</li>
</ul>
</li>
<li>Database administrator:
<ul>
<li>like web admins, and to paraphrase above, database administrators are system
architects responsible for the overall design, implementation, and
maintenance of database management systems.</li>
</ul>
</li>
<li>Network administrator:
<ul>
<li>"a person who manages a network within an organization. Responsibilities
include network security, installing new applications, distributing software
upgrades, monitoring daily activity, enforcing licensing agreements,
developing a storage management program, and providing for routine backups"
(<a href="https://csrc.nist.gov/glossary/term/network_administrator">Network Administrator @NIST</a>).</li>
</ul>
</li>
<li>Mail server administrator:
<ul>
<li>"mail server administrators are system architects responsible for the
overall design and implementation of mail servers" (<a href="https://csrc.nist.gov/glossary/term/mail_server_administrator">Mail Server Administrators @NIST</a>).</li>
</ul>
</li>
</ul>
<p>Depending on where a system administrator works, they may specialize in any of the above administrative areas, or
if they work for a small organization, all of the above duties may be rolled into one position.
Some of the positions have evolved quite a bit over the last couple of decades.
For example, it wasn't too long ago when organizations would operate their own mail servers, but
this has largely been outsourced to third-party providers, such as Google (via Gmail) and Microsoft (via Outlook).
People are still needed to work with these third-party email providers, but
the nature of the work is different than operating independent mail servers.</p>
<h2 id="certifications"><a class="header" href="#certifications">Certifications</a></h2>
<p>It's not always necessary to get certified as a systems administrator to get work as one, but there might be cases where it is necessary;
for example, in government positions or in large corporations.
It also might be the case that you can get work as an entry level systems administrator and
then pursue certification with the support of your organization.</p>
<p>Some common starting certifications are:</p>
<ul>
<li><a href="https://www.redhat.com/en/services/certification/rhcsa">Red Hat Certified System Administrator (RHCSA)</a></li>
<li><a href="https://www.comptia.org/certifications/server">CompTIA Server+</a></li>
<li><a href="https://www.comptia.org/certifications/a">CompTIA A+</a></li>
</ul>
<p>Plus, Google offers, via <a href="https://www.coursera.org/">Coursera</a>, a beginners <a href="https://www.coursera.org/professional-certificates/google-it-support">Google IT Support Professional Certificate</a> that may be helpful.</p>
<h2 id="associations"><a class="header" href="#associations">Associations</a></h2>
<p>Getting involved in associations and related organizations is a great way to learn and to connect with others in the field.
Here are few ways to connect.</p>
<p><a href="https://lopsa.org/AboutLOPSA">LOPSA</a>, or The League of Professional System Administrators, is a non-profit association that seeks to advance
the field and membership is free for students.</p>
<p><a href="https://www.acm.org/">ACM</a>, or the Association for Computing Machinery, has a number of relevant <a href="https://www.acm.org/special-interest-groups/alphabetical-listing">special interest groups (SIGs)</a>
that might be beneficial to systems administrators.</p>
<p><a href="http://www.npa.org/">NPA</a>, or the Network Professional Association, is an organization that "supports IT/Network professionals."</p>
<h2 id="codes-of-ethics"><a class="header" href="#codes-of-ethics">Codes of Ethics</a></h2>
<p>Systems administrators manage computer systems that contain a lot of data about us and this raises privacy and competency issues,
which is why some have created code of ethics statements.
Both LOPSA and NPA have created such statements that are well worth reviewing and discussing.</p>
<ul>
<li>LOPSA: <a href="https://lopsa.org/CodeOfEthics">Code of Ethics</a></li>
<li>NPA: <a href="https://www.npa.org/public/about_codeofethics.cfm">Code of Ethics</a></li>
</ul>
<h2 id="keeping-up"><a class="header" href="#keeping-up">Keeping Up</a></h2>
<p>Technology changes fast.
In fact, even though I teach this course about every year, I need to revise the course each time, sometimes substantially,
to reflect changes that have developed over short periods of time.
It's also your responsibility, as sysadmins, to keep up, too.</p>
<p>I therefore suggest that you continue your education by reading and practicing.
For example, there are lots of books on systems administration.
<a href="https://www.oreilly.com/library/view/essential-system-administration/0596003439/">O'Reilly</a> continually publishes on the topic.
RedHat, the makers of the Red Hat Linux distribution, and sponsors of <a href="https://www.fedoraproject.org/">Fedora Linux</a>,
provides the <a href="https://www.redhat.com/sysadmin/">Enable Sysadmin</a> site, with new articles each day, authored by systems administrators, on the field.
Opensource.com, also supported by Red Hat, <a href="https://opensource.com/tags/sysadmin">publishes articles on systems administration</a>
(although it's been on hiatus for a while now).
<a href="https://www.redhat.com/en/command-line-heroes">Command Line Heroes</a> is a fun and informative podcast on technology and sysadmin related topics
(also, this has been on hiatus).
<a href="https://www.linuxjournal.com/">Linux Journal</a> publishes great articles on Linux related topics.</p>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>In this section I provided definitions of systems administrators and also the related or more specialized positions,
such as database administrator, network administrator, and others.</p>
<p>I provided links to various certifications you might pursue as a systems administrator, and
links to associations that might benefit you and your career.</p>
<p>Technology manages so much of our daily lives, and computer systems store lots of data about us.
Since systems administrators manage these systems, they hold a great amount of responsibility to protect them and our data.
Therefore, I provided links to two code of ethics statements that we will discuss.</p>
<p>It's also important to keep up with the technology, which changes fast.
The work of a systems administrator is much different today than it was ten or twenty years ago, and
that surely indicates that it could be much different in another ten to twenty years.
If we don't keep up, we won't be of much use to the people we serve.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="project-setup"><a class="header" href="#project-setup">Project Setup</a></h1>
<p>In this section, you will learn how to use <a href="https://cloud.google.com">Google Cloud</a> (gcloud)
to install and manage Linux servers as virtual machines.
We will specifically use <code>gcloud</code> to create virtual instances of the
Ubuntu Server Linux operating system.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="using-gcloud-for-virtual-machines"><a class="header" href="#using-gcloud-for-virtual-machines">Using gcloud for Virtual Machines</a></h1>
<p>After this section, you will be able to achieve the following outcomes:</p>
<ul>
<li><strong>Understand the concept of Virtual Machines (VMs):</strong> Learn what a VM is and how it operates on a host operating system.</li>
<li><strong>Set up a Google Cloud project using <code>gcloud</code>:</strong> Create a Google Cloud project and enable billing for it.</li>
<li><strong>Create a Virtual Machine instance:</strong> Configure and deploy a VM on Google Cloud using the Ubuntu 22.04 LTS operating system.</li>
<li><strong>Install and initialize the <code>gcloud</code> CLI:</strong> Set up the <code>gcloud</code> command interface on your local machine for managing cloud resources.</li>
<li><strong>Connect to the VM using SSH:</strong> Establish a secure connection to your VM via the command line from your local machine.</li>
<li><strong>Update and manage the VM:</strong> Perform essential updates on the VM and create snapshots for backup and recovery.</li>
</ul>
<h2 id="virtual-machines"><a class="header" href="#virtual-machines">Virtual Machines</a></h2>
<p>Our goal in this section is to create a <strong>virtual machine (VM)</strong> <em>instance</em> running a distribution of the Linux operating system.
A VM is a virtualized operating system that runs on a host operating system.
That host operating system may also be Linux, but it could be Windows or macOS.
In short, using virtual machines means instead of installing an operating system on bare metal,
we use virtual machine software to mimic the process of installing an additional OS as an <em>app</em> (so to speak) on an existing OS.</p>
<blockquote>
<p>There are many ways to do virtualization.
According to <a href="https://www.redhat.com/en/topics/virtualization/what-is-a-virtual-machine">Red Hat</a>, there is data virtualization, desktop virtualization,
server virtualization, OS virtualization, (which is the technology we cover here),
and network functions virtualization.</p>
</blockquote>
<p>In this book, we're going to use Google Cloud to create and run our virtual machines.
There are other options available that you can explore on your own.</p>
<h2 id="google-cloud--gcloud"><a class="header" href="#google-cloud--gcloud">Google Cloud / gcloud</a></h2>
<h3 id="google-account"><a class="header" href="#google-account">Google Account</a></h3>
<p>We need a Google account to create our virtual machines.
I imagine you already have a Google account, but if not, then create one at <a href="https://www.google.com">https://www.google.com</a>.
Be sure to use your personal Google account for this project.</p>
<h3 id="google-cloud-gcloud-project"><a class="header" href="#google-cloud-gcloud-project">Google Cloud (gcloud) Project</a></h3>
<p>After signing into Google:</p>
<ol>
<li>Create a Google Cloud project.</li>
<li>Enable billing for that project.</li>
<li>Create a VM (or <em>virtual instance</em>) on Google Cloud.</li>
<li>Install the <code>gcloud</code> CLI software on our personal machines to connect to our remote VM;
<ul>
<li>alternatively, use the web interface (details below) to connect to our remote VM.</li>
</ul>
</li>
</ol>
<blockquote>
<p>Although I include most of the instructions on this page to perform the above steps,
it is imperative that you <strong>read through Google's instructions</strong> also.</p>
</blockquote>
<h4 id="create-a-project"><a class="header" href="#create-a-project">Create a Project</a></h4>
<p>After signing into your Google account,
proceed to <strong>Step 1</strong> at the top of the  <a href="https://cloud.google.com/sdk/docs/install-sdk">Install the gcloud CLI</a> page to create a new project.
Review the page on <a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects#gcloud">creating and managing projects</a>.</p>
<p>When you create your project, you can name it anything, but try to name it something to do with this project.
E.g., I might use the name <strong>sysadmin-418</strong>.
<em>Avoid spaces in the names of your project.</em>
Click on the <strong>Create</strong> button, and leave the organization field set to <strong>No Organization</strong>.
Make sure you've selected your project, and then click on <strong>Enable</strong> for <strong>Compute Engine API</strong>.</p>
<h4 id="google-billing"><a class="header" href="#google-billing">Google Billing</a></h4>
<p>Second, set up a billing account for your gcloud project.
This means there is a cost associated with this product,
but the machines we'll build require few resources and the cost should be minimal.
In the past, I usually pay about $1 per month.
<a href="https://cloud.google.com/sdk/docs/install-sdk">Follow Step 2</a> to enable billing for the new project.
See also the page on how to <a href="https://cloud.google.com/billing/docs/how-to/manage-billing-account">create, modify, or close your self-serve Cloud Billing account</a>.</p>
<h4 id="gcloud-vm-instance"><a class="header" href="#gcloud-vm-instance">gcloud VM Instance</a></h4>
<p>Next, log into <a href="https://console.cloud.google.com/">Google Cloud Console</a>.
This should take you to the Dashboard page.</p>
<p>Our first goal is to create a <strong>virtual machine (VM)</strong> <em>instance</em>.
As a reminder, a VM is a virtualized operating system.
We will use software to mimic the process of installing an operating system on Google's servers.</p>
<p>Google Cloud offers a number of Linux-based operating systems to create VMs.
We're going to use the Ubuntu operating system and specifically the Ubuntu 22.04 LTS version.
We are not going to install a graphical user interface on our Ubuntu servers.
Rather, we will focus on using the command line to do most of our work.</p>
<blockquote>
<p>What is Ubuntu?
Ubuntu is a distribution of Linux.
A new version of Ubuntu is released every six months.
The 22.04 signifies that this is the April 2022 version.
The LTS signifies <strong>Long Term Support</strong>.
LTS versions are released every two years, and Canonical LTD, the owners of Ubuntu, provide five years standard support for LTS versions.
Thus, Ubuntu 22.04 is supported through June 2027.</p>
<p>LTS versions of Ubuntu are more stable than non-LTS versions of Ubuntu.
The latter receive nine months of standard support and generally use cutting edge technology.
Cutting edge technology is not always desirable for server operating systems, which often prioritize stability.
Each version of Ubuntu has a code name.
Ubuntu 22.04 LTS has the code name <strong>Jammy Jellyfish</strong>.
You can see a list of versions, code names, release dates, and more on Ubuntu's <a href="https://wiki.ubuntu.com/Releases">Releases</a> page.</p>
</blockquote>
<p>You should be on the page where you create a new VM, but if not</p>
<ul>
<li>If Click the three horizontal bars at the top left of the screen.</li>
<li>Hover over the <strong>Compute Engine</strong> link, and then select <strong>VM Instances</strong>.</li>
<li>In the window, select the project that you created earlier.
<ul>
<li>E.g., for me, I used the project name <strong>sysadmin-418</strong>.</li>
</ul>
</li>
<li>Next, click on <strong>Create Instance</strong>.</li>
<li>Change the name for your <strong>instance</strong>.
<ul>
<li>E.g., I chose <strong>fall-2025</strong> (no spaces)</li>
</ul>
</li>
</ul>
<p>If you are already on the Create VM page, then:</p>
<ul>
<li>Change the name for your <strong>instance</strong>.
<ul>
<li>E.g., I chose <strong>fall-2025</strong> (no spaces)</li>
</ul>
</li>
<li>Use default <strong>Region</strong> and <strong>Zone</strong>.</li>
<li>Make sure <strong>E2 (Low cost, day-to-day computing)</strong> is selected.</li>
<li>Under the <strong>Machine type</strong> drop down box, select <strong>e2-micro (0.25-2 vCPU (1 shared core), 1 GB memory)</strong>
<ul>
<li>This is the lowest cost virtual machine and perfect for our needs.</li>
</ul>
</li>
</ul>
<p>Next, click on the <strong>OS and storage</strong> link in the left hand navigation section.</p>
<ul>
<li>Click on the <strong>Change</strong> button.</li>
<li>Under <strong>Operating system</strong>, select <strong>Ubuntu</strong>.</li>
<li>Under <strong>Version</strong>, select <strong>Ubuntu 22.04 LTS x86/64</strong></li>
<li>Leave <strong>Boot disk type</strong> be set to <strong>Balanced persistent disk</strong></li>
<li>Disk size should be set to <strong>10 GB</strong>.</li>
<li>Click on the <strong>Select</strong> button.</li>
</ul>
<p>Next, click on the <strong>Networking</strong> link in the left hand navigation section.</p>
<ul>
<li>Check the <strong>Allow HTTP Traffic</strong> button</li>
<li>Finally, click on the <strong>Create</strong> button to create your VM instance.</li>
</ul>
<h4 id="install-the-latest-gcloud-cli-version"><a class="header" href="#install-the-latest-gcloud-cli-version">Install the latest gcloud CLI version</a></h4>
<p>In this section, we install the <code>gcloud</code> CLI software to connect to our virtual machines on Google Cloud.
Using the <code>gcloud</code> CLI is a more advanced way to connect to our VMs.
If you prefer, you can connect to your VM using Google's web interface.
Skip to the <a href="2a-using-gcloud-virtual-machines.html#connect-to-our-vm">Connect To Our VM</a> section if you prefer the web interface.</p>
<p>Using the <code>gcloud</code> CLI will allow us to connect to remote server using our own terminal applications.
The <strong><a href="https://cloud.google.com/sdk/docs/install-sdk">Install the gcloud CLI</a></strong> page provides instructions for different operating systems.</p>
<p>There are installation instructions for macOS, Windows, Chromebooks, and various Linux distributions.
Follow these instructions closely for the operating system that you're using.</p>
<blockquote>
<p>Note that for macOS, you have to choose among three different CPU/chip architectures.
If you have an older macOS machine (before November 2020 or so), it's likely that you'll select <strong>macOS 64-bit (x86_64)</strong>.
If you have a newer macOS machine, then it's likely you'll have to select <strong>macOS 64-bit (arm64, Apple M1 silicon).</strong>
It's unlikely that any of you are using a 32-bit macOS operating system.
If you're not sure which macOS system you have, then let me know and I can help you determine the appropriate platform.
Alternatively, follow these instructions to find your processor information:</p>
<ul>
<li>click on the Apple menu</li>
<li>choose <strong>About This Mac</strong></li>
<li>locate the <strong>Processor</strong> or <strong>Chip</strong> information</li>
</ul>
</blockquote>
<p>After you have downloaded the gcloud CLI for your particular OS and CPU architecture,
you will need to open a command prompt/terminal on your machines to complete the instructions
that describe how to install the gcloud CLI.
macOS uses the Terminal app, which can be located using Spotlight.
Windows users can use the Command Prompt or Powershell.</p>
<h5 id="windows-users"><a class="header" href="#windows-users">Windows Users</a></h5>
<p>Windows users will download a regular <strong>.exe</strong> file, and launch the installer in the regular Windows way.
Please follow the rest of the instructions for Windows.</p>
<h5 id="macos-users"><a class="header" href="#macos-users">macOS Users</a></h5>
<p><strong>macOS</strong> users may need to complete some setup work before installing Google Cloud.
First, open your Terminal.app and run the following code:</p>
<pre><code>xcode-select --install
</code></pre>
<p>Once the Xcode developer tools are installed, you need to install the macOS Homebrew package manager.
To do so, follow the instructions here:</p>
<p><a href="https://brew.sh/">Homebrew</a></p>
<p>After Homebrew is installed use the <code>brew</code> command to install <a href="https://github.com/pyenv/pyenv">pyenv</a>.</p>
<pre><code>brew install pyenv
</code></pre>
<p>And then use <code>pyenv</code> to install the latest version of Python.
For example, to install the <a href="https://www.python.org/">latest release of Python</a> (as of August 2024):</p>
<pre><code>penv install 3.12.5
</code></pre>
<p>Finally, you can install the Google Cloud application using the steps outlined below.
Or you can use the steps outlined in the <a href="https://cloud.google.com/sdk/docs/downloads-interactive#linux-mac">Google Cloud Interactive installation</a>.</p>
<p>See also:</p>
<p><a href="https://cloud.google.com/python/docs/setup">Setting up a Python development environment</a></p>
<p>macOS users will download a <strong>.tar.gz</strong> file and extract the <strong>.tar.gz</strong> using the <code>tar</code> command.
The <strong>.tar.gz</strong> file may have been downloaded to your <strong>Downloads</strong> folder.
First, in your Terminal.app, move that file to your home directory and extract it there.
Once extracted, change to home directory with the <code>cd</code> command.
For example, if you are running macOS and downloaded the x86_64 version of the gcloud CLI, then open your Terminal.app and run the following commands:</p>
<pre><code>mv ~/Downloads/google-cloud-cli-darwin-x86_64.tar.gz $HOME
cd $HOME
tar -xzf google-cloud-cli-444.0.0-darwin-x86_64.tar.gz 
cd google-cloud-sdk
</code></pre>
<p>Modify the file names in the commands above, as appropriate, if you're using the M1 version of the gcloud CLI.</p>
<h4 id="initializing-the-gcloud-cli"><a class="header" href="#initializing-the-gcloud-cli">Initializing the gcloud CLI</a></h4>
<p>Regardless if you're using macOS or Windows, you will now initialize your Google Cloud installation the same way.
First, scroll down the install page to the section titled <a href="https://cloud.google.com/sdk/docs/install-sdk#initializing_the"><strong>Initializing the gcloud CLI</strong></a>.
In your terminal, run the initialization command.
Per the instructions at the above page, it should be something like so:</p>
<pre><code>gcloud init
</code></pre>
<p>And continue to follow the instructions in the documentation.</p>
<h2 id="connect-to-our-vm"><a class="header" href="#connect-to-our-vm">Connect to our VM</a></h2>
<h3 id="using-gcloud-cli"><a class="header" href="#using-gcloud-cli">Using <code>gcloud</code> CLI</a></h3>
<p>After the new VM machine has been created, you connect to it via the command line.
macOS users will connect to it via their Terminal.app.
Windows users can connect to it via their Command shell or Powershell.</p>
<p>If you have used <code>ssh</code> before, note that we use a slightly different <code>ssh</code> command to connect to our VMs.
The syntax follows this pattern:</p>
<pre><code>gcloud compute ssh --zone "zone-info" "name-info" --project "project-id"
</code></pre>
<p>You need to replace the values in the double quotes in the above command
with the values located in your Google Cloud console and in your VM instances section.
You can select the <strong>SSH</strong> drop down box to copy the exact <code>gcloud</code> command to connect to your server.</p>
<h3 id="using-the-web-interface"><a class="header" href="#using-the-web-interface">Using the Web Interface</a></h3>
<p>If you did not install <code>gcloud</code> CLI, then you can connect through the Google Cloud Console website.
To do so:</p>
<ol>
<li>Click on the drop down arrow next to the <code>SSH</code> button for your VM instance.</li>
<li>Select, <strong>Open in browser window</strong>.</li>
<li>Authorize it to allow <strong>SSH-in-browser to connect to VMs</strong>.</li>
<li>A terminal in a browser window should appear.</li>
</ol>
<h2 id="update-our-ubuntu-vm"><a class="header" href="#update-our-ubuntu-vm">Update our Ubuntu VM</a></h2>
<p>Once you have access to the command line on your remote Linux virtual instance,
you will need to update your OS.
The VM will include a recently updated version of Ubuntu 22.04, but it may not be completely updated.
Thus the first thing we need to do is update our machines.
Since this is an Ubuntu machine, use the following two commands to update your machines.
Type the first command in, wait for it to complete, and then type the second command.
<strong>READ the OUTPUT</strong> closely.
It will ask you to continue.
Press <strong>Y</strong> to continue (lowercase <strong>y</strong> is fine).</p>
<pre><code>sudo apt update
sudo apt -y upgrade
</code></pre>
<p>You are done!
To exit the VM, type the <code>exit</code> command:</p>
<pre><code>exit
</code></pre>
<p>Typing <code>exit</code> at the prompt will always close our connection to our remote servers.</p>
<h2 id="snapshots"><a class="header" href="#snapshots">Snapshots</a></h2>
<p>You have installed a pristine version of Ubuntu, but mistakes will happen while learning how to use your machines.
If you want, you can backup this pristine version of the operating system.
This will allow you to restore the server if something goes wrong later.</p>
<p><strong>NOTE:</strong> It's pretty easy to create a new VM instance.
Therefore, it's okay to create snapshots later when you are working on your projects.
This will reduce costs until needed.</p>
<p>To get started:</p>
<ol>
<li>In the left hand navigation panel, click <strong>Compute Engine</strong> and then <strong>Snapshots</strong>.</li>
<li>At the top of the page, click on <strong>Create Snapshot</strong>.</li>
<li>Provide a name for your snapshot: e.g., <strong>ubuntu-1</strong>.</li>
<li>Provide a description of your snapshot: e.g., <strong>This is a new install of Ubuntu 22.04.</strong></li>
<li>Choose your <strong>Source disk</strong>.</li>
<li>Choose a <strong>Location</strong> to store your snapshot.
<ul>
<li>To avoid extra charges, choose <strong>Regional</strong>.</li>
<li>From the drop down box, select the same location (zone-info) your VM has</li>
</ul>
</li>
<li>Click on <strong>Create</strong></li>
</ol>
<p><strong><p style="color:red">Please monitor your billing for this to avoid costs that you do not want to incur.</p></strong></p>
<h2 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h2>
<p>Congrats!
You have successfully completed your first Linux server installation.
In this section, you learned about virtual machines (VMs) and created one using Google Cloud.
Specifically, you created a Ubuntu 22.04 LTS Linux virtual machine.
While this may seem like a lot of information,
by the end of this book you will be able to effortlessly deploy and manage VMs for various tasks.
Such tasks may include setting up websites and more.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="learning-the-command-line"><a class="header" href="#learning-the-command-line">Learning the Command Line</a></h1>
<p>In this section, our focus is learning the command line environment, how to use it, and what it offers.</p>
<p>It's more common for people to learn how to use a computer via a graphical user interface (GUI).
Yet, GUIs are not well suited for servers.
There are a few reasons for this.
First, GUIs entail extra software.
The more software we have on a server, the more resources that software consumes,
the more software that needs to be managed, and the more we expose our systems to security risks.
You could therefore imagine how problematic it would be for a company to manage thousands of servers if all those servers had GUIs installed on them.
Second, GUIs do not provide a good platform for automation (aka, scripting), at least not remotely as well as command line interfaces (CLIs) do.
It's because of this and for other reasons, we will learn how to use the CLI.</p>
<p>Learning the CLI has other benefits.
Using the command line means using a <a href="https://en.wikipedia.org/wiki/Unix_shell">shell</a>, and using a shell means programming a computer.
Thus, while this book does not spend much time on <em>programming</em> per se, you will by default be programming just by using the CLI.
Using the CLI also removes a lot of <a href="https://en.wikipedia.org/wiki/Desktop_metaphor">abstractions</a> that GUIs introduce.
These abstractions, or metaphors, obfuscate how computers function even if they make using computers easier, which is debatable.
Thus, by learning the CLI, you'll gain a better understanding how computers work.</p>
<p>Fortunately, Linux and many other Unix-like operating systems have the ability to operate without graphical user interfaces.
This is partly the reason why these operating systems have done so well in the server market.
Let's get started!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-linux-filesystem"><a class="header" href="#the-linux-filesystem">The Linux Filesystem</a></h1>
<p>In this section, we will cover the:</p>
<ul>
<li>the Linux filesystem and how it is structured and organized, and</li>
<li>the basic commands to navigate around and to work with directories and files</li>
</ul>
<blockquote>
<p>The terms <strong>directories</strong> and <strong>folders</strong> are synonymous, but as users of primarily graphical user interfaces,
you &gt; are more likely familiar with the term <strong>folders</strong>.
I will more often use the term <strong>directories</strong> since that is the command line (text user interface) convention.
I will use the term <strong>folders</strong> when referring to a graphical environment.</p>
</blockquote>
<p>Throughout this demonstration, I encourage you to connect to your remote server using the <code>gcloud compute ssh</code> command or
through the web shell and follow along with the commands that I use.
See <a href="2a-using-gcloud-virtual-machines.html">Section 2.1</a> for details on connecting to the remote server.</p>
<h2 id="visualizing-the-filesystem-as-a-tree"><a class="header" href="#visualizing-the-filesystem-as-a-tree">Visualizing the Filesystem as a Tree</a></h2>
<p>We will need to work within the filesystem quite, but the term <strong>filesystem</strong> may refer to different concepts,
and it's important to clear that up before we start.</p>
<p>In come cases, a <strong>filesystem</strong> refers to how data (files) are <a href="https://en.wikipedia.org/wiki/File_system">stored and retrieved</a>
on a device like a hard drive, USB drive, etc.
For example, macOS uses the <a href="https://support.apple.com/guide/disk-utility/file-system-formats-available-in-disk-utility-dsku19ed921c/mac">Apple File System (APFS)</a> by default, and Windows uses the <a href="https://docs.microsoft.com/en-us/troubleshoot/windows-client/backup-and-storage/fat-hpfs-and-ntfs-file-systems">New Technology File System (NTFS)</a>.
Linux and other Unix-like operating systems use a variety of filesystems, but presently, the two major ones are <strong>ext4</strong> and <strong>btrfs</strong>.
The former is the default filesystem on distributions like <a href="https://www.debian.org/">Debian</a> and <a href="https://ubuntu.com">Ubuntu</a>;
the latter is the default on the <a href="https://getfedora.org/">Fedora</a> and <a href="https://www.opensuse.org/">openSUSE</a> distributions.
<a href="https://opensource.com/article/18/4/ext4-filesystem">Opensource.com</a> has a nice overview of filesystems under this concept.</p>
<p>A <strong>filesystem</strong> might also be used to refer to the <strong>directory structure</strong> or <a href="https://refspecs.linuxfoundation.org/FHS_3.0/fhs/ch01.html">directory tree</a> of a system.
In graphical user interface parlance, this is simply how the folders are your disk are organized.
This concept of a filesystem is related to the prior concept of a filesystem, but
it's used here to refer to the location of files and directories on a system.
For example, on Windows, the filesystem is identified by a letter, like the <strong>C:</strong> drive,
regardless if the disk has a NTFS filesystem or a FAT filesystem.
Additional drives (e.g., extra hard drives, USB drives, DVD drives, etc.), will be assigned their own letters (<strong>A:</strong>, <strong>B:</strong>, <strong>D:</strong>, etc.).
<a href="https://developer.apple.com/library/archive/documentation/FileManagement/Conceptual/FileSystemProgrammingGuide/FileSystemOverview/FileSystemOverview.html">macOS adheres to a tree like filesystem</a> like Linux, UNIX, and other Unix-like operating systems, and
<a href="https://www.opengroup.org/openbrand/register/">this is because macOS is a registered UNIX® OS</a>.</p>
<p>In Unix-like OSes, like Linux, we have a top-level <strong>root</strong> directory identified by a single forward slash  <strong>/</strong>,
and then subdirectories under that root directory.
Additional drives (e.g., extra hard drives, USB drives, DVD drives, etc.) are <strong>mounted</strong> under that root hierarchy and
not as separate drives like on Windows.
Run the command <code>man 7 file-hierarchy</code> to review the directory structure that Linux distributions use along
with an explanation for the major bottom level directories.
In this section, we will learn about this type of filesystem.</p>
<blockquote>
<p>The <code>man</code> command (short for 'manual') provides access to Linux's main system documentation.
You can use the Page Up/Down keys to review documentation, and press <code>q</code> to exit.</p>
</blockquote>
<p>On Linux, we can visualize the filesystem with the <code>tree</code> command.
The <code>tree</code> command, like many Linux commands, can be run on its own or with options, like in the second example below:</p>
<ul>
<li><code>tree</code> : list contents of directories in a tree-like format
<ul>
<li><code>tree -dfL 1</code> : directories only, full path, one level</li>
<li><code>tree -dfL 1 /</code> : list directories only at root <strong>/</strong> level</li>
</ul>
</li>
</ul>
<blockquote>
<p>The <code>tree</code> command may not be installed by default.
It can be installed with the command: <code>sudo apt install tree</code></p>
</blockquote>
<h3 id="the-root-directory-and-its-base-level-directories"><a class="header" href="#the-root-directory-and-its-base-level-directories">The root Directory and its Base Level Directories</a></h3>
<p>As explained in the documentation, some of the major sub directories under <strong>/</strong> (root) are:</p>
<ul>
<li><code>/bin</code> : binary files needed to use the system</li>
<li><code>/boot</code>  : files needed to boot the system</li>
<li><code>/dev</code> : device files (all hardware has a file)</li>
<li><code>/etc</code> : system configuration files</li>
<li><code>/home</code> : user directories</li>
<li><code>/lib</code> : libraries/programs needed for other programs</li>
<li><code>/media</code> : external storage is mounted</li>
<li><code>/mnt</code> : other filesystems may be mounted</li>
<li><code>/opt</code> : store software code to compile software</li>
<li><code>/proc</code> : files containing info about your computer</li>
<li><code>/root</code> : home directory of superuser</li>
<li><code>/run</code> : used by system processes</li>
<li><code>/sbin</code> : like <code>/bin</code>, binary files that require superuser privileges</li>
<li><code>/srv</code> : contains data for servers</li>
<li><code>/sys</code> : contains info about devices</li>
<li><code>/tmp</code> : temp files used by applications</li>
<li><code>/usr</code> : user binaries, etc that might be installed by users</li>
<li><code>/var</code> : variable files, used often for system logs</li>
</ul>
<p>Although there are 18 directories listed above that <strong>branch</strong> off from the root directory, we will use some more often than others.
For example, the <code>/etc</code> directory contains system configuration files, and we will use the contents of this directory,
along with the <code>/var</code> directory, quite a bit when we set up our web servers, relational database servers, and more later.
The <code>/home</code> directory is where our default home directories are stored.
If you manage a multi-user system, then this will be an important directory to manage.</p>
<p>Source: <a href="https://www.linux.com/tutorials/linux-filesystem-explained/">Linux Filesystem Explained</a></p>
<h2 id="relative-and-absolute-paths"><a class="header" href="#relative-and-absolute-paths">Relative and Absolute Paths</a></h2>
<p>macOS users have the Finder app to navigate their filesystem, to move files to different folders, to copy files, to trash them, etc.
Window users have File Explorer for these functions.
Linux users have similar graphical software options, but all of these functions can be completed on the Linux command line,
and generally more efficiently.
To get started, we need to learn two things first:</p>
<ol>
<li>how to specify the locations of files and directories in the filesystem</li>
<li>the commands needed to work with the filesystem</li>
</ol>
<p>To help specify the locations of files and directories, there are two key concepts to know:</p>
<ul>
<li>absolute paths</li>
<li>relative paths</li>
</ul>
<p>Above we learned about the <code>/</code> root directory and its subdirectories.
All sorts of commands, especially those that deal with files and directories (like copying, moving, deleting),
require us to specify on the command line the locations of the files and directories.
It's common to specify the location in two different ways, by specifying their <strong>absolute</strong> path (or location) on the filesystem,
or the <strong>relative</strong> path (or location).</p>
<p>To demonstrate, we might want to move around the filesystem.
When we first log in to our remote system, our default location will be our home directory, sometimes referred to as <code>$HOME</code>.
The path (location) to that directory will be.</p>
<pre><code>/home/USER
</code></pre>
<p>Where <strong>USER</strong> is your username.
Therefore, since my username is <strong>seanburns</strong>, my home directory is located at:</p>
<pre><code>/home/seanburns
</code></pre>
<p>which we can see specified with the <code>pwd</code> (print working directory) command:</p>
<pre><code>pwd
/home/seanburns
</code></pre>
<blockquote>
<p>When I write <code>$HOME</code>, I am referring to a default, <strong>environmental</strong> variable that points to our home directory.
It's <strong>variable</strong> because, depending on which account we're logged in as, <strong>$HOME</strong> will point to a different location.
For me, then, that will be <code>/home/seanburns</code>, if I'm logged in as <code>seanburns</code>.
For you it'll point to your home directory.</p>
</blockquote>
<p>In my home directory, I have a subdirectory called <code>public_html</code>.
The path to that is:</p>
<pre><code>/home/seanburns/public_html
</code></pre>
<p>In a program like Finder (macOS) or File Explorer (Windows), if I want to change my location to that subdirectory (or folder),
then I'd double click on its folder icon.
On the command line, however, I have to write out the command and the path to the subdirectory.
Therefore, <strong>starting in my home directory</strong>, I use the following command to switch to the public_html subdirectory:</p>
<pre><code>cd public_html
</code></pre>
<blockquote>
<p>Note that files and directories in Linux are case sensitive.
This means that a directory named <code>public_html</code> can co-exist alongside a directory named <code>Public_html</code>.
Or a file named <code>paper.txt</code> can co-exist alongside a file named <code>Paper.txt</code>.
So be sure to use the proper case when spelling out files, directories, and even commands.</p>
</blockquote>
<p>The above is an example of using a relative path, and that command would only be successful if I were first in my <code>$HOME</code> directory.
That's because I specified the location of <code>public_html</code> relative to my default (<code>$HOME</code>) location.</p>
<p>I could have also specified the absolute location, but this would be the wordier way.
Since the <code>public_html</code> directory is in my <code>$HOME</code> directory, and my <code>$HOME</code> directory is a subdirectory in the <code>/home</code> directory,
then to specify the absolute path in the above command, I'd write:</p>
<pre><code>cd /home/sean/public_html
</code></pre>
<p>Again, the relative path specified above would only work if I was in my home directory,
because <code>cd public_html</code> is relative to the location of <code>/home/seanburns</code>.
That is, the subdirectory <code>public_html</code> is in <code>/home/seanburns</code>.
But specifying the absolute path would work no matter where I was located in the filesystem.
For example, if I was working on a file in the <code>/etc/apache2`` directory, then using the absolute path (</code>cd /home/seanburns/public_html<code>) would work. But the relative path (</code>cd public_html<code>) command would not since there is no subdirectory called </code>public_html<code>* in the </code>/etc/apache2` directory.</p>
<p>Finally, you can use the <code>ls</code> command to list the contents of a directory, i.e., the files and subdirectories in a directory:</p>
<pre><code>ls
</code></pre>
<p>We will cover this more next.</p>
<h2 id="conclusion-2"><a class="header" href="#conclusion-2">Conclusion</a></h2>
<p>Understanding relative and absolute paths is one of the more difficult concepts for new commandline users to learn,
but after time, it'll feel natural.
So just keep practicing, and I'll go over this throughout the semester.</p>
<p>In this section, you learned the following commands:</p>
<ul>
<li><code>tree</code> to list directory contents in a tree-like format</li>
<li><code>cd</code> to <strong>change directory</strong></li>
<li><code>pwd</code> to <strong>print working directory</strong></li>
</ul>
<p>You learned different ways to refer to the home directory:</p>
<ul>
<li><strong>/home/USER</strong></li>
<li><strong>$HOME</strong></li>
<li><strong>~</strong></li>
</ul>
<p>You learned about relative and absolute paths.
An absolute path starts with the root directory <code>/</code>.
Here's an absolute path to a file named <code>paper.txt</code> in my home directory:</p>
<ul>
<li>absolute path: <code>/home/seanburns/paper.txt</code></li>
</ul>
<p>If I were already in my home directory, then the relative path would simply be:</p>
<ul>
<li>relative path: <code>paper.txt</code></li>
</ul>
<h2 id="additional-readings"><a class="header" href="#additional-readings">Additional Readings</a></h2>
<p>Read through these two pages for more info on the file system and directories:</p>
<ul>
<li><a href="https://natalieagus.github.io/50005/os/filesystem">UNIX File System</a></li>
<li><a href="https://natalieagus.github.io/50005/os/directories">UNIX Directories</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="files-and-directories"><a class="header" href="#files-and-directories">Files and Directories</a></h1>
<p>In this section, we will cover:</p>
<ol>
<li>
<p><strong>Basic Directory and File Commands</strong>:</p>
<ul>
<li>Overview of GNU Coreutils.</li>
<li>Commands for navigating directories and working with files.</li>
</ul>
</li>
<li>
<p><strong>Directory Listing</strong>:</p>
<ul>
<li><code>ls</code>: List directory contents.</li>
<li>Options for <code>ls</code> (e.g., <code>-l</code>, <code>-a</code>, <code>-al</code>).</li>
<li><code>pwd</code>: Print working directory.</li>
<li>Using <code>man</code> pages for command options.</li>
</ul>
</li>
<li>
<p><strong>Basic File Operations</strong>:</p>
<ul>
<li><code>cp</code>: Copying files and directories.</li>
<li><code>mv</code>: Moving and renaming files and directories.</li>
<li><code>rm</code>: Removing files and directories.</li>
<li><code>touch</code>: Updating file timestamps or creating empty files.</li>
<li>Options for each command, including interactive modes.</li>
</ul>
</li>
<li>
<p><strong>Special File Types</strong>:</p>
<ul>
<li><code>mkdir</code>: Creating directories.</li>
<li><code>rmdir</code>: Deleting empty directories.</li>
<li><code>rm -r</code>: Recursively deleting directories with content.</li>
</ul>
</li>
<li>
<p><strong>Printing Text</strong>:</p>
<ul>
<li><code>echo</code>: Printing text or variables to standard output.</li>
<li><code>cat</code>: Concatenating and printing file contents.</li>
<li><code>less</code>: Viewing file contents one page at a time.</li>
</ul>
</li>
</ol>
<h2 id="basic-directory-and-file-commands"><a class="header" href="#basic-directory-and-file-commands">Basic Directory and File commands</a></h2>
<p>In order to explore the above directories but also to create new ones and work with files, we need to know some basic terminal commands.
A lot of these commands are part of the base system called <a href="https://en.wikipedia.org/wiki/List_of_GNU_Core_Utilities_commands">GNU Coreutils</a>,
and in this demo, we will specifically cover some of the following GNU Coreutils:</p>
<ul>
<li><a href="https://www.gnu.org/software/coreutils/manual/coreutils.html#toc-Directory-listing-1">Directory Listing</a></li>
<li><a href="https://www.gnu.org/software/coreutils/manual/coreutils.html#Basic-operations">Basic Operations</a></li>
<li><a href="https://www.gnu.org/software/coreutils/manual/coreutils.html#Basic-operations">Special File Types</a></li>
<li><a href="https://www.gnu.org/software/coreutils/manual/coreutils.html#Printing-text">Printing Text</a></li>
</ul>
<h3 id="directory-listing"><a class="header" href="#directory-listing">Directory Listing</a></h3>
<blockquote>
<p>I have already demonstrated one command: the <code>cd</code> (change directory) command.
This will be one of the most frequently used commands in your toolbox.</p>
</blockquote>
<p>In our current directory, or once we have changed to a new directory, we will want to learn its contents
(what files and directories it contains).
We have a few commands to choose from to list contents (e.g.,  you have already seen the <code>tree</code> command),
but the most common command is the <code>ls</code> (list) command.
We use it by typing the following two letters in the terminal:</p>
<pre><code>ls
</code></pre>
<p>Again, to confirm that we're in some specific directory, use the <code>pwd</code> command to <strong>print</strong> the <strong>working directory</strong>.</p>
<p>Most commands can be combined with <strong>options</strong>.
Options provide additional functionality to the base command, and in order to see what options are available for the <code>ls</code> command,
we can look at its <strong>man(ual) page</strong>:</p>
<pre><code>man ls
</code></pre>
<p>From the <code>ls</code> <strong>man page</strong>, we learn that we can use the <code>-l</code> option to format the output of the <code>ls</code> command as a long-list,
or a list that provides more information about the files and directories in the working directory.
Later, we will cover more about what the other parts of output of this option mean.</p>
<pre><code>ls -l
</code></pre>
<p>We can use the <code>-a</code> option to list hidden files.
In Linux, hidden files that have names starting with a period.
These files are not visible with the default <code>ls</code> command.
We have a some of those files in our <code>$HOME</code> directories, and we can see them like so:</p>
<pre><code>ls -a
</code></pre>
<p>We can also combine options.
For example, to view all files, including hidden ones, in the long-list format, we can use:</p>
<pre><code>ls -al
</code></pre>
<h2 id="basic-file-operations"><a class="header" href="#basic-file-operations">Basic File Operations</a></h2>
<p>Some basic file operation commands include:</p>
<ul>
<li><code>cp</code>    : copying files and directories</li>
<li><code>mv</code>    : moving (or renaming) files and directories</li>
<li><code>rm</code>    : removing (or deleting) files and directories</li>
<li><code>touch</code> : change file timestamps (or, create a new, empty file)</li>
</ul>
<p>These commands also have various options that can be viewed in their respective <strong>man pages</strong>.
Again, command options provide additional functionality to the base command, and
are mostly (but not always) prepended with a dash and a letter or number.
To see examples, type the following commands, which will launch the manual pages for them.
Press <code>q</code> to exit the manual pages, and use your up and down arrow keys to scroll through the manuals:</p>
<pre><code>man cp
man mv
man rm
man touch
</code></pre>
<p>The <code>touch</code> command's primary use is to change a file's timestamp;
that is, the command updates a file's "access and modification times" (see <code>man touch</code>).
For example, let's say we have a file called <code>paper.txt</code> in our home directory.
We can see the output here:</p>
<pre><code>ls -l paper.txt
-rw-rw-r-- 1 seanburns seanburns 0 Jun 27 00:13 /home/seanburns/paper.txt
</code></pre>
<p>This shows that the last modification time was 12:03AM on June 27.</p>
<p>If I run the touch command on <code>paper.txt</code>, the timestamp will change:</p>
<pre><code>touch paper.txt
-rw-rw-r-- 1 seanburns seanburns 0 Jun 27 00:15 /home/seanburns/paper.txt
</code></pre>
<p>This shows an updated modification timestamp of 12:15AM.</p>
<p>The side effect occurs when we name a file with the <code>touch</code> command, but the file does not exist,
in which case the <code>touch</code> command will create an empty file with the name we use.</p>
<p>Let's say that I do <strong>not</strong> have a file named <code>file.txt</code> in my home directory.
If I run the <code>ls -l file.txt</code> command, I'll receive an error since the file does not exist.
But if I then use the <code>touch file.txt</code> command, and then run <code>ls -l file.txt</code>, we'll see that the file now exists,
that it has a byte size of zero:</p>
<pre><code>ls -l file.txt
ls: cannot access 'file.txt': No such file or directory
touch file.txt
ls -l file.txt
-rw-rw-r-- 1 sean sean 0 Jun 27 00:18 file.txt
</code></pre>
<p>Here are some ways to use the other three commands and their options:</p>
<h3 id="copying-files-and-directories"><a class="header" href="#copying-files-and-directories">Copying Files and Directories</a></h3>
<p>To copy an existing file (<code>file1.txt</code>) to a new file (<code>file2.txt</code>):</p>
<pre><code>cp file1.txt file2.txt
</code></pre>
<p>Use the <code>-i</code> option to copy that file in interactive mode; that is, to prompt you before overwriting an existing file.</p>
<p>We also use the <code>cp</code> command to copy directories.</p>
<h3 id="moving-files-and-directories"><a class="header" href="#moving-files-and-directories">Moving Files and Directories</a></h3>
<p>The <code>mv</code> command will move an existing file to a different directory, and/or rename the file.
For example, from within our home directory (therefore, using relative path names), to move a file named <code>file.docx</code>
to a subdirectory named <code>Documents</code>:</p>
<pre><code>mv file.docx Documents/
</code></pre>
<p>To rename a file only (keeping it in the same directory), the command looks like this:</p>
<pre><code>mv file.docx new_name.docx
</code></pre>
<p>To move the file to our <code>Documents/</code> subdirectory and also rename it, then we'd do this:</p>
<pre><code>mv file.docx Documents/new_name.docx
</code></pre>
<p>The <code>man</code> page for the <code>mv</code> command also describes an <code>-i</code> option for interactive mode that helps prevent us from overwriting existing files.
For example, if we have a file called <code>paper.docx</code> in our <code>$HOME</code> directory, and
we have a file named <code>paper.docx</code> in our <code>$HOME/Documents</code> directory, and if these are actually two different papers (or files),
then moving the file to that directory will overwrite it without asking.
The <code>-i</code> option will prompt us first:</p>
<pre><code>mv -i paper.docx Documents/paper.docx
</code></pre>
<h3 id="remove-or-delete"><a class="header" href="#remove-or-delete">Remove or Delete</a></h3>
<p>Finally, to delete a file, we use the <code>rm</code> command:</p>
<pre><code>rm file.html
</code></pre>
<blockquote>
<p>Unlike the trash bin in your graphical user environment, it's hard to recover a deleted file using the <code>rm</code> command.
That is, using <code>rm</code> does not mean the file or directory is <strong>trashed</strong>; rather, it means it was <strong>deleted</strong>.</p>
</blockquote>
<h2 id="special-file-types"><a class="header" href="#special-file-types">Special File Types</a></h2>
<p>For now, let's only cover two commands here:</p>
<ul>
<li><code>mkdir</code> for creating a new directory</li>
<li><code>rmdir</code> for deleting an empty directory</li>
</ul>
<p>Like the above commands, these commands also have their own set of options that can be viewed in their respective <strong>man pages</strong>:</p>
<pre><code>man mkdir
man rmdir
</code></pre>
<h3 id="make-or-create-a-new-directory"><a class="header" href="#make-or-create-a-new-directory">Make or Create a New Directory</a></h3>
<p>We use these commands like we do the ones above.
If we are in our <code>$HOME</code> directory, and we want to create a new directory called <code>bin</code>, we do:</p>
<pre><code>mkdir bin 
</code></pre>
<blockquote>
<p>The <code>bin</code> directory in our <code>$HOME</code> directory is a default location to store our personal applications, or
applications (programs) that are only available to us.</p>
</blockquote>
<p>And if we run <code>ls</code>, we should see that it was successful.</p>
<h3 id="delete-a-directory"><a class="header" href="#delete-a-directory">Delete a Directory</a></h3>
<p>The <code>rmdir</code> command is a bit weird because it only removes <strong>empty</strong> directories.
To remove the directory we just created, we use it like so:</p>
<pre><code>rmdir bin 
</code></pre>
<p>However, if you want to remove a directory that contains files or other subdirectories,
then you will have to use the <code>rm</code> command along with the <code>-r</code> (recursive) option:</p>
<pre><code>rm -r directory-with-content/
</code></pre>
<h2 id="printing-text"><a class="header" href="#printing-text">Printing Text</a></h2>
<p>There a number of ways to print text to <strong>standard output</strong>, which is our screen by default in the terminal.
We could also redirect standard output to a file, to a printer, or to a remote shell.
We'll see examples like that later.
Here let's cover two commands:</p>
<ul>
<li><code>echo</code> : to print a line of text to standard output</li>
<li><code>cat</code>  : to concatenate and write files</li>
<li><code>less</code> : to view files one page at a time</li>
</ul>
<blockquote>
<p><strong>Standard output</strong> is by default the screen.
When we <strong>print</strong> to standard output, then by default we print to the screen.
However, standard output can be <strong>redirected</strong> to files, programs, or devices, like actual printers.</p>
</blockquote>
<h3 id="print-to-screen"><a class="header" href="#print-to-screen">Print to Screen</a></h3>
<p>To use <code>echo</code>:</p>
<pre><code>echo "hello world"
echo "Today is a good day."
</code></pre>
<p>We can also <code>echo</code> variables:</p>
<pre><code>a=4
echo "$a"
</code></pre>
<h3 id="print-file-to-screen"><a class="header" href="#print-file-to-screen">Print File to Screen</a></h3>
<p><code>cat</code> is listed elsewhere in the GNU Coreutils page.
The primary use of the <code>cat</code> command is to join, combine, or concatenate files, but if used on a single file,
it has this nice side effect of printing the content of the file to the screen:</p>
<pre><code>cat file.html
</code></pre>
<p>If the file is very long, we might want to use what's called a <strong>pager</strong>.
There are a few pagers to use, but the <code>less</code> command is a common one:</p>
<pre><code>less file.html
</code></pre>
<p>Like with the <strong>man pages</strong>, use the up and down arrow keys to scroll through the output, and press <code>q</code> to quit the pager.</p>
<h2 id="conclusion-3"><a class="header" href="#conclusion-3">Conclusion</a></h2>
<p>In this demo, we learned about the filesystem or directory structure of Linux,
and we also learned some basic command to work with directories and files.
You should practice using these commands as much as possible.
The more you use them, the easier it'll get.
Also, be sure to review the <strong>man pages</strong> for each of the commands, especially to see what options are available for each of them.</p>
<p>Basic commands covered in this demo include:</p>
<ul>
<li><code>cat</code>   : display contents of a file</li>
<li><code>cp</code>    : copy</li>
<li><code>echo</code>  : print a line of text</li>
<li><code>less</code>  : display contents of a file by page</li>
<li><code>ls</code>    : list</li>
<li><code>man</code>   : manual pages</li>
<li><code>mkdir</code> : create a directory</li>
<li><code>mv</code>    : move or rename</li>
<li><code>pwd</code>   : print name of current/working directory</li>
<li><code>rmdir</code> : delete an empty directory</li>
<li><code>rm</code>    : remove or delete a file or directory</li>
<li><code>tree</code>  : list contents of directories in a tree-like format</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="file-permissions-and-ownership"><a class="header" href="#file-permissions-and-ownership">File Permissions and Ownership</a></h1>
<p>In this section, we will cover:</p>
<ol>
<li>
<p><strong>Identifying Ownership and Permissions</strong>:</p>
<ul>
<li>Overview of file ownership (user and group ownership).</li>
<li>Understanding file permissions (read, write, execute).</li>
<li>Using <code>ls -l</code> to view ownership and permissions.</li>
<li>Explanation of how to interpret the output of <code>ls -l</code>.</li>
</ul>
</li>
<li>
<p><strong>Changing File Permissions</strong>:</p>
<ul>
<li>Using <code>chmod</code> to change file permissions.</li>
<li>Explanation of octal values for permissions (<code>rwx</code> and their octal equivalents).</li>
<li>Examples of setting permissions using <code>chmod</code> with octal notation (e.g., <code>chmod 700</code>, <code>chmod 644</code>).</li>
</ul>
</li>
<li>
<p><strong>Changing File Ownership</strong>:</p>
<ul>
<li>Using <code>chown</code> to change file ownership (user and group).</li>
<li>Examples of changing user ownership and group ownership separately and together.</li>
<li>Usage of <code>sudo</code> to execute administrative commands when needed.</li>
</ul>
</li>
<li>
<p><strong>Additional Commands</strong>:</p>
<ul>
<li><code>ls -ld</code>: List directories and their attributes.</li>
<li><code>groups</code>: Show group memberships for a user.</li>
<li><code>sudo</code>: Run commands as another user with elevated privileges.</li>
</ul>
</li>
</ol>
<h2 id="identifying-permissions-and-ownership"><a class="header" href="#identifying-permissions-and-ownership">Identifying Permissions and Ownership</a></h2>
<p>In the last section, we saw that the output of the <code>ls -l</code> command included a lot extra information besides a listing of file names.
The output also listed the owners and permissions for each file and directory.</p>
<p>Each user account on a Linux system has a user name and has at least one group membership.
That name and that group membership determine the user and group ownership for all files created under that account.</p>
<p>In order to allow or restrict access to files and directories,
ownership and permissions are set in order to manage that kind of access to those files and directories.
There are thus two owners for every file and directory:</p>
<ul>
<li>user owner</li>
<li>group owner</li>
</ul>
<p>And there are three permission <em>modes</em> that restrict or expand access to each file (or directory) based on user or group membership:</p>
<ul>
<li><strong>r</strong>ead</li>
<li><strong>w</strong>rite</li>
<li>e<strong>x</strong>ecute</li>
</ul>
<blockquote>
<p>I am emphasizing the <strong>rwx</strong> in the above list of modes because we will need to remember what these letters stand for when
we work with file and directory permissions.</p>
</blockquote>
<p>Consider the output of <code>ls -l</code> in my home directory that contains a file called <strong>paper.txt</strong>:</p>
<pre><code>-rw-rw-r-- 1 seanburns seanburns 0 Sep  7 14:41 paper.txt
</code></pre>
<p>According to the above output, we can parse the following information about the file:</p>
<div class="table-wrapper"><table><thead><tr><th>Attributes</th><th><code>ls -l</code> output</th></tr></thead><tbody>
<tr><td>File permissions</td><td><code>-rw-rw-r--</code></td></tr>
<tr><td>Number of links</td><td>1</td></tr>
<tr><td>Owner name</td><td>seanburns</td></tr>
<tr><td>Group name</td><td>seanburns</td></tr>
<tr><td>Byte size</td><td>0</td></tr>
<tr><td>Last modification date</td><td>Sep  7 14:41</td></tr>
<tr><td>File name</td><td>paper.txt</td></tr>
</tbody></table>
</div>
<p>The Owner and Group names of the <code>paper.txt</code> file are both <code>seanburns</code> because
there is a user account named <code>seanburns</code> on the system and
a group account named <code>seanburns</code> on the system, and that file exists in the user <code>seanburns</code>'s home directory.
You can see which groups you belong to on your system with the <code>groups</code>.</p>
<p>The <strong>File permissions</strong> show:</p>
<pre><code>-rw-rw-r--
</code></pre>
<p>Ignore the first dash for now.
The remaining permissions can be broken down into three parts:</p>
<ul>
<li>rw- (read and write only permissions for the Owner)</li>
<li>rw- (read and write only permissions for the Group)</li>
<li>r-- (read-only permissions for the other, or World)</li>
</ul>
<p>We read the output as such:</p>
<ul>
<li>User <strong>seanburns</strong> is the Owner and has <strong>r</strong>ead and <strong>w</strong>rite permissions on the file but not e<strong>x</strong>ecute permissions (<code>rw-</code>).</li>
<li>Group <strong>seanburns</strong> is the Group owner and has <strong>r</strong>ead and <strong>w</strong>rite permissions on the file but not e<strong>x</strong>ecute permissions (<code>rw-</code>).</li>
<li>The <strong>Other/World</strong> can <strong>r</strong>ead the file but cannot <strong>w</strong>rite to the file nor e<strong>x</strong>ecute the file (<code>r--</code>).</li>
</ul>
<blockquote>
<p>The word <strong>write</strong> is a classical computing term that means, essentially, to edit and save edits of a file.
Today we use the term <strong>save</strong> instead of <strong>write</strong>, but remember that they are basically equivalent terms.</p>
</blockquote>
<p>The <strong>Other/World</strong> ownership allows people to view (read) the file but not write (save) to it nor execute (run) it.
Any webpage you view on the internet at least has Other/World mode set to read.</p>
<p>Let's take a look at another file.
In our <code>/bin</code> directory, we can see a listing of executable programs on the system.
For example, take a look at the <code>scp</code> (secure copy) program as follows:</p>
<pre><code>ls -l /bin/scp
-rwxr-xr-x 1 root   root    133720 Apr  11 /bin/scp*
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Attributes</th><th><code>ls -l</code> output</th></tr></thead><tbody>
<tr><td>File permissions</td><td><code>-rwxr-xr-x</code></td></tr>
<tr><td>Number of links</td><td>1</td></tr>
<tr><td>Owner name</td><td>root</td></tr>
<tr><td>Group name</td><td>root</td></tr>
<tr><td>Byte size</td><td>133720</td></tr>
<tr><td>Last modification date</td><td>Apr 11 2025</td></tr>
<tr><td>File name</td><td>/bin/scp</td></tr>
</tbody></table>
</div>
<p>Since <code>scp</code> is a computer program used to securely copy files between different machines, it needs to be e<strong>x</strong>ecutable.
That is, users on the system need to be able to run it.
But notice that the owner and group names of the file point to the user <code>root</code>.
We have already learned that there is a <code>root</code> directory in our filesystem.
This is the top level directory in our filesystem and is referenced by the forward slash: <code>/</code>.
But there is also a <code>root</code> user account.
This is the system's <strong>superuser</strong>.
The <strong>superuser</strong> can run or access anything on the system, and this user also owns most of the system files.</p>
<p>Back to permissions. We read the output of the <code>ls -l /bin/scp</code> command as such:</p>
<ul>
<li>User <strong>root</strong> is the Owner and has <strong>r</strong>ead, <strong>w</strong>rite, and e<strong>x</strong>ecute (<code>rwx</code>) permissions on the file.</li>
<li>Group <strong>root</strong> is the Group owner and has <strong>r</strong>ead and e<strong>x</strong>ecute permissions but not <strong>w</strong>rite permissions (<code>r-x</code>)</li>
<li>The <strong>Other/World</strong> has <strong>r</strong>ead and e<strong>x</strong>ecute permissions but not <strong>w</strong>rite (<code>r-x</code>).
This permissions allows other users (like you and me) to use the <code>scp</code> program.</li>
</ul>
<p>Finally, let's take a look at the permissions for a directory itself.
When I run the following command in my home directory, it will show the permissions for my <code>/home/seanburns</code> directory:</p>
<pre><code>ls -ld
</code></pre>
<p>And the output is:</p>
<pre><code>drwxr-x--- 4 seanburns seanburns 4096 Sep  2 19:07 .
</code></pre>
<p>This shows that:</p>
<div class="table-wrapper"><table><thead><tr><th>Attributes</th><th><code>ls -ld</code> output</th></tr></thead><tbody>
<tr><td>File permissions</td><td><code>drwxr-x---</code></td></tr>
<tr><td>Number of links</td><td>4</td></tr>
<tr><td>Owner name</td><td>seanburns</td></tr>
<tr><td>Group name</td><td>seanburns</td></tr>
<tr><td>Byte size</td><td>4096</td></tr>
<tr><td>Last modification date</td><td>Sep  2</td></tr>
<tr><td>File name</td><td>.</td></tr>
</tbody></table>
</div>
<p>This is a little different from the previous examples, but let's parse it:</p>
<ul>
<li>Instead of an initial dash, this <em>file</em> has an initial <strong>d</strong> that identifies this as a directory.
Directories in Linux are simply special types of files.</li>
<li>User <code>seanburns</code> has read, write, and execute (<code>rwx</code>) permissions.</li>
<li>Group <code>seanburns</code> have execute (<code>r-x</code>) read and execute permissions.</li>
<li><code>Other/World</code> have no permisisons on this directory.</li>
<li><code>.</code> signifies the current directory, which happens to be my home directory, since I ran that command at the <code>/home/seanburns</code> path.</li>
</ul>
<p>Why does the directory have an e<strong>x</strong>ecutable bit set since it's not a program?
The executable bit is required on directories to access them.
That is, if we want to <code>cd</code> into a directory, then the executable bit needs to be set on the directory.</p>
<h2 id="changing-file-permissions-and-ownership"><a class="header" href="#changing-file-permissions-and-ownership">Changing File Permissions and Ownership</a></h2>
<h3 id="changing-file-permissions"><a class="header" href="#changing-file-permissions">Changing File Permissions</a></h3>
<p>All the files and directories on a Linux system have default ownership and permissions set.
This includes new files that we might create as we use our systems.
There will be times when we will want to change the defaults.
For example, if I were to create accounts for other people for this system, I might want to disallow them access to my home directory.
There are several commands available to do that, and here I'll introduce you to the two most common ones.</p>
<ol>
<li>The <code>chmod</code> command is used to change file and directory permissions: the <code>-rwxrwxrwx</code> part of a file.</li>
<li>The <code>chown</code> command is used to change a file's and directory's owner and group.</li>
</ol>
<h4 id="chmod"><a class="header" href="#chmod"><code>chmod</code></a></h4>
<p>Each one of those bits (the <code>r</code>, the <code>w</code>, and the <code>x</code>) are assigned the following <a href="https://docs.oracle.com/cd/E19504-01/802-5750/6i9g464pv/index.html">octal</a> values:</p>
<div class="table-wrapper"><table><thead><tr><th>permission</th><th>description</th><th>octal value</th></tr></thead><tbody>
<tr><td>r</td><td>read</td><td>4</td></tr>
<tr><td>w</td><td>write</td><td>2</td></tr>
<tr><td>x</td><td>execute</td><td>1</td></tr>
<tr><td>-</td><td>no permissions</td><td>0</td></tr>
</tbody></table>
</div>
<p>There are octal values for the three set of permissions represented by <code>-rwxrwxrwx</code>.
If I bracket the sets (for demonstration purposes only), they look like this:</p>
<div class="table-wrapper"><table><thead><tr><th>Owner</th><th>Group</th><th>Other/World</th></tr></thead><tbody>
<tr><td>rwx-</td><td>rwx-</td><td>rwx-</td></tr>
<tr><td>4210</td><td>4210</td><td>4210</td></tr>
</tbody></table>
</div>
<p>The first set describes the permissions for the owner.
The second set describes the permissions for the group.
The third set describes the permissions for the Other/World.</p>
<p>We use the <code>chmod</code> command and the octal values to change a file or directory's permissions.
For each set, we add up the octal values.
For example, to make a file read (4), write (2), and executable (1) for the owner only, and
zero out the permissions for the group and Other/World, we use the <code>chmod</code> command like so:</p>
<pre><code>chmod 700 paper.txt
</code></pre>
<p>We use 7 because <code>4+2+1=7</code>, and we use two zeroes in the second two places since we're removing permissions for group and Other/World.</p>
<p>If we want to make the file read, write, and executable by the owner, the group, and the world, then we repeat this for each set:</p>
<pre><code>chmod 777 paper.txt
</code></pre>
<p>More commonly, we might want to restrict ownership.
Here we enable <code>rw-</code> for the owner, and <code>r--</code> for the group and the Other/World:</p>
<pre><code>chmod 644 paper.txt
</code></pre>
<p>Because <code>4+2=6</code> for owner, and <code>4</code> is read only for group and Other/World, respectively.</p>
<h3 id="changing-file-ownership"><a class="header" href="#changing-file-ownership">Changing File Ownership</a></h3>
<h4 id="chown"><a class="header" href="#chown"><code>chown</code></a></h4>
<p>In order to change the ownership of a file, we use the <code>chown</code> command followed by the name of the owner.</p>
<p>I can generally only change the user owner of a file if I have admin access on a system.
In such a case, I would have to use the <code>sudo</code> command, which gives me superuser privileges.
To change the owner only, say from the user <code>seanburns</code> to the user <code>root</code>:</p>
<pre><code>sudo chown root paper.txt
</code></pre>
<p>In the following example, I make the <code>root</code> user the group owner of my <code>paper.txt</code> file.
Note that I include a colon before the name <code>root</code>.
This signifies changing group membership only.</p>
<pre><code>sudo chown :root paper.txt
</code></pre>
<blockquote>
<p>Look at the output as you go using the <code>ls -l</code> command.</p>
</blockquote>
<p>To change both user owner and group owner, we simply specify both names and separate those names by a colon.
Thus, since <code>paper.txt</code> now has <code>root</code> as the user owner and <code>root</code> as the group owner,
I revert ownership back to me for both user and group:</p>
<pre><code>sudo chown sean:sean paper.txt
</code></pre>
<h2 id="conclusion-4"><a class="header" href="#conclusion-4">Conclusion</a></h2>
<p>In this section, we learned:</p>
<ul>
<li>how to identify file/directory ownership and permissions</li>
<li>and how to change file/directory ownership and permissions.</li>
</ul>
<p>The commands we used to change these include:</p>
<ul>
<li><code>chmod</code> : for changing file permissions (or file mode bits)</li>
<li><code>chown</code> : for changing file ownership</li>
</ul>
<p>We also used the following commands:</p>
<ul>
<li><code>ls</code>         : list directory contents
<ul>
<li><code>ls -ld</code> : long list directories themselves, not their contents</li>
</ul>
</li>
<li><code>groups</code>     : print the groups a user is in</li>
<li><code>sudo</code>       : execute a command as another user</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="text-processing-part-1"><a class="header" href="#text-processing-part-1">Text Processing: Part 1</a></h1>
<p>In this section, we will cover</p>
<ol>
<li><strong>Text processing tools are fundamental</strong>: Learning to process and
manipulate text is a crucial skill for systems administrators, programmers,
and data analysts. Linux provides a variety of tools to examine, manipulate,
and analyze text.</li>
<li><strong>Plain text is foundational</strong>: Programs and data are often stored in plain
text, making it essential to know how to handle text files effectively.</li>
<li><strong>Essential text processing commands</strong>: Commands such as <code>cat</code>, <code>cut</code>,
<code>head</code>, <code>tail</code>, <code>sort</code>, <code>uniq</code>, and <code>wc</code> allow users to view, manipulate,
and analyze text files, even large datasets, with ease.</li>
<li><strong>Power of pipes and redirection</strong>: Using pipes (<code>|</code>) and redirection (<code>&gt;</code>,
<code>&gt;&gt;</code>), you can chain commands together to create more complex workflows for
processing text files.</li>
<li><strong>CSV data manipulation</strong>: This lecture shows how to work with CSV
(comma-separated value) files, demonstrating how to view, sort, and filter
data with tools like <code>cut</code> and <code>uniq</code>.</li>
<li><strong>Practical applications for systems administration</strong>: The lecture
emphasizes that text processing skills are directly applicable to managing
user accounts, security, system configuration, and more in a systems
administration context.</li>
</ol>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<p>One of the more important sets of tools that Linux (as well Unix-like)
operating systems provide are tools that
<a href="https://tldp.org/LDP/abs/html/textproc.html">aid processing and manipulating text</a>.
The ability to process and manipulate text, programmatically,
is a basic and essential part of many programming languages,
(e.g., Python, JavaScript, etc),
and learning how to process and manipulate text is
an important skill for a variety of jobs including
statistics, data analytics, data science, programming, web programming,
systems administration, and so forth.
In other words,
this functionality of Linux (and Unix-like) operating systems
essentially means that to learn Linux and the tools that it provides
is akin to learning how to program.</p>
<blockquote>
<p>Plain text files are the basic building blocks of programs and data.
Programs are written in plain text editors (Vim, NeoVim, VS Code, etc), and
data is often stored as plain text.
Linux offers many tools to examine, manipulate, process, analyze,
and visualize data in plain text files.</p>
</blockquote>
<p>In this section, we will learn some of the basic
tools to examine plain text (i.e., data).
We will do some programming later in this class, but for us,
the main objective with learning to program
aligns with our work as systems administrators.
That means our text processing and programming goals will serve our interests
in managing users, security, networking, system configuration, and so forth
as Linux system administrators.</p>
<p>In the meantime, the goal of this section is to acquaint ourselves with
some of the tools that can be used to process text.
In this section, we will only cover a handful of text processing
programs or utilities,
but here is a fairly comprehensive list,
and we'll examine some additional ones from this list
later in the semester:</p>
<ul>
<li><code>cat</code>      : concatenate files and print on the standard output</li>
<li><code>cut</code>      : remove sections from each line of files</li>
<li><code>diff</code>     : compare files line by line</li>
<li><code>echo</code>     : display a line of text</li>
<li><code>expand</code>   : convert tabs to spaces</li>
<li><code>find</code>     : search for files in a directory hierarchy</li>
<li><code>fmt</code>      : simple optimal text formatter</li>
<li><code>fold</code>     : wrap each input line to fit in specified width</li>
<li><code>grep</code>     : print lines that match patterns</li>
<li><code>head</code>     : output the first part of files</li>
<li><code>join</code>     : join lines of two files on a common field</li>
<li><code>look</code>     : display lines beginning with a given string</li>
<li><code>nl</code>       : number lines of files</li>
<li><code>paste</code>    : merge lines of files</li>
<li><code>printf</code>   : format and print data</li>
<li><code>shuf</code>     : generate random permutations</li>
<li><code>sort</code>     : sort lines of text files</li>
<li><code>tail</code>     : output the last part of files</li>
<li><code>tr</code>       : translate or delete characters</li>
<li><code>unexpand</code> : convert spaces to tabs</li>
<li><code>uniq</code>     : report or omit repeat lines</li>
<li><code>wc</code>       : print newline, word, and byte counts for each file</li>
</ul>
<p>We will also discuss two types of operators, the pipe and the redirect.
The latter has a version that will write over the contents of a file,
and a version that will append contents to the end of a file:</p>
<ul>
<li><code>|</code> : redirect standard output from command1 to standard input for command2</li>
<li><code>&gt;</code> : redirect to standard output to a file, overwriting</li>
<li><code>&gt;&gt;</code> : redirect to standard output to a file, appending</li>
</ul>
<p>Today I want to cover a few of the above commands for processing data in a file;
specifically:</p>
<ul>
<li><code>cat</code>  : concatenate files and print on the standard output</li>
<li><code>cut</code>  : remove sections from each line of files</li>
<li><code>head</code> : output the first part of files</li>
<li><code>sort</code> : sort lines of text files</li>
<li><code>tail</code> : output the last part of files</li>
<li><code>uniq</code> : report or omit repeat lines</li>
<li><code>wc</code>   : print newline, word, and byte counts for each file</li>
</ul>
<p>Let's look at a toy, sample file that contains structured data as a CSV (comma separated value) file.
You can download the file to your <code>gcloud</code> virtual machine using the following command:</p>
<pre><code>wget https://raw.githubusercontent.com/cseanburns/linux_sysadmin/master/data/operating-systems.csv
</code></pre>
<p>The file contains a list of operating systems (column one), their software license (column two), and the year the OSes were released (column three).
We can use the <code>cat</code> command to view the entire contents of this small file:</p>
<p><strong>Command:</strong></p>
<pre><code>cat operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>It's a small file, but we might want the line and word count of the file.
To acquire that, we can use the <code>wc</code> (word count) command.
By itself, the <code>wc</code> command will print  the number of lines, words, and bytes of a file.
The following output states that the file contains seven lines, 23 words, and 165 bytes:</p>
<p><strong>Command:</strong></p>
<pre><code>wc operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>  7  23 165 operating-systems.csv
</code></pre>
<p>We can use the <code>head</code> command to output the first ten lines of a file.
Since our file is only seven lines long,
we can use the <code>-n</code> option  to change the default number of lines.
In the following example, I print the first three lines of the file:</p>
<p><strong>Command:</strong></p>
<pre><code>head -n3 operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
</code></pre>
<p>Using the <code>cut</code> command, we can select data from file.
In the first example, I want to select column two (or field two), which contains the license information.
Since this is a CSV file, the fields (aka, columns) are separated by commas.
Therefore I use <code>-d</code> option to instruct the <code>cut</code> command to use commas as the separating character.
The <code>-f</code> option tells the <code>cut</code> command to select field two.
Note that a CSV file may use other characters as the separator character, like the Tab character or a colon.
In such cases, it may still be called a CSV file but you might also see <code>.dat</code> files for data files or other variations.</p>
<p><strong>Command:</strong></p>
<pre><code>cut -d"," -f2 operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code> Proprietary
 BSD
 GPL
 Proprietary
 Proprietary
 Proprietary
 Apache
</code></pre>
<p>From there it's trivial to select a different column.
In the next example, I select column three to get the release year:</p>
<p><strong>Command:</strong></p>
<pre><code>cut -d"," -f3 operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code> 2009
 1993
 1991
 2007
 2001
 1993
 2008
</code></pre>
<p>A genius aspect of the Linux (and Unix) commandline is the ability to <strong>pipe</strong> and <strong>redirect</strong> output from one program to another program.
Output can be further directed to a file.
By stringing together multiple programs in this way, we can create small programs that do much more than the simple programs that compose them.</p>
<p>For example, in the following example, I use the pipe operators to send the output of the <code>cut</code> command to the <code>sort</code> command.
This sorts the data in alphabetical or numerical order, depending on the character type (lexical or numerical).
I then pipe that output to the <code>uniq</code> command, which removes duplicate rows.
Finally, I redirect that final output to a new file titled <strong>os-years.csv</strong>.
Since the year <strong>1993</strong> appears twice in the original file, it only appears once in the output because the <code>uniq</code> command removed the duplicate:</p>
<p><strong>Command:</strong></p>
<pre><code>cut -d"," -f3 operating-systems.csv | sort | uniq &gt; os-years.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>cat os-years.csv
 1991
 1993
 2001
 2007
 2008
 2009
</code></pre>
<p>Data files like this often have a header line at the top row that names the data columns.
It's useful to know how to work with such files, so let's add a header row to the top of the file.
In this example, I'll use the <code>sed</code> command, which we will learn more about in the next lesson.
For now, we use <code>sed</code> with the option <code>-i</code> to edit the file, then <code>1i</code> instructs <code>sed</code> to <strong>insert</strong> text at <strong>line 1</strong>.
<code>\OS, License, Year</code> is the text that we want inserted at line 1.
We wrap the argument within single quotes:</p>
<p><strong>Command:</strong></p>
<pre><code>sed -i '1i \OS, License, Year' operating-systems.csv
cat operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>I added the header row just to demonstrate how to remove it when processing files with header rows.
Say we want the license field data, but we need to remove that first line.
In this case, we can use the tail command:</p>
<p><strong>Command:</strong></p>
<pre><code>tail -n +2 operating-systems.csv | cut -d"," -f2 | sort | uniq &gt; license-data.csv
cat license-data.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code> Apache
 BSD
 GPL
 Proprietary
</code></pre>
<blockquote>
<p>The <code>tail</code> command generally outputs the last lines of a file, but the <code>-n +2</code> option is special.
It makes the <code>tail</code> command output a file starting at the second line.
We could specify a different number in order to start output at a different line.
See <code>man tail</code> for more information.</p>
</blockquote>
<h2 id="conclusion-5"><a class="header" href="#conclusion-5">Conclusion</a></h2>
<p>In this lesson, we learned how to process and make sense of data held in a text file.
We used some commands that let us select, sort, de-duplicate, redirect, and view data in different ways.
Our data file was a small one, but these are powerful and useful command and operators that would make sense of large data file.</p>
<p>The commands we used in this lesson include:</p>
<ul>
<li><code>cat</code>  : concatenate files and print on the standard output</li>
<li><code>cut</code>  : remove sections from each line of files</li>
<li><code>head</code> : output the first part of files</li>
<li><code>sort</code> : sort lines of text files</li>
<li><code>tail</code> : output the last part of files</li>
<li><code>uniq</code> : report or omit repeat lines</li>
<li><code>wc</code>   : print newline, word, and byte counts for each file</li>
</ul>
<p>We also used two types of operators, the pipe and the redirect:</p>
<ul>
<li><code>|</code> : redirect standard output command1 to standard input of command2</li>
<li><code>&gt;</code> : redirect to standard output to a file, overwriting</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="text-processing-part-2"><a class="header" href="#text-processing-part-2">Text Processing: Part 2</a></h1>
<p>In this section, we will cover:</p>
<ol>
<li><strong>Expanding the toolbox</strong>: This section introduces more powerful text
processing utilities: <code>grep</code>, <code>sed</code>, and <code>awk</code>, which are essential for
advanced pattern matching, filtering, and text manipulation on the Linux
command line.</li>
<li><strong><code>grep</code> for pattern matching</strong>: The <code>grep</code> command allows you to search for
patterns in files and output matching lines. You can perform
case-insensitive searches, invert matches, count occurrences, and use
regular expressions to refine your searches.</li>
<li><strong><code>sed</code> for stream editing</strong>: <code>sed</code> is a non-interactive text editor
designed for filtering and transforming text. You can delete, replace, and
manipulate specific lines in a file, making it a powerful tool for batch
text processing tasks.</li>
<li><strong><code>awk</code> for structured data</strong>: <code>awk</code> is a complete scripting language for
pattern scanning and processing columns of structured data. It can handle
arithmetic, generate reports, and perform logical comparisons, making it
ideal for working with CSVs and other structured text files.</li>
<li><strong>Efficiency with one-liners</strong>: The combination of <code>grep</code>, <code>sed</code>, and <code>awk</code>
allows for creating powerful one-liner commands to process large amounts of
text quickly, reducing the need for more complex scripts.</li>
<li><strong>Regular expressions are key</strong>: Regular expressions (<strong>regex</strong>) play a
significant role in refining searches and manipulations in both <code>grep</code> and
<code>sed</code>. Understanding basic regex patterns, such as <code>^</code> for line start and
<code>$</code> for line end, is crucial for effective text processing.</li>
<li><strong>Integration with other tools</strong>: Like the tools introduced in Part 1,
<code>grep</code>, <code>sed</code>, and <code>awk</code> integrate well with pipes and redirection, allowing
you to chain them with other commands for flexible and efficient text
workflows.</li>
</ol>
<h2 id="getting-started-1"><a class="header" href="#getting-started-1">Getting Started</a></h2>
<p>In the last section, we covered the <code>cat</code>, <code>cut</code>, <code>head</code>, <code>sort</code>, <code>tail</code>, <code>uniq</code>, and <code>wc</code> utilities.</p>
<p>We also learned about the <code>|</code> pipe operator.
The pipe operator is used to redirect <strong>standard output</strong> from one command to a second command.
Then the second command can process the output from the first command.
An example is:</p>
<pre><code>sort file.txt | uniq
</code></pre>
<p>This sorts the lines in a file named <strong>file.txt</strong> and then prints to standard output only the unique lines
Note that files must be sorted before piped to <code>uniq</code>.</p>
<p>We learned about the <code>&gt;</code> and <code>&gt;&gt;</code> redirect operators.
They work like the pipe operator, but instead of directing output to a new command, they direct output to a file for saving.
As a reminder, the single redirect <code>&gt;</code> overwrites a file or creates a file if it does not exist.
The double redirect <code>&gt;&gt;</code> appends to a file or creates a file if it does not exist.
It's safer to use the double redirect, but if you are processing large amounts of data, it could also mean creating large files really quickly.
If that gets out of hand, then you might crash your system.
To build on our prior example, we can add <code>&gt;&gt;</code> to send the output to a new file called <strong>output.txt</strong>:</p>
<pre><code>sort file.txt | uniq &gt;&gt; output.txt
</code></pre>
<p>We have available more powerful utilities and programs to process, manipulate, and analyze text files.
In this section, we will cover the following three of these:</p>
<ul>
<li><code>grep</code> : print lines that match patterns</li>
<li><code>sed</code>  : stream editor for filtering and transforming text</li>
<li><code>awk</code>  : pattern scanning and text processing language</li>
</ul>
<h2 id="grep"><a class="header" href="#grep">Grep</a></h2>
<p>The <code>grep</code> command is one of my most often used commands.
Basically, <code>grep</code> "prints lines that match patterns" (see <code>man grep</code>).
In other words, it's search, and it's super powerful.</p>
<p><code>grep</code> works line by line.
So when we use it to search a file for a <strong>string</strong> of text, it will return the whole line that matches the string.
This <strong>line by line</strong> idea is part of the history of Unix-like operating systems.
It's super important to remember that most utilities and programs that we use on the commandline are line oriented.</p>
<blockquote>
<p>"A string is any series of characters that are interpreted literally by a
script. For example, 'hello world' and 'LKJH019283' are both examples of
strings." -- <a href="https://www.computerhope.com/jargon/s/string.htm">Computer Hope</a>. More generally, it's the literal
characters that we type. It's data.</p>
</blockquote>
<p>Let's consider the file <strong>operating-systems.csv</strong>, as seen below:</p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>If we want to search for the string <strong>Chrome</strong>, we can use <code>grep</code>.
Notice that even though the string <strong>Chrome</strong> only appears once, and in one part of a line, <code>grep</code> returns the entire line.</p>
<p><strong>Command:</strong></p>
<pre><code>grep "Chrome" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
</code></pre>
<p>Be aware that, by default, <code>grep</code> is case-sensitive, which means a search for the string <strong>chrome</strong>, with a lower case <strong>c</strong>, would return no results.
Fortunately, <code>grep</code> has an <code>-i</code> option, which means to ignore the case of the search string.
In the following examples, <code>grep</code> returns nothing in the first search since we do not capitalize the string <strong>chrome</strong>.
However, adding the <code>-i</code> option results in success:</p>
<p><strong>Command:</strong></p>
<pre><code>grep "chrome" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<p>None.</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i "chrome" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
</code></pre>
<p>We can also search for lines that <strong>do not</strong> match our string  using the <code>-v</code> option.
We can combine that with the <code>-i</code> option to ignore the string's case.
Therefore, in the following example, all lines that do not contain the string <strong>chrome</strong> are returned:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -vi "chrome" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>I used the <code>tail</code> command in the prior section to show how we might use <code>tail</code> to remove the header (1st line) line in a file.
However, it's an odd use of the <code>tail</code> command, which normally just prints the last lines of a file.
Instead, we can use <code>grep</code> to remove the first line.
To do so, we use what's called a <strong>regular expression</strong>, or <strong>regex</strong> for short.
Regex is a method used to identify patterns in text via abstractions.
They can get complicated, but we can use some easy regex methods.</p>
<p>Let's use a version of the above file with the header line:</p>
<p><strong>Command:</strong></p>
<pre><code>cat operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>To use <code>grep</code> to remove the first line of a file, we can invert our search to select all lines not matching "OS" at the start of a line.
Here the carat key <code>^</code> is a <strong>regex</strong> indicating the start of a line.
Again, this <code>grep</code> command returns all lines that do not match the string <strong>os</strong> at the start of a line, ignoring case:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -vi "^os" operating-systems.csv
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>Alternatively, since we know that the string <strong>Year</strong> comes at the end of the first line,
we can use <code>grep</code> to invert a search for that.
Here the dollar sign key <code>$</code> is a <strong>regex</strong> indicating the end of a line.
Like the above, this <code>grep</code> command returns all lines that do not match the string <strong>year</strong> at the end of a line, ignoring case:</p>
<p><strong>Command</strong>:</p>
<pre><code>grep -vi "year$" operating-systems.csv
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>The <code>man grep</code> page lists other options, but a couple of other good ones include:</p>
<p>Get a count of the matching lines with the <code>-c</code> option:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -ic "proprietary" operating-systems.csv
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>4
</code></pre>
<p>Print only the match and not the whole line with the <code>-o</code> option:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -io "proprietary" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Proprietary
Proprietary
Proprietary
Proprietary
</code></pre>
<p>We can simulate a Boolean OR search, and print lines matching one or both strings using the <code>-E</code> option.
We separate the strings with a vertical bar <code>|</code>.
This is similar to a Boolean OR search since there's at least one match in the following string,
there is at least one result.</p>
<p>Here is an example where only one string returns a true value:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -Ei "bsd|atari" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>FreeBSD, BSD, 1993
</code></pre>
<p>Here's an example where both strings evaluate to true:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -Ei "bsd|gpl" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>FreeBSD, BSD, 1993
Linux, GPL, 1991
</code></pre>
<p>By default, <code>grep</code> will return results where the string appears within a larger word, like <strong>OS</strong> in <strong>macOS</strong>.</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i "os" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
iOS, Proprietary, 2007
macOS, Proprietary, 2001
</code></pre>
<p>However, we might want to limit results so that we only return results where <strong>OS</strong> is a complete word.
To do that, we can surround the string with special characters:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i "\&lt;os\&gt;" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
</code></pre>
<p>Sometimes we want the context for a result.
That is, we might want to print lines that surround our matches.
For example, print the matching line plus the two lines after the matching line using the <code>-A NUM</code> option:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i "chrome" -A 2 operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
</code></pre>
<p>Or, print the matching line plus the two lines before the matching line using the <code>-B NUM</code> option:</p>
<p><strong>Command</strong></p>
<pre><code>grep -i "android" -B 2 operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>We can combine many of the variations.
Here I search for the whole word <strong>BSD</strong>, case insensitive, and print the line before and the line after the match:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i -A 1 -B 1 "\&lt;bsd\&gt;" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
</code></pre>
<p><code>grep</code> is very powerful, and there are more options listed in its <code>man</code> page.</p>
<blockquote>
<p>Note that I enclose my search strings in double quotes. For example: <code>grep "search string" filename.txt</code> It's not always required to enclose a search
string in double quotes, but it's good practice because if your string
contains more than one word or empty spaces, the search will fail.</p>
</blockquote>
<h2 id="sed"><a class="header" href="#sed">Sed</a></h2>
<p><code>sed</code> is a type of non-interactive text editor that filters and transforms text (<code>man sed</code>).
By default <code>sed</code> works on <strong>standard output</strong>, and edits can be redirected (<code>&gt;</code> or <code>&gt;&gt;</code>) to new files or made <strong>in-place</strong> using the <code>-i</code> option.</p>
<p>Like the other utilities and programs we've covered, including <code>grep</code>, <code>sed</code> works line by line.
But unlike <code>grep</code>, <code>sed</code> provides a way to <strong>address</strong> specific lines or ranges of lines,
and then run filters or transformations on those lines.
Once lines in a text file have been identified or addressed, <code>sed</code> offers commands to filter or transform the text at those specific lines.</p>
<p>This concept of the line address is important, but not all text files are explicitly line numbered.
Below I use the <code>nl</code> command to number lines in our file, even though the contents of the file do not actually display line numbers:</p>
<p><strong>Command:</strong></p>
<pre><code>nl operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>     1	OS, License, Year
     2	Chrome OS, Proprietary, 2009
     3	FreeBSD, BSD, 1993
     4	Linux, GPL, 1991
     5	iOS, Proprietary, 2007
     6	macOS, Proprietary, 2001
     7	Windows NT, Proprietary, 1993
     8	Android, Apache, 2008
</code></pre>
<p>After we've identified the lines in a file that we want to edit, <code>sed</code> offers commands to filter, transform, or edit the text at the line addresses.
Some of these commands include:</p>
<ul>
<li><code>a</code> : appending text</li>
<li><code>c</code> : replace text</li>
<li><code>d</code> : delete text</li>
<li><code>i</code> : inserting text</li>
<li><code>p</code> : print text</li>
<li><code>r</code> : append text from file</li>
<li><code>s</code> : substitute text</li>
<li><code>=</code> : print the current line number</li>
</ul>
<p>Let's see how to use <code>sed</code> to print line numbers instead of using the <code>nl</code> command.
To do so, we use the equal sign <code>=</code> to identify line numbers.
Note that it places the line numbers just above each line:</p>
<p><strong>Command:</strong></p>
<pre><code>sed '=' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>1
OS, License, Year
2
Chrome OS, Proprietary, 2009
3
FreeBSD, BSD, 1993
4
Linux, GPL, 1991
5
iOS, Proprietary, 2007
6
macOS, Proprietary, 2001
7
Windows NT, Proprietary, 1993
8
Android, Apache, 2008
</code></pre>
<p>In the last section, we used the <code>tail</code> command to remove the header line of our file.
Above, we used <code>grep</code> to accomplish this task.
It's much easier to use <code>sed</code> to remove the header line of the <strong>operating-systems.csv</strong>.
We simply specify the line number (<code>1</code>) and then use the delete command (<code>d</code>).
Thus, we delete line 1 with the command below.
As long as we don't use the <code>-i</code> operator, we don't change the actual file.</p>
<p><strong>Command:</strong></p>
<pre><code>sed '1d' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<blockquote>
<p>Note that I use single apostrophes for the <code>sed</code> command.
This is required.</p>
</blockquote>
<p>If I wanted to make that a permanent deletion, then I would use the <code>-i</code> option, which means that I would edit the file <strong>in-place</strong> (see <code>man sed</code>):</p>
<p><strong>Command:</strong></p>
<pre><code>sed -i '1d' operating-systems.csv
</code></pre>
<p>To refer to line <strong>ranges</strong>, I add a comma between <strong>addresses</strong>.
Therefore, to edit lines 1, 2, and 3:</p>
<p><strong>Command:</strong></p>
<pre><code>sed '1,3d' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>I can use <code>sed</code> to <strong>find and replace</strong> strings.
The syntax for this is:</p>
<pre><code>sed 's/regexp/replacement/' filename.txt
</code></pre>
<p>The <strong>regexp</strong> part of the above command is where I place regular expressions.
Simple strings like words work here, too, since they are treated as regular expressions themselves.</p>
<p>In the next example, I use <code>sed</code> to search for the string "Linux", and replace it with the string "GNU/Linux":</p>
<p><strong>Command:</strong></p>
<pre><code>sed 's/Linux/GNU\/Linux/' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
GNU/Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<blockquote>
<p>Because the string <strong>GNU/Linux</strong> contains a forward slash, and because
<code>sed</code> uses the forward slash as a separator, note that I <strong>escaped</strong> the
forward slash with a back slash. This escape tells <code>sed</code> to interpret the
forward slash in <strong>GNU/Linux</strong> literally and not as a special <code>sed</code>
character.</p>
</blockquote>
<p>If we want to add new rows to the file, we can append <code>a</code> or insert <code>i</code> text after or at specific lines:</p>
<p>To append text <strong>after line 3</strong>, use <code>a</code>:</p>
<p><strong>Command:</strong></p>
<pre><code>sed '3a FreeDOS, GPL, 1998' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
FreeDOS, GPL, 1998
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>To insert <strong>at line 3</strong>, use <code>i</code>:</p>
<p><strong>Command:</strong></p>
<pre><code>sed '3i CP\/M, Proprietary, 1974' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
CP/M, Proprietary, 1974
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>Note that the FreeDOS line doesn't appear in the last output.
This is because I didn't use the <code>-i</code> option nor
did I redirect output to a new file.
If we want to edit the file <strong>in-place</strong>, that is, save the edits, then the commands would look like so:</p>
<pre><code>sed -i '3a FreeDOS, GPL, 1998' operating-systems.csv
sed -i '3i CP\/M, Proprietary, 1974' operating-systems.csv
</code></pre>
<p>Instead of using line numbers to specify addresses in a text file, we can use regular expressions as addresses, which may be simple words.
In the following example, I use the regular expression <code>1991$</code> instead of specifying line 4.
The regular expression <code>1991$</code>  means <strong>lines ending with the string 1991</strong>.
Then I use the <code>s</code> command to start a find and replace.
<code>sed</code> finds the string <strong>Linux</strong> and then replaces that with the string <strong>GNU/Linux</strong>.
I use the back slash to escape the forward slash in GNU/Linux:</p>
<p><strong>Command:</strong></p>
<pre><code>sed '/1991$/s/Linux/GNU\/Linux/' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
GNU/Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>Here's an example using <code>sed</code> to simply search for a pattern.
In this example, I'm interested in searching for all operating systems that were released on or after 2000:</p>
<p><strong>Command:</strong></p>
<pre><code>sed -n '/20/p' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Android, Apache, 2008
</code></pre>
<p>The above would be equivalent to:</p>
<pre><code>grep "20" operating-systems.csv
</code></pre>
<p><code>sed</code> is much more powerful than what I've demonstrated here, and if you're interested in learning more, there are lots of tutorials on the web.
Here are a few good ones:</p>
<ul>
<li><a href="https://opensource.com/article/20/12/sed">Learn to use the Sed text editor</a></li>
<li><a href="https://www.gnu.org/software/sed/manual/sed.html">Sed Introduction</a></li>
<li><a href="https://catonmat.net/sed-one-liners-explained-part-one">Sed One-Liners Explained, Part I: File Spacing, Numbering and Text Conversion and Substitution</a></li>
<li><a href="https://edoras.sdsu.edu/doc/sed-oneliners.html">sed one-liners</a></li>
<li><a href="https://www.tutorialspoint.com/sed/index.htm">Sed Tutorial</a></li>
</ul>
<h2 id="awk"><a class="header" href="#awk">Awk</a></h2>
<p><code>awk</code> is a complete scripting language designed for "pattern scanning and processing" text.
It generally performs some <strong>action</strong> when it detects some <strong>pattern</strong> and is particularly suited for <strong>columns of structured data</strong>.
See <code>man awk</code>for documentation..</p>
<p><code>awk</code> works on columns  regardless if the contents include structured data  (like a CSV file) or not (like a letter or essay).
If the data is structured, then that means the data will be formatted in some way.
In the last few sections, we have looked at a CSV file.
This is structured data because the data points  in this file are separated by commas.</p>
<p>For <code>awk</code> to work with columns in a file, it needs some way to refer to those columns.
In the examples below, we'll see that columns in a text file are referred to by a dollar sign and then the number of the column <code>$n</code>.
So, <code>$1</code> indicates column one,  <code>$2</code> indicates column two, and so on.
If we use <code>$0</code>, then we refer to the entire file.
In our example text file, <code>$1</code> indicates the OS Name column, <code>$2</code> indicates the License column, <code>$3</code> indicates the release Year column,
and <code>$0</code> indicates all columns.</p>
<p>The syntax for <code>awk</code> is a little different than what we've seen so far.
Basically, <code>awk</code> uses the following syntax, where <strong>pattern</strong> is optional.</p>
<pre><code>awk pattern { action statements }
</code></pre>
<p>Let's see some examples.</p>
<p>To print the first column of our file, we do not need the <strong>pattern</strong> part of the command but only need to state an action statement within curly braces.
In the command below, the action statement is <code>'{ print $1 }'</code>.</p>
<p><strong>Command:</strong></p>
<pre><code>awk '{ print $1 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS,
Chrome
FreeBSD,
Linux,
iOS,
macOS,
Windows
Android,
</code></pre>
<p>By default, <code>awk</code> considers the first empty space as the field delimiter.
That's why in the command above only the term <strong>Windows</strong> and <strong>Chrome</strong> appear in the results even though it should be <strong>Windows NT</strong> and <strong>Chrome OS</strong>.
It's also why we see commas in the output.
To fix this, we tell <code>awk</code> to use a comma as the field separator, instead of the default empty space.
To specify that we want <code>awk</code> to treat the comma as a field delimiter,
we use the <code>-F</code> option, and we surround the comma with single quotes:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '{ print $1 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS
Chrome OS
FreeBSD
Linux
iOS
macOS
Windows NT
Android
</code></pre>
<p>By specifying the comma as the field separator, our results are more accurate, and the commas no longer appear either.</p>
<p>Like <code>grep</code> and <code>sed</code>, <code>awk</code> can do search.
In this next example, I print the column containing the string <strong>Linux</strong>.
Here I am using the <strong>pattern</strong> part of the command: <code>'/Linux/'</code>.</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '/Linux/ { print $1 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Linux
</code></pre>
<p>Note how <code>awk</code> does not return the whole line but only the match.</p>
<p>With <code>awk</code>, we can retrieve more than one column, and we can use <code>awk</code> to generate reports.
This was part of the original motivation to create this language.</p>
<p>In the next example, I select columns two and one in that order, which is something the <code>cut</code> command cannot do.
I also add a space between the columns using the double quotes to surround an empty space.
Then I modified the field delimiter to include both a comma and a space to get the output that I want:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F', ' '{ print $2 " " $1 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>License OS
Proprietary Chrome OS
BSD FreeBSD
GPL Linux
Proprietary iOS
Proprietary macOS
Proprietary Windows NT
Apache Android
</code></pre>
<p>I can make output more readable by adding text to print:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '{ print $1 " was released in" $3 "." }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS was released in Year.
Chrome OS was released in 2009.
FreeBSD was released in 1993.
Linux was released in 1991.
iOS was released in 2007.
macOS was released in 2001.
Windows NT was released in 1993.
Android was released in 2008.
</code></pre>
<p>Since <code>awk</code> is a full-fledged programming language, it understands data structures, which means it can do math or work on strings of text.
Let's illustrate this by doing some math or logic on column 3.</p>
<p>Here I print all of column three:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '{ print $3 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code> Year
 2009
 1993
 1991
 2007
 2001
 1993
 2008
</code></pre>
<p>Next I print only the parts of column three that are greater than 2005, and
then pipe <code>|</code> the output through the <code>sort</code> command to sort the numbers in numeric order:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '$3 &gt; 2005 { print $3 }' operating-systems.csv | sort
</code></pre>
<p><strong>Output:</strong></p>
<pre><code> 2007
 2008
 2009
</code></pre>
<p>If I want to print only the parts of column one where column three equals to 2007, then I would run this command:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '$3 == 2007 { print $1 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>iOS
</code></pre>
<p>If I want to print only the parts of columns one and three where column 3 equals 2007:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '$3 == 2007 { print $1 $3 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>iOS 2007
</code></pre>
<p>Or, print the entire line where column three equals 2007:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '$3 == 2007 { print $0 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>iOS, Proprietary, 2007
</code></pre>
<p>I can print only those lines where column three is greater than 2000 and less than 2008:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '$3 &gt; 2000 &amp;&amp; $3 &lt; 2008 { print $0 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>iOS, Proprietary, 2007
macOS, Proprietary, 2001
</code></pre>
<p>Even though we wouldn't normally sum years, let's print the sum of column three  to demonstrate how summing works in <code>awk</code>:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' 'sum += $3 { print sum }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>2009
4002
5993
8000
10001
11994
14002
</code></pre>
<p>Here are a few basic string operations.
First, print column one in upper case:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '{ print toupper($1) }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS
CHROME OS
FREEBSD
LINUX
IOS
MACOS
WINDOWS NT
ANDROID
</code></pre>
<p>Or print column on in lower case:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '{ print tolower($1) }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>os
chrome os
freebsd
linux
ios
macos
windows nt
android
</code></pre>
<p>Or, get the length of each string in column one:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '{ print length($1) }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>2
9
7
5
3
5
10
7
</code></pre>
<p>We can add additional logic.
The double ampersands <code>&amp;&amp;</code> indicate a Boolean/Logical <strong>AND</strong>.
The exclamation point <code>!</code> indicates a Boolean/Logical <strong>NOT</strong>.
In the next example, I print only those lines where column three is greater than 1990, and the line has the string "BSD" in it:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '$3 &gt; 1990 &amp;&amp; /BSD/ { print $0 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>FreeBSD, BSD, 1993
</code></pre>
<p>Now I reverse that, and print only those lines where column three is greater than 1990 and the line DOES NOT have the string "BSD" in it:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '$3 &gt; 1990 &amp;&amp; !/BSD/ { print $0 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>The double vertical bar <code>||</code> indicates a Boolean/Logical <strong>OR</strong>.
The next command prints only those lines that contain the string "Proprietary" or the string "Apache",
or it would print both if both strings were in the text:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '/Proprietary/ || /Apache/ { print $0 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>I can take advantage of regular expressions.
If I needed to analyze a large file and wasn't sure that some fields would be upper or lower case,
then I could use regular expressions to consider both possibilities.
That is, by adding <strong>[pP]</strong> and <strong>[aA]</strong>, <code>awk</code> will check for both the words <strong>Proprietary</strong> and <strong>proprietary</strong>, and <strong>Apache</strong> and <strong>apache</strong>.</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F',' '/[pP]roprietary/ || /[aA]pache/ { print $0 }' operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p><code>awk</code> is full-fledged programming language.
It provides conditionals, control structures, variables, etc., and so I've only scratched the surface.
If you're interested in learning more, then check out some of these tutorials:</p>
<ul>
<li><a href="https://www.tecmint.com/category/awk-command/">Awk Command</a></li>
<li><a href="https://catonmat.net/awk-one-liners-explained-part-one">Awk One-Liners Explained, Part I: File Spacing, Numbering and Calculations</a></li>
<li><a href="https://www.grymoire.com/Unix/Awk.html">Awk Tutorial</a></li>
<li><a href="https://blog.robertelder.org/intro-to-awk-command/">How To Become a 10x Engineer using the Awk Command</a></li>
<li><a href="https://arstechnica.com/gadgets/2021/08/linux-bsd-command-line-101-using-awk-sed-and-grep-in-the-terminal/">Linux/BSD command line wizardry: Learn to think in sed, awk, and grep</a></li>
<li><a href="https://earthly.dev/blog/awk-examples/">Understanding AWK</a></li>
</ul>
<h2 id="conclusion-6"><a class="header" href="#conclusion-6">Conclusion</a></h2>
<p>The Linux command line offers a lot of utilities to examine data.
Prior to this lesson, we covered a few of them that helped us get parts of a file and
then pipe those parts through other commands or redirect output to files.
We can use pipes and redirects with <code>grep</code>, <code>sed</code>, and <code>awk</code>.
If needed, we may be able to avoid using the basic utilities like
<code>cut</code>, <code>wc</code>, etc if want to learn more powerful programs like <code>grep</code>, <code>sed</code>, and <code>awk</code>.</p>
<p>It's fun to learn and practice these.
Despite this, you do not have to become a <code>sed</code> or an <code>awk</code> programmer.
Like the utilities that we've discussed in prior lectures, the power of programs like these is that they are easy to use as <strong>one-liners</strong>.
If you want to get started, the resources listed above can guide you.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="regular-expressions-with-grep"><a class="header" href="#regular-expressions-with-grep">Regular Expressions with <code>grep</code></a></h1>
<p>By the end of this section, you will:</p>
<ol>
<li><strong>Understand the purpose of <code>grep</code></strong>: Recognize the versatility of <code>grep</code>
for searching through text and its use in filtering output, searching for
patterns in files, and extracting relevant data.</li>
<li><strong>Perform basic searches using <code>grep</code></strong>: Search for multiword strings and
whole words while understanding how to handle case sensitivity and word
boundaries.</li>
<li><strong>Utilize regular expressions</strong>: Apply regular expressions with <code>grep</code> to
search for more complex text patterns, using features like bracket
expressions, character classes, and anchoring.</li>
<li><strong>Leverage repetition and OR operators</strong>: Use repetition operators (e.g.,
<code>*</code>, <code>+</code>) and Boolean OR searches to find repetitive patterns or multiple
possible matches in your text.</li>
<li><strong>Compare outputs with process substitution</strong>: Understand how to compare the
output of multiple <code>grep</code> commands using process substitution techniques
with the <code>diff</code> command.</li>
<li><strong>Understand broader applications</strong>: Gain a foundational understanding of
regular expressions that apply across multiple programming languages and
tools beyond just <code>grep</code>.</li>
</ol>
<h2 id="getting-started-2"><a class="header" href="#getting-started-2">Getting Started</a></h2>
<p>The <code>grep</code> command is a powerful tool used in the Linux command line for searching through text.
It scans files or input for lines that match a specified pattern, which can be a simple word or a more complex <strong>regular expression</strong>.
<code>grep</code> is often used to filter output, search for specific data in logs, or find occurrences of certain text patterns within files.
Its versatility makes it an essential tool for efficiently locating information in large sets of data or documents.</p>
<p>In this section, we learn how to use <code>grep</code> to search files.
We will use simple search strings with <code>grep</code> to search for regular words.
But we will use <strong>regular expressions</strong> to search for more complex patterns.</p>
<h3 id="download-data-file"><a class="header" href="#download-data-file">Download Data File</a></h3>
<p>To follow along in this tutorial, download the following file to your home directory on your Google Cloud VM:</p>
<pre><code>wget https://raw.githubusercontent.com/cseanburns/linux_sysadmin/refs/heads/master/data/cities.md
</code></pre>
<h2 id="multiword-strings"><a class="header" href="#multiword-strings">Multiword strings</a></h2>
<p>It's good habit to include search strings within quotes, but this is especially important if we would search for multiword strings.
In these cases, we must enclose them in quotes.</p>
<p><strong>Command:</strong></p>
<pre><code>cat cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| City              | 2020 Census | Founded |
|-------------------|-------------|---------|
| New York City, NY | 8804190     | 1624    |
| Los Angeles, CA   | 3898747     | 1781    |
| Chicago, IL       | 2746388     | 1780    |
| Houston, TX       | 2304580     | 1837    |
| Phoenix, AZ       | 1624569     | 1881    |
| Philadelphia, PA  | 1576251     | 1701    |
| San Antonio, TX   | 1451853     | 1718    |
| San Diego, CA     | 1381611     | 1769    |
| Dallas, TX        | 1288457     | 1856    |
| San Jose, CA      | 983489      | 1777    |
</code></pre>
<p><strong>Command:</strong></p>
<pre><code>grep "San Antonio" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| San Antonio, TX | 1451853 | 1718 |
</code></pre>
<h2 id="whole-words-case-sensitive-by-default"><a class="header" href="#whole-words-case-sensitive-by-default">Whole words, case sensitive by default</a></h2>
<p>As a reminder, <code>grep</code> commands are case-sensitive by default.
Thus, note that the contents of <strong>cities.md</strong> are all in lowercase.
If I run the above command without the city named capitalized, then <code>grep</code> will return nothing:</p>
<p><strong>Command:</strong></p>
<pre><code>grep "san antonio" cities.md
</code></pre>
<p>To tell grep to ignore case, I need to use the <code>-i</code> option.
We also want to make sure that we enclose our entire search string withing double quotes.</p>
<p>This is a reminder for you to run <code>man grep</code> and to read through the documentation and see what the various options exit for this command.</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i "san antonio" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| San Antonio, TX | 1451853 | 1718 |
</code></pre>
<h3 id="whole-words-by-the-edges"><a class="header" href="#whole-words-by-the-edges">Whole words by the edges</a></h3>
<p>To search whole words, we can use special characters to match strings at the start and/or the end of words.
For example, note the output if I search for cities in California in my file by searching for the string <strong>ca</strong>.
Since this string appears in Chi<strong>ca</strong>go, then that city matches my grep search:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i "ca" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| Los Angeles, CA | 3898747 | 1781 |
| Chicago, IL     | 2746388 | 1780 |
| San Diego, CA   | 1381611 | 1769 |
| San Jose, CA    | 983489  | 1777 |
</code></pre>
<p>To limit results to only <strong>CA</strong>, we can enclose our search in special characters that tell <code>grep</code> to limit by whole words only:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i "\bca\b" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| Los Angeles, CA | 3898747 | 1781 |
| San Diego, CA   | 1381611 | 1769 |
| San Jose, CA    | 983489  | 1777 |
</code></pre>
<blockquote>
<p><strong>Note:</strong> in some cases you might need an extra backslash: <code>grep -i "\\bca\\b" cities.md</code>.</p>
</blockquote>
<p>We can reverse that output and look for strings within other words.
Here is an example of searching for the string <strong>ca</strong> within words:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i "\Bca\B" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| Chicago, IL | 2746388 | 1780 |
</code></pre>
<h2 id="bracket-expressions-and-character-classes"><a class="header" href="#bracket-expressions-and-character-classes">Bracket Expressions and Character Classes</a></h2>
<p>In conjunction with the <code>grep</code> command, we can also use regular expressions to search for more general patterns in text files.
For example, we can use <strong>bracket expressions</strong> and <strong>character classes</strong> to search for patterns in the text.
Here again using <code>man grep</code> is very important because it includes instructions on how to use these regular expressions.</p>
<h3 id="bracket-expressions"><a class="header" href="#bracket-expressions">Bracket expressions</a></h3>
<p>From <code>man grep</code> on <strong>bracket expressions</strong>:</p>
<blockquote>
<p>A bracket expression is a list of characters enclosed by [ and ]. It matches
any single character in that list. If the first character of the list is the
caret ^ then it matches any character not in the list. For example, the
regular expression [0123456789] matches any single digit.</p>
</blockquote>
<p>The regular expression [^0123456789] matches the inverse.</p>
<blockquote>
<p>Within a bracket expression, a range expression consists of two characters
separated by a hyphen. It matches any single character that sorts between the
two characters.</p>
</blockquote>
<p>To see how this works, let's search the <strong>cities.md</strong> file for letters matching <strong>A, B, or C</strong>.
Specifically, in the following command I use a hyphen to match any characters <strong>in</strong> the range A, B, C.
The output does not include the cities <strong>Houston</strong> or <strong>Dallas</strong> since neither of those lines contain capital <strong>A, B, or C</strong> characters:</p>
<p><strong>Command:</strong></p>
<pre><code>grep "[A-C]" cities.md 
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| City              | 2020 Census | Founded |
| New York City, NY | 8804190     | 1624    |
| Los Angeles, CA   | 3898747     | 1781    |
| Chicago, IL       | 2746388     | 1780    |
| Phoenix, AZ       | 1624569     | 1881    |
| Philadelphia, PA  | 1576251     | 1701    |
| San Antonio, TX   | 1451853     | 1718    |
| San Diego, CA     | 1381611     | 1769    |
| San Jose, CA      | 983489      | 1777    |
</code></pre>
<blockquote>
<p><strong>Note:</strong> Use <code>grep -i "[A-C]" cities.md</code> for a case insensitive search.</p>
</blockquote>
<h3 id="bracket-expressions-inverse-searches"><a class="header" href="#bracket-expressions-inverse-searches">Bracket expressions, inverse searches</a></h3>
<p>When placed after the first bracket, the carat key acts as a Boolean NOT.
The following command matches any characters <strong>not in</strong> the range A,B,C:</p>
<p><strong>Command:</strong></p>
<pre><code>grep "[^A-C]" cities.md
</code></pre>
<p>The output matches all lines since there are no instances of <strong>A, B, and C</strong> in all lines:</p>
<p><strong>Output:</strong></p>
<pre><code>| City              | 2020 Census | Founded |
|-------------------|-------------|---------|
| New York City, NY | 8804190     | 1624    |
| Los Angeles, CA   | 3898747     | 1781    |
| Chicago, IL       | 2746388     | 1780    |
| Houston, TX       | 2304580     | 1837    |
| Phoenix, AZ       | 1624569     | 1881    |
| Philadelphia, PA  | 1576251     | 1701    |
| San Antonio, TX   | 1451853     | 1718    |
| San Diego, CA     | 1381611     | 1769    |
| Dallas, TX        | 1288457     | 1856    |
| San Jose, CA      | 983489      | 1777    |
</code></pre>
<h4 id="process-substitution"><a class="header" href="#process-substitution">Process substitution</a></h4>
<p>Process substitution allows you to use the output of a command as if it were a file.
This is particularly useful when you want to compare the outputs of two commands directly, without having to save them to temporary files.</p>
<p>For example, we can confirm that output from one command does not include Houston or Dallas in a second command by comparing the outputs.
Specifically, we compare the outputs of two or more commands using <strong>process substitution</strong>.
This works because the <strong>process substitution</strong> creates temporary files from the outputs.</p>
<p><strong>Command:</strong></p>
<pre><code>diff &lt;(grep "[A-C]" cities.md) &lt;(grep "[^A-C]" cities.md)
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>1a2
&gt; |-----------------|-------------|------|
4a6
&gt; | Houston, TX     | 2304580     | 1837 |
8a11
&gt; Dallas, TX        | 1288457     | 1856
</code></pre>
<hr />
<h5 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h5>
<ul>
<li><code>&lt;(command)</code> creates a temporary file (or file-like stream) that holds the output of command.</li>
<li><code>diff</code> can then read from these streams as if they were regular files, comparing their contents without needing you to manually save and load files.
The output of the <code>diff</code> command is nicely explained in this <a href="https://unix.stackexchange.com/a/216131">Stack Overflow</a> answer.</li>
</ul>
<p>Without process substitution, you would need to save the outputs of both grep commands to temporary files and then compare them:</p>
<pre><code>grep "[A-C]" cities.md &gt; output1.txt
grep "[^A-C]" cities.md &gt; output2.txt
diff output1.txt output2.txt
</code></pre>
<p>This alternative works but is more cumbersome, as it requires managing temporary files.
Process substitution simplifies the process by handling this behind the scenes.</p>
<hr />
<p>Try this command for an alternate output:</p>
<pre><code>diff -y &lt;(grep "[A-C]" cities.md) &lt;(grep "[^A-C]" cities.md)
</code></pre>
<p>Our ranges may be alphabetical or numerical.
The following command matches any numbers <strong>in</strong> the range 1,2,3:</p>
<p><strong>Command:</strong></p>
<pre><code>grep "[1-3]" cities.md
</code></pre>
<p>Since all single digits appear in the file, the above command returns all lines.
To invert the search, we can use the following grep command.
This will match all non-integers:</p>
<p><strong>Command:</strong></p>
<pre><code>grep "[^0-9]" cities.md
</code></pre>
<h3 id="bracket-expressions-carat-preceding-the-bracket"><a class="header" href="#bracket-expressions-carat-preceding-the-bracket">Bracket expressions, carat preceding the bracket</a></h3>
<p>We saw in a previous section that the carat <code>^</code> key indicates the start of line.
However, we learned above that it can be used to return the inverse of a string in special circumstances.
To use the carat to signify the start of a line, the carat key must precede the opening bracket.
For example, the following command matches any lines that start with the upper case letters within the range of <strong>N,O,P</strong>:</p>
<p><strong>Command:</strong></p>
<pre><code>grep "^| [N-P]" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>New York City, NY | 8804190 | 1624
Phoenix, AZ       | 1624569 | 1881
Philadelphia, PA  | 1576251 | 1701
</code></pre>
<p>And we can reverse that with the following command, which returns all lines that <strong>do not</strong> start with <strong>N,O, or P</strong>:</p>
<p><strong>Command:</strong></p>
<pre><code>grep "^| [^N-P]" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| City            | 2020 Census | Founded |
| Los Angeles, CA | 3898747     | 1781    |
| Chicago, IL     | 2746388     | 1780    |
| Houston, TX     | 2304580     | 1837    |
| San Antonio, TX | 1451853     | 1718    |
| San Diego, CA   | 1381611     | 1769    |
| Dallas, TX      | 1288457     | 1856    |
| San Jose, CA    | 983489      | 1777    |
</code></pre>
<h3 id="character-classes"><a class="header" href="#character-classes">Character classes</a></h3>
<p>Character classes are special types of predefined bracket expressions.
They make it easy to search for general patterns.
From <code>man grep</code> on <strong>character classes</strong>:</p>
<blockquote>
<p>Finally, certain named classes of characters are predefined within bracket
expressions, as follows. Their names are self explanatory, and they are
[:alnum:], [:alpha:], [:blank:], [:cntrl:], [:digit:], [:graph:], [:lower:],
[:print:], [:punct:], [:space:], [:upper:], and [:xdigit:]. For example,
[[:alnum:]] means the character class of numbers and letters ...</p>
</blockquote>
<p>Below I use the <code>awk</code> command to select the fourth column (or field) using the pipe as the field delimiter.
I pipe the output to <code>grep</code> to select lines containing a vertical bar and four digit numbers <code>[[:digit:]]{4}</code> from the results of the <code>awk</code> command:</p>
<p><strong>Command:</strong></p>
<pre><code>awk -F"|" '{ print $4 }' cities.md | grep -Eo "[[:digit:]]{4}"
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>1624
1781
1780
1837
1881
1701
1718
1769
1856
1777
</code></pre>
<blockquote>
<p>I first tested that the <code>awk</code> command selects the appropriate field by running it by itself: <code>awk -F"|" '{ print $4 }' cities.md</code>.</p>
</blockquote>
<h2 id="anchoring"><a class="header" href="#anchoring">Anchoring</a></h2>
<p>As seen above, outside of bracket expressions and character classes, we use the caret <code>^</code> to mark the beginning of a line.
We can also use the <code>$</code> to match the end of a line.
Using either (or both) is called <strong>anchoring</strong>.
Anchoring works in many places.
For example, to search all lines that start with capital <strong>D through L</strong></p>
<p><strong>Command:</strong></p>
<pre><code>grep "^| [D-L]" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| Los Angeles, CA | 3898747 | 1781 |
| Houston, TX     | 2304580 | 1837 |
| Dallas, TX      | 1288457 | 1856 |
</code></pre>
<p>To show how to anchor the end of a line, let's look at the <strong>operating-systems.csv</strong> file.</p>
<p><strong>Command:</strong></p>
<pre><code>grep "1993$" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>FreeBSD, BSD, 1993
Windows NT, Proprietary, 1993
</code></pre>
<p>We can use both anchors in our <code>grep</code> commands.
The following searches for any lines starting with capital letters that range from C through F.
Then any lines ending with the numbers starting from 3 through 6.
The single dot stands for any character, and the asterisk stands for "the preceding character will zero or more times" (<code>man grep</code>).</p>
<p><strong>Command:</strong></p>
<pre><code>grep "^[C-F].*[3-6]$" operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>CP/M, Proprietary, 1974
FreeBSD, BSD, 1993
</code></pre>
<h2 id="repetition"><a class="header" href="#repetition">Repetition</a></h2>
<p>If we want to use regular expressions to identify repetitive patterns, then we can use repetition operators.
As we saw above, the most useful one is the <code>*</code> asterisk.
But there are other options:</p>
<p>In come cases, we need to add the -E option
to extend <code>grep</code>'s regular expression functionality:</p>
<p>Here, the preceding item <strong>S</strong> is matched one or more times:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -E "S+" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| San Antonio, TX | 1451853 | 1718 |
| San Diego, CA   | 1381611 | 1769 |
| San Jose, CA    | 983489  | 1777 |
</code></pre>
<p>In the next search, the preceding item <strong>l</strong> is matched exactly 2 times:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -E "l{2}" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| Dallas, TX | 1288457 | 1856 |
</code></pre>
<p>Finally, in this example, the preceding item <strong>7</strong> is matched at least two times or at most three times:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -E "7{2,3}" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| San Jose, CA | 983489 | 1777 |
</code></pre>
<h2 id="or-searches"><a class="header" href="#or-searches">OR searches</a></h2>
<p>We can use the vertical bar <code>|</code> to do a Boolean OR search.
In a Boolean OR statement, the statement is True if either one part is true, the other part is true, or both are true.
In a search statement, this means that at least one part of the search is true.</p>
<p>The following will return lines for each city because they both appear in the file:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -E "San Antonio|Dallas" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| San Antonio, TX | 1451853 | 1718 |
| Dallas, TX      | 1288457 | 1856 |
</code></pre>
<p>The following will match San Antonio even though Lexington does not appear in the file:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -E "San Antonio|Lexington" cities.md
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>| San Antonio, TX | 1451853 | 1718 |
</code></pre>
<h2 id="conclusion-7"><a class="header" href="#conclusion-7">Conclusion</a></h2>
<p>We covered a lot in this section on <code>grep</code> and regular expressions.</p>
<p>We specifically covered:</p>
<ul>
<li>multiword strings</li>
<li>whole word searches and case sensitivity</li>
<li>bracket expressions and character classes</li>
<li>anchoring</li>
<li>repetition</li>
<li>Boolean OR searches</li>
</ul>
<p>Even though we focused on <code>grep</code>, many these regular expressions work across many programming languages.</p>
<p>See <a href="https://www.regular-expressions.info/">Regular-Expression.info</a> for more in-depth lessons on regular expressions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="review"><a class="header" href="#review">Review</a></h1>
<p>Here is a review of commands
and concepts that we have
covered so far.</p>
<h2 id="commands"><a class="header" href="#commands">Commands</a></h2>
<p>We have covered the following
commands so far:</p>
<div class="table-wrapper"><table><thead><tr><th>Command</th><th>Example</th><th>Explanation</th></tr></thead><tbody>
<tr><td>tree</td><td>tree -dfL 1</td><td>List directories, full path, one level</td></tr>
<tr><td>cd</td><td>cd ~</td><td>change to home directory</td></tr>
<tr><td></td><td>cd /</td><td>change to root directory</td></tr>
<tr><td></td><td>cd bin</td><td>change to bin directory from current directory</td></tr>
<tr><td>pwd</td><td>pwd</td><td>print working / current directory</td></tr>
<tr><td>ls</td><td>ls ~</td><td>list home directory contents</td></tr>
<tr><td></td><td>ls -al</td><td>list long format and hidden files in current directory</td></tr>
<tr><td></td><td>ls -dl</td><td>list long format the current directory</td></tr>
<tr><td>man</td><td>man ls</td><td>open manual page for the ls command</td></tr>
<tr><td></td><td>man man</td><td>open manual page for the man command</td></tr>
<tr><td>cp</td><td>cp * bin/</td><td>copy all files in current directory to bin subdir</td></tr>
<tr><td>mv</td><td>mv oldname newname</td><td>rename file oldname to newname</td></tr>
<tr><td></td><td>mv oldir bin/newdir</td><td>move oldman to bin subdir and rename to newdir</td></tr>
<tr><td>rm</td><td>rm oldfile</td><td>delete file named oldfile</td></tr>
<tr><td></td><td>rm -r olddir</td><td>delete directory olddir and its contents</td></tr>
<tr><td>touch</td><td>touch newfile</td><td>create a file called newfile</td></tr>
<tr><td></td><td>touch oldfile</td><td>modify timestamp of file called oldfile</td></tr>
<tr><td>mkdir</td><td>mkdir newdir</td><td>create a new directory called newdir</td></tr>
<tr><td>rmdir</td><td>rmdir newdir</td><td>delete directory called newdir if empty</td></tr>
<tr><td>echo</td><td>echo "hello"</td><td>print "hello" to screen</td></tr>
<tr><td>cat</td><td>cat data.csv</td><td>print contents of file called data.csv to screen</td></tr>
<tr><td></td><td>cat data1.csv data2.csv</td><td>concatenate data1.csv and data2.csv to screen</td></tr>
<tr><td>less</td><td>less file</td><td>view contents of file called file</td></tr>
<tr><td>sudo</td><td>sudo command</td><td>run command as superuser</td></tr>
<tr><td>chown</td><td>sudo chown root:root file</td><td>change owner and group to root of file file</td></tr>
<tr><td>chmod</td><td>chmod 640 file</td><td>change permissions of file to -rw-r-----</td></tr>
<tr><td></td><td>chmod 775 somedir</td><td>change permissions of of somedir to drwxrwxr-x</td></tr>
<tr><td>groups</td><td>groups user</td><td>print the groups the user is in</td></tr>
<tr><td>wc</td><td>wc -l file</td><td>print number of lines of file</td></tr>
<tr><td></td><td>wc -w file</td><td>print number of words of file</td></tr>
<tr><td>head</td><td>head file</td><td>print top ten lines of file</td></tr>
<tr><td></td><td>head -n3 file</td><td>print top three lines of file</td></tr>
<tr><td>tail</td><td>tail file</td><td>print bottom ten lines of file</td></tr>
<tr><td></td><td>tail -n3 file</td><td>print bottom three lines of file</td></tr>
<tr><td>cut</td><td>cut -d"," -f2 data.csv</td><td>print second column of file data.csv</td></tr>
<tr><td>sort</td><td>sort -n file</td><td>sort file by numerical order</td></tr>
<tr><td></td><td>sort -rn file</td><td>sort file by reverse numerical order</td></tr>
<tr><td></td><td>sort -df file</td><td>sort file by dictionary order and ignore case</td></tr>
<tr><td>uniq</td><td>uniq file</td><td>report or omit repeated lines in sorted file</td></tr>
<tr><td></td><td>uniq -c file</td><td>report count of duplicate lines in sorted file</td></tr>
</tbody></table>
</div>
<p>In addition to the above commands,
we also have pipelines using the <code>|</code>.
Pipelines send the standard output of
one command to a second command
(or more).
The following command sorts the
contents of a file and then
sends the output to the <code>uniq</code>
command to remove duplicates:</p>
<pre><code>sort file | uniq
</code></pre>
<p>Redirection uses the <code>&gt;</code> or the <code>&gt;&gt;</code>
to redirect output of a command to a file.
A single <code>&gt;</code> will overwrite the contents
of a file.
A double <code>&gt;&gt;</code> will append to the
contents of a file.</p>
<p>Redirect the output of the <code>ls</code>
command to a file called <strong>dirlist</strong>:</p>
<pre><code>ls &gt; dirlist
</code></pre>
<p>Append the date to the end of
the file <strong>dirlist</strong>:</p>
<pre><code>date &gt;&gt; dirlist
</code></pre>
<h2 id="paths"><a class="header" href="#paths">Paths</a></h2>
<p>I introduced the concept of absolute and relative paths
in <a href="03-filesystem-file-management.html">section 2.3</a>.
In this session, the goal is to revisit paths
(locations of files and directories in the filesystem),
and provide some examples.
This will be important as we proceed to Bash scripting
and other tasks going forward.</p>
<h3 id="change-directories"><a class="header" href="#change-directories">Change Directories</a></h3>
<p>The <code>cd</code> command is used to change directories.
When we login to our systems,
we will find ourselves in our <strong>$HOME</strong> directory,
which is located at <code>/home/USER</code>.</p>
<p>To change to the root directory, type:</p>
<pre><code>pwd
/home/sean
cd /
pwd
/
</code></pre>
<p>From there, to change to the <code>/bin</code> directory:</p>
<pre><code>cd bin
pwd
/bin
</code></pre>
<p>To change to the previous working directory:</p>
<pre><code>cd -
pwd
/
</code></pre>
<p>To go home quickly, just enter <code>cd</code> by itself:</p>
<pre><code>cd
pwd
/home/sean
</code></pre>
<p>To change to the <code>public_html</code> directory:</p>
<pre><code>cd public_html
pwd
/home/sean/public_html
</code></pre>
<p>To change to the directory one level up:</p>
<pre><code>cd ..
pwd
cd /home/sean
</code></pre>
<h2 id="make-directories"><a class="header" href="#make-directories">Make Directories</a></h2>
<p>Sometimes we'll want to create new directories.
To do so, we use the <code>mkdir</code> command.</p>
<p>To make a new directory in our <strong>$HOME</strong> directory:</p>
<pre><code>pwd
/home/sean
mkdir documents
cd documents
pwd
/home/sean/documents
cd
pwd
/home/sean
</code></pre>
<p>To make more than one directory at the same time,
where the second or additional directories are nested,
use the <code>-p</code> option:</p>
<pre><code>mkdir -p photos/2022
</code></pre>
<h2 id="remove-or-delete-files-and-directories"><a class="header" href="#remove-or-delete-files-and-directories">Remove or Delete Files and Directories</a></h2>
<p>To remove a file, we use the <code>rm</code> command.
If the file is in a subdirectory,
specify the relative path:</p>
<pre><code>pwd
/home/sean
rm public_html/index.html
</code></pre>
<p>To remove a file in a directory one level up,
use the <code>..</code> notation.
For example, if I'm in my <strong>documents</strong> directory,
and I want to delete a file in my home (parent) directory:</p>
<pre><code>cd documents
pwd
/home/sean/documents
rm ../file.txt
</code></pre>
<p>Alternatively, I could the tilde as shorthand for <strong>$HOME</strong>:</p>
<pre><code>rm ~/file.txt
</code></pre>
<p>To remove a file nested in multiple subdirectories,
just specify the path (absolute or relative).</p>
<pre><code>rm photos/2022/05/22/IMG_2022_05_22.jpg
</code></pre>
<p>Remember that the <code>rm</code> command deletes files and directories.
Use it with caution,
or with the <code>-i</code> option.</p>
<h2 id="copy-files-or-directories"><a class="header" href="#copy-files-or-directories">Copy Files or Directories</a></h2>
<p>Let's say I want to copy a file in my <strong>$HOME</strong> directory
to a nested directory:</p>
<pre><code>cp file.txt documents/ICT418/homework/
</code></pre>
<p>Or, we can copy a file from one subdirectory to another.
Here I copy a file in my <code>~/bin</code> directory
to my <code>~/documents</code>directory.
The <code>~</code> (tilde) is shorthand for my <strong>$HOME</strong> directory.</p>
<pre><code>cp ~/bin/file.txt ~/documents/``
</code></pre>
<h2 id="move-or-rename-files-or-directories"><a class="header" href="#move-or-rename-files-or-directories">Move or Rename Files or Directories</a></h2>
<p>Let's say I downloaded a file to my <code>~/Downloads</code> directory,
and I want to move it to my <code>~/documents</code> directory:</p>
<pre><code>mv ~/Downloads/article.pdf ~/documents/
</code></pre>
<p>Or, let's say we rename it in the process:</p>
<pre><code>mv ~/Downloads/article.pdf ~/documents/article-2022.pdf
</code></pre>
<p>We can also move directories.
Since the commandline is case-sensitive,
let's say I rename the <strong>documents</strong> directory
to <strong>Documents</strong>:</p>
<pre><code>mv ~/documents ~/Documents
</code></pre>
<h2 id="conclusion-8"><a class="header" href="#conclusion-8">Conclusion</a></h2>
<p>Use this page as a reference to
the commands that we have covered
so far.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scripting-the-command-line"><a class="header" href="#scripting-the-command-line">Scripting the Command Line</a></h1>
<p>Up to this point, we've explored a variety of commands available on the Linux command line.
We've learned how to work with files and directories, manage permissions and ownership, and process text in multiple ways.</p>
<p>While these tasks have focused on using the command line prompt, this approach is often temporary and manual.
For more complex tasks, or when we want to automate a series of commands, it becomes useful to save them in a file.
To achieve this, we need to work with a <strong>text editor</strong>.
Since we're primarily operating in the terminal, we'll focus on terminal-based text editors, which offer several practical options.</p>
<p>In this section, we'll explore some of the most popular terminal-based text editors.
We'll start with a historical perspective, beginning with the classic <code>ed</code> editor.
From there, we'll move on to more widely-used editors like <code>vim</code> and <code>nano</code>.
While I personally prefer <code>vim</code> for its flexibility and power, <code>nano</code> tends to be more accessible for beginners.
We'll also touch on a couple of newer, user-friendly editors: <code>micro</code> and <code>tilde</code>.</p>
<p>After we've covered these editors, we'll dive into more advanced text processing techniques using <strong>regular expressions</strong>.
Regular expressions allow us to identify and manipulate patterns in text.
Although they're useful directly at the command line, they truly shine when integrated into scripts for automation and complex processing.</p>
<p>With these tools in hand, we'll then move on to creating <code>bash</code> scripts, combining the commands we've learned into efficient, automated workflows.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="text-editors"><a class="header" href="#text-editors">Text editors</a></h1>
<p>In this section, we will cover and:</p>
<ol>
<li><strong>Understand the role of text editors</strong>: Recognize the importance of text
editors in the command-line environment for saving commands, writing
scripts, and editing configuration files.</li>
<li><strong>Differentiate between text editors</strong>: Identify key differences between
line editors like <code>ed</code> and visual editors like <code>vim</code>, <code>nano</code>, <code>micro</code>, and
<code>tilde</code>.</li>
<li><strong>Operate a line editor</strong>: Use basic commands in <code>ed</code>, such as addressing
lines, manipulating text, and editing files.</li>
<li><strong>Explore the functionality of <code>vim</code></strong>: Understand the basic modal operation
of <code>vim</code>, including command mode, insert mode, and how to integrate shell
commands within the editor.</li>
<li><strong>Utilize beginner-friendly editors</strong>: Comfortably use <code>nano</code>, <code>micro</code>,
<code>tilde</code>, and <code>edit</code> for straightforward text editing tasks, taking advantage of their
user-friendly key bindings and interfaces.</li>
<li><strong>Appreciate historical context</strong>: Recognize the historical significance of
<code>ed</code> and <code>vim</code> and how their development has influenced modern computing
practices.</li>
</ol>
<h2 id="getting-started-3"><a class="header" href="#getting-started-3">Getting Started</a></h2>
<p>Working on the command line means writing a lot of commands.
There will be times when we want to save some of the commands that we write in order to re-use them later.
Or, we might want to develop the commands into a script (i.e., a program) because we want to automate a process.
The shell is great for writing one off commands, so-called <strong>one-liners</strong>, but
it's not a great place to write multi-line or very long commands.
Therefore it can be helpful to write and save our commands in a text editor.</p>
<p>Another thing to keep in mind is that the shell that we are working with is called <code>bash</code>, and
<code>bash</code> is a full-fledged programming language.
That means that when we write a simple command, like <code>cd public_html</code>, we are programming.
It makes sense that the more programming that we do, the better we'll get at it.
This requires  more sophisticated environments to help manage our programs than the command line prompt can provide.
Text editors fulfill that role.</p>
<p>As we learn more about how to do systems administration with Linux, we will need to edit configuration files, too.
Most configuration files exist in the <code>/etc</code> directory.
For example, later in the semester we will install the <a href="https://httpd.apache.org/">Apache Web Server</a>, and
we will need to edit Apache's configuration files in the process.
We could do this using some of the tools that we've already covered, like <code>sed</code> and <code>awk</code>, but
it'll make our lives much easier to use a text editor.</p>
<p>In any case, in order to save our commands or edit text files, a text editor is very helpful.
Programmers use text editors to write programs, but programmers often work in graphical user environments,
so they often use GUI text editors or <a href="https://en.wikipedia.org/wiki/Integrated_development_environment">IDE</a>s.
As systems administrators, it would be unusual to have a graphical user interface installed on a server.
The servers that we manage contain limited or specific software that serves the server's main purpose.
Additional software on a server that is not relevant to its main function only takes up extra disk space,
consumes valuable computing resources, and poses an additional <a href="https://en.wikipedia.org/wiki/Attack_surface">security footprint</a>.</p>
<p>In this lesson, we'll learn about several text editors: <code>ed</code>, <code>vim</code>, <code>nano</code>, <code>micro</code>, <code>tilde</code>, and <code>edit</code>.
We cover <code>ed</code> primarily for its historical importance, and its descendant, <code>vim</code>,
which is a powerful editor that is widely used today, but these editors have high learning curves.
<code>emacs</code> is another common text editor that can be used on the command line, but it also has a learning curve, and
I am not covering it here.
For simplicity, I will encourage you to use <code>nano</code>, <code>micro</code>, <code>tilde</code>, or <code>edit</code>, but
if you continue to use the command line, you should learn more advanced editors like <code>vim</code> or <code>emacs</code>.</p>
<h2 id="ed"><a class="header" href="#ed"><code>ed</code></a></h2>
<p><code>ed</code> is a line editor that is installed by default on many Linux distributions.
Ken Thompson created <code>ed</code> in the late 1960s to write the original Unix operating system.
It was used without computer monitors because those were still uncommon, and
instead for <a href="https://en.wikipedia.org/wiki/Teleprinter">teletypewriters (TTYs)</a> and <a href="https://www.youtube.com/watch?v=S81GyMKH7zw">printers</a>.
The lack of a visual display, like a monitor, is the reason that <code>ed</code> was written as a line editor.
If you visit that second link, you will see the terminal interface from those earlier days.
It is the same basic interface you are using now when you use your terminal applications, which
are virtualized versions of those old teletypewriters.
I think this is a testament of the power of the terminal:
that advanced computer users still use the same basic technology today.</p>
<p>In practice, when we use a line editor like <code>ed</code>, the main process of entering text is like any other editor.
The big difference is when we need to manipulate text.
In a graphical text editor, if we want to delete a word or edit some text,
we might backspace over the text or highlight a word and delete it.
In a line editor, we manipulate text by referring to lines or across multiple lines and
then run commands on the text in those line(s).
This is process we followed when we covered <code>grep</code>, <code>sed</code>, and <code>awk</code>, and especially <code>sed</code>, and
it should not surprise you that <a href="https://www.oreilly.com/library/view/sed-awk/1565922255/ch02s01.html">these are related to ed</a>.</p>
<p>To operationalize this, like in <code>sed</code>, each line has an <strong>address</strong>.
The address for line 7 is <strong>7</strong>, and so forth.
Line editors like <code>ed</code> are command driven.
There is no menu to select from at the top of the <em>window</em>.
In fact, when we used <code>ed</code> to open an existing file, the text in the file isn't even printed on the screen.
If a user wants to delete a word, or print (to screen) some text,
the user has to command the line editor to print the relevant line.
We do this by specifying the line's address and issuing a command to delete the word on that line, or print the line.
Line editors also work on ranges of line, including all the lines in the file, just like <code>sed</code> does.</p>
<p>Many of the commands that <code>ed</code> uses are also used by <code>sed</code>, since <code>sed</code> is based on <code>ed</code>.
The following table compares commands between these two programs:</p>
<div class="table-wrapper"><table><thead><tr><th>Command</th><th><code>sed</code></th><th><code>ed</code></th></tr></thead><tbody>
<tr><td>append text</td><td><code>a</code></td><td><code>a</code></td></tr>
<tr><td>replace text</td><td><code>c</code></td><td><code>c</code></td></tr>
<tr><td>delete text</td><td><code>d</code></td><td><code>d</code></td></tr>
<tr><td>insert text</td><td><code>i</code></td><td><code>i</code></td></tr>
<tr><td>print text</td><td><code>p</code></td><td><code>p</code></td></tr>
<tr><td>substitute text</td><td><code>s</code></td><td><code>s</code></td></tr>
<tr><td>print w/ line #</td><td><code>=</code></td><td><code>n</code></td></tr>
</tbody></table>
</div>
<p>However, there are big differences that mainly relate to the fact that <code>ed</code> is a text editor and <code>sed</code> is not (really).
For example, here are some commands that mostly make sense in <code>ed</code> as a text editor.
<code>sed</code> can do some of these tasks, where it makes sense (e.g., we don't quit <code>sed</code>), but sometimes in a non-trivial way.</p>
<div class="table-wrapper"><table><thead><tr><th>Command</th><th><code>ed</code> only</th></tr></thead><tbody>
<tr><td>edit file</td><td><code>e</code></td></tr>
<tr><td>join lines</td><td><code>j</code></td></tr>
<tr><td>copies lines</td><td><code>t</code></td></tr>
<tr><td>moves lines</td><td><code>m</code></td></tr>
<tr><td>undo</td><td><code>u</code></td></tr>
<tr><td>saves file</td><td><code>w</code></td></tr>
<tr><td>quits <code>ed</code> before saving</td><td><code>q</code></td></tr>
<tr><td>Quits <code>ed</code> w/o saving</td><td><code>Q</code></td></tr>
</tbody></table>
</div>
<p>There are other differences, but these are sufficient for our purposes.</p>
<p>Let's see how to use <code>ed</code> to open a file, and print the content without (<code>1,$p</code>) and with (<code>1,$n</code>) line numbers.</p>
<pre><code>ed operating-systems.csv
183
1,$p
OS, License, Year
Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
1,$n
1 OS, License, Year
2 Chrome OS, Proprietary, 2009
3	FreeBSD, BSD, 1993
4	Linux, GPL, 1991
5	iOS, Proprietary, 2007
6	macOS, Proprietary, 2001
7	Windows NT, Proprietary, 1993
8	Android, Apache, 2008
</code></pre>
<p>Using <code>ed</code>, we can remove the header line of the <strong>operating-systems.csv</strong> file by specifying the line number (<code>1</code>),
and issuing the delete command (<code>d</code>), just like in <code>sed</code>.
This becomes a permanent change if I save the file with the <code>w</code> (write) command:</p>
<pre><code>1d
1,$p
Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>To refer to line <strong>ranges</strong>, I add a comma between <strong>addresses</strong>.
Therefore, to delete lines 1, 2, and 3, and then quit <strong>without saving</strong>:</p>
<pre><code>1,3d
,p
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
Q
</code></pre>
<p>Note that with <code>sed</code>, in order to make a change <strong>in-place</strong>, we need to use the <code>-i</code> option.
But with <code>ed</code>, we save changes with the <code>w</code> (write) command.</p>
<pre><code>ed operating-systems.csv
183
1,3d
,p
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
w
</code></pre>
<p>I can use <code>ed</code> to <strong>find and replace</strong> strings.
The syntax is the same as it is in <code>sed</code>.
I'll start with a fresh version of the file:</p>
<pre><code>1,$s/Linux/GNU\/Linux/
</code></pre>
<p>If we want to add new rows to the file, we can append <code>a</code> or insert <code>i</code> text after or at specific lines.
To append text after line 3, use <code>a</code>.
We enter a period on a newline to leave input mode and return to command mode:</p>
<pre><code>3a
FreeDOS, GPL, 1998
.
</code></pre>
<p>Because we enter input mode when using the <code>a</code>, <code>i</code>, or <code>c</code> commands,
we enter a period <code>.</code> on a line by itself to revert to command mode.</p>
<p>To insert at line 2, use <code>i</code>:</p>
<pre><code>2i
CP/M, Proprietary, 1974
.
</code></pre>
<p>Like <code>sed</code>, we can also <strong>find and replace</strong> using regular expressions instead of line numbers.
I start a new <code>ed</code> session to reload the file to start fresh:</p>
<pre><code>ed operating-systems.csv
183
/Linux/s/Linux/GNU\/Linux/
</code></pre>
<p>Of course, <code>ed</code> can be used to write and not simply edit files.
Let's start fresh.
In the following session,
I'll start <code>ed</code>, enter append mode <code>a</code>, write a short letter, exit append mode <code>.</code>,
name the file <code>f</code>, write <code>w</code> (save) the file, and quit <code>q</code>:</p>
<pre><code>ed
a
Dear Students,

I hope you find this really interesting.
Feel free to practice and play on the command line,
as well as use tools like ed, the standard editor.

Sincerely,
Dr. Burns
.
f letter.txt
w
q
</code></pre>
<p>It's good to know something about <code>ed</code> for historical reasons and
because the line editing technology developed for it is still in use today,
as seen with commands like <code>grep</code> and <code>sed</code>.
It is also a basic part of the design of the <code>vim</code> text editor.</p>
<h2 id="vim"><a class="header" href="#vim"><code>vim</code></a></h2>
<p>The <code>vim</code> text editor is a descendant of <code>ed</code>.
Generally, we started with <code>ed</code>, which influenced the creation of <a href="https://en.wikipedia.org/wiki/Vi">vi</a>, which led eventually to <code>vim</code>,
aka, <strong>Vi IMproved</strong>.
The original <code>vi</code> text editor was recreated and is available as the <code>nvi</code> editor.
Due to this genealogy, <code>vim</code> uses many of the same commands as <code>ed</code> does when <code>vim</code> is in command mode.
Like <code>ed</code>, we can start <code>vim</code> at the <code>bash</code> prompt with or without a file name.
Here I open the <strong>letter.txt</strong> file with <code>vim</code>.
The default mode is <strong>command mode</strong>:</p>
<pre><code>vim letter.txt
Dear Students,

I hope you find this really interesting.
Feel free to practice and play on the command line,
as well as use tools like ed, the standard editor.

Sincerely,
Dr. Burns
</code></pre>
<p>To enter <strong>insert mode</strong>, I can type <code>i</code> or <code>a</code> for <strong>insert</strong> or <strong>append</strong> mode.
There isn't any difference on an empty file, but on a file that has text,
<code>i</code> will start <strong>insert</strong> mode before the cursor position, and <code>a</code> will <strong>insert</strong> mode after the cursor position.
Once in <strong>insert</strong> mode, you can type text as you normally would and use the arrow keys to navigate around the file.</p>
<p>To return to <strong>command mode</strong> in <code>vim</code>, you press the <strong>Esc</strong> key.
And then you can enter commands like you would with <code>ed</code>, using the same syntax.</p>
<p>Unlike <code>ed</code>, when in <strong>command mode</strong>, the commands we type are not placed wherever the cursor is,
but at the bottom of the screen.
Let's first turn on line numbers to know which address is which, and then we'll replace <strong>ed</strong> with <strong>Ed</strong>.
Note that I precede these commands with a colon:</p>
<pre><code>:set number
:5s/ed/Ed/
</code></pre>
<p>One of the more powerful things about both <code>ed</code> and <code>vim</code> is that I can call <code>bash</code> shell commands from the editors.
Let's say that I want to add the date to my letter file.
To do that, Linux has a command called <code>date</code> that will return today's date and time.
To call the <code>date</code> command within <code>vim</code> and insert the output into the file:
I press <strong>Esc</strong> to enter <strong>command mode</strong> (if I'm not already in it),
enter a colon, type <code>r</code> for the <em>read into buffer</em> command,
then enter the shell escape command, which is an exclamation point <code>!</code>, and then the <code>bash</code> shell <code>date</code> command:</p>
<pre><code>:r !date
Dear Students,

I hope you find this really interesting.
Feel free to practice and play on the command line,
as well as use tools like ed, the standard editor.
Thu Jun 30 02:44:08 PM EDT 2022

Sincerely,
Dr. Burns
</code></pre>
<p>Since the last edit I made was to replace <strong>ed</strong> with <strong>Ed</strong>, <code>vim</code> entered the date after that line, which is line 6.
To move that date line to the top of the letter, I can use the move <code>m</code> command and move it to line 0, which is the top of the file:</p>
<pre><code>:6m0
Thu Jun 30 02:44:30 PM EDT 2022
Dear Students,

I hope you find this really interesting.
Feel free to practice and play on the command line,
as well as use tools like Ed, the standard editor.

Sincerely,
Dr. Burns
</code></pre>
<p>You can use the arrow keys and Page Up/Page Down keys to navigate in <code>vim</code>,
but by far the most excellent thing about this editor is to be able to use the <strong>j,k,l,h</strong> keys to navigate around a file:</p>
<ul>
<li><code>j</code> moves down line by line</li>
<li><code>k</code> moves up line by line</li>
<li><code>l</code> moves right letter by letter</li>
<li><code>h</code> moves left letter by letter</li>
</ul>
<p>Like the other commands, you can precede this with addresses.
To move 2 lines down, you type <code>2j</code>, and so forth.
<code>vim</code> has had such a powerful impact on software development that programmers have built these keystrokes
into applications like Gmail, Facebook, and more.</p>
<p>To save the file and exit <code>vim</code>, return to <strong>command mode</strong> by pressing the <code>Esc</code> key, and then write and quit:</p>
<pre><code>:wq
</code></pre>
<p>The above barely scratches the surface.
There are whole books on these editors as well as websites, videos, etc that explore them in more detail.</p>
<h2 id="nano"><a class="header" href="#nano"><code>nano</code></a></h2>
<p>The <code>nano</code> text editor is the user-friendliest of these text editors.
The friendliest thing about <code>nano</code> is that it is <a href="https://en.wikipedia.org/wiki/Mode_(user_interface)">modeless</a>.
You're already accustomed to using modeless editors in GUI apps.
Modeless simply means that you can add and manipulate text without changing to insert or command mode.
It is also familiar because it uses control keys to perform its operations.
The tricky part is that the control keys are assigned to different keystroke combinations than what many might be used to.
For example, instead of Ctrl-c or Cmd-c to copy,
in <code>nano</code> you press the <code>M-6</code> key (press <code>Alt</code>, <code>Cmd</code>, or <code>Esc</code> key and <code>6</code>) to copy.
Then to paste, you press <code>Ctrl-u</code> instead of the more common <code>Ctrl-v</code>.
Fortunately, <code>nano</code> lists the shortcuts at the bottom of the screen.</p>
<p>The shortcuts listed need some explanation.
The carat mark is shorthand for the keyboard's <strong>Control (Ctrl)</strong> key.
Therefore to <strong>Save As</strong> a file, we <strong>write</strong> out the file by pressing <code>Ctrl-o</code>.
The <strong>M-</strong> key is also important, and depending on your keyboard configuration,
it may correspond to your <code>Alt</code>, <code>Cmd</code>, or <code>Esc</code> keys.
To search for text, you press <code>^W</code>, If your goal is to copy, then press <strong>M-6</strong> to copy a line.
Move to where you want to paste the text, and press <strong>Ctrl-u</strong> to paste.</p>
<p>For the purposes of this class, that's all you really need to know about <code>nano</code>.
Use it and get comfortable writing in it.
Some quick tips:</p>
<ol>
<li><code>nano file.txt</code> will open and display the file named <strong>file.txt</strong>.</li>
<li><code>nano</code> by itself will open to an empty page.</li>
<li>Save a file by pressing <code>Ctrl-o</code>.</li>
<li>Quit and save by pressing <code>Ctrl-x</code>.</li>
<li>Be sure to follow the prompts at the bottom of the screen.</li>
</ol>
<h2 id="micro-and-tilde"><a class="header" href="#micro-and-tilde"><code>micro</code> and <code>tilde</code></a></h2>
<p><code>nano</code> is usually installed by default on many Linux distributions, which is why I cover it here.
However, if you want to use a more modern modeless editor, then I suggest <code>micro</code>, <code>tilde</code>, or <code>edit</code>.</p>
<p>The following <code>apt</code> command installs both <code>micro</code> and <code>tilde</code> at the same time.</p>
<pre><code>sudo apt install micro tilde
</code></pre>
<p>We can launch them with or without file names.
To launch <code>micro</code> without a file name as an argument:</p>
<pre><code>micro
</code></pre>
<p>To launch <code>tilde</code>:</p>
<pre><code>tilde
</code></pre>
<p>The <a href="https://micro-editor.github.io/">micro</a> text editor uses standard key combinations like
<strong>Ctrl-S</strong> to save, <strong>Ctrl-O</strong> to open, <strong>Ctrl-Q</strong> to quit.
The <a href="https://os.ghalkes.nl/tilde/">tilde</a> text editor also uses the standard key combinations, but it also has a menu bar.
To access the menu bar, you press the <strong>Alt</strong> key plus the first letter of the menu bar option.
For example, <strong>Alt-f</strong> opens the <strong>File Menu</strong>, etc.</p>
<h2 id="edit"><a class="header" href="#edit"><code>edit</code></a></h2>
<p>The <a href="https://github.com/microsoft/edit">edit</a> text editor is a new, open source editor from Microsoft that's
inspired by the original MS-DOS editor from the early 1990s.
Although it is built for use on Windows, it can be installed on Linux.
To install, visit the program's <a href="https://github.com/microsoft/edit/releases/tag/v1.2.0">GitHub releases</a> link and copy the URL for the file named:
<strong>edit-[version]-x86-64-linux-gnu.tar.zst</strong>, where <strong>[version]</strong> equals the most recent version.
We can use <code>wget</code> to download the source file to our servers.
For example, to download the most recent version, which at the time of writing this is version <code>1.2.0</code>:</p>
<pre><code>wget https://github.com/microsoft/edit/releases/download/v1.2.0/edit-1.2.0-x86_64-linux-gnu.tar.zst
</code></pre>
<p>The file is compressed.
To decompress it, we use the following <code>tar</code> command:</p>
<pre><code>tar --use-compress-program=unzstd -xvf edit-1.2.0-x86_64-linux-gnu.tar.zst
</code></pre>
<p>This will output a file called <code>edit</code>.
Move this file to an executable <code>$PATH</code>, such as <code>/usr/local/bin</code>:</p>
<pre><code>sudo mv edit /usr/local/bin
</code></pre>
<p>Once moved, you can use <code>edit</code> to work with files like you would with <code>micro</code> or <code>tilde</code>.</p>
<pre><code>edit [file_name]
</code></pre>
<p>Note that the GitHub page for <code>edit</code> provides instructions for installing this editor on Windows,
in case you're interested in doing so.</p>
<h2 id="conclusion-9"><a class="header" href="#conclusion-9">Conclusion</a></h2>
<p>In prior lessons, we learned how to use the <code>bash</code> command prompt and how to view, manipulate, and
edit files from that shell.
In this lesson, we learned how to use several command line text editors.
Editors allow us to save our commands, create scripts, and in the future, edit configuration files.</p>
<p>The commands we used in this lesson include:</p>
<ul>
<li><code>ed</code> : line-oriented text editor</li>
<li><code>vim</code> : Vi IMproved, a programmer's text editor</li>
<li><code>nano</code> : Nano's ANOther editor, inspired by Pico</li>
<li><code>micro</code>: A modern and intuitive terminal-based text editor</li>
<li><code>tilde</code>: The Tilde Text Editor</li>
<li><code>edit</code>: Microsoft text editor</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="using-git-for-documentation"><a class="header" href="#using-git-for-documentation">Using Git for Documentation</a></h2>
<p>It's a challenge to manage and document complex systems, but
it's essential to keep a record of how we change or alter our systems,
how we configure them, and how we automate them.
It's essential because we administer systems for ourselves and for others, and
keeping records allows us to build off our or others prior work.</p>
<p>Maintaining documentation is also an important part of identifying points of failure in our systems.
For example, we might change some configuration files, and
one of those changes might lead to an <a href="https://en.wikipedia.org/wiki/2024_CrowdStrike-related_IT_outages">eventual system failure</a>.
In such a scenario,
documenting our changes can help us track and identify the culprit file and the location in that file.</p>
<p>Documentation in systems administration generally includes documenting
configuration files, automation scripts, server deployment guides, and maintenance procedures.
This work serves as a crucial reference point for teams; i.e.,
it ensures consistency in system management and eases the onboarding process for new administrators.</p>
<p>Git is a distributed version control system used to track changes and manage versions of text files.
We use Git because it is robust, versatile, and widely used.
Although it is more commonly used for software developers, it's not limited that usage.</p>
<p>In this section, we learn how to use Git to maintain and enhance documentation in a sysadmin context.
This will only be an intro to Git, but key areas of discussion include:</p>
<ul>
<li>Utilizing Git for version control of configuration files and scripts.</li>
<li>Employing best practices for documenting system configurations.</li>
</ul>
<h3 id="understanding-file-naming-conventions"><a class="header" href="#understanding-file-naming-conventions">Understanding File Naming Conventions</a></h3>
<p>First, it's important to standardize around file naming, especially for newly created files.
File naming is a fundamental aspect of organizing and maintaining a clear documentation system, and
adhering to a consistent naming convention is important for several reasons:</p>
<ol>
<li><strong>Clarity and Accessibility</strong>: Well-named files are easier to identify and
understand at a glance. This saves time and reduces confusion.</li>
<li><strong>System Compatibility</strong>: Certain characters in file names can cause issues
in different operating systems. Avoid spaces and special characters to ensure broader compatibility.</li>
<li><strong>Ease of Navigation</strong>: Consistent naming aids in navigating through files.
This is especially important in a large directory or Git repository.</li>
<li><strong>Version Control</strong>: Clear naming policies helps in tracking changes and managing versions more effectively.</li>
</ol>
<p>When naming files, it's best to follow the guidelines below.
I use the <code>md</code> extension to identify these files as Markdown files, but
regardless of file type, these guidelines are broadly applicable to all file names:</p>
<ul>
<li>Use single words or combine words using camelCase, underscores (<code>_</code>), or hyphens (<code>-</code>). For example:
<ul>
<li><code>ServerSetupGuide.md</code>,</li>
<li><code>server_setup_guide.md</code>, or</li>
<li><code>server-setup-guide.md</code>.</li>
</ul>
</li>
<li>Avoid spaces because they can cause issues in URLs and command-line operations.
For example, do not name a file like this:
<ul>
<li>server setup guide.md</li>
</ul>
</li>
<li>Avoid special characters in file names, such as <code>!</code>, <code>$</code>, <code>#</code>, <code>%</code>, etc.
These characters often have specific functions in certain environments or scripts, like the <code>bash</code> shell.</li>
</ul>
<h4 id="use-markdown"><a class="header" href="#use-markdown">Use Markdown</a></h4>
<p>We will use Markdown syntax in our documentation work.
Markdown is a widely used markup language to format text, and
files written in Markdown can be converted to HTML, DOCX, PPTX, PDF, and more.
Plus, if you use GitHub, files written in Markdown will automatically render into HTML.</p>
<h3 id="basic-markdown-tutorial"><a class="header" href="#basic-markdown-tutorial">Basic Markdown Tutorial</a></h3>
<p>Here's a quick guide to the most commonly used Markdown syntax, but
see the <a href="https://www.markdownguide.org/">Markdown Guide</a> for full details.</p>
<h4 id="headings"><a class="header" href="#headings">Headings</a></h4>
<p>Headings are created using the <code>#</code> symbol before your text.
The number of <code>#</code> symbols indicates the level of the heading.
Use headings to broadly structure your documents.</p>
<pre><code># Heading 1
## Heading 2
### Heading 3
#### Heading 4
##### Heading 5
###### Heading 6
</code></pre>
<p>Use the Heading 1 only once in a document, and then other heading levels for sections and subsections.
As an example:</p>
<pre><code># Apache Web Server Documentation

Some introductory text here.

## Installing Apache

Some text on installing Apache here.

## Configuring Apache

Some text on configuring Apache here.

## Starting Apache

Some text on starting Apache here.
</code></pre>
<h4 id="emphasis"><a class="header" href="#emphasis">Emphasis</a></h4>
<ul>
<li><strong>Bold</strong>: To make text bold, wrap text in double asterisks or double underscores.
For example, <code>**bold**</code> or <code>__bold__</code>.</li>
<li><em>Italic</em>: To italicize text, wrap it in single asterisks or single underscores.
For example, <code>*italic*</code> or <code>_italic_</code>.</li>
</ul>
<h4 id="lists"><a class="header" href="#lists">Lists</a></h4>
<ul>
<li>
<p><strong>Unordered Lists</strong>: Use asterisks, plus signs, or hyphens to create bullet points.</p>
</li>
<li>
<p>Nest lists using extra indentation.</p>
<pre><code>* Item
* Item
  * Subitem
  * Subitem
</code></pre>
</li>
<li>
<p><strong>Ordered Lists</strong>: Use numbers followed by periods for an ordered list.</p>
<pre><code>1. First item
2. Second item
   1. Subitem 2.1
   2. Subitem 2.2
</code></pre>
</li>
<li>
<p>Ordered Lists: Alternate numbered and lettered lists:</p>
<pre><code>1. First item
2. Second item
   a. Subitem 2.a
   b. Subitem 2.b
</code></pre>
</li>
<li>
<p>Ordered Lists: Alternate numbered and unordered lists:</p>
<pre><code>1. First item
2. Second item
   - Subitem
   - Subitem
</code></pre>
</li>
</ul>
<h4 id="links-and-images"><a class="header" href="#links-and-images">Links and Images</a></h4>
<ul>
<li><strong>Links</strong>: To create a link, wrap the link text in brackets <code>[ ]</code>, and then wrap the URL in parentheses <code>( )</code>.
<ul>
<li>For example, to link to GitHub.com: <code>[GitHub](https://github.com)</code></li>
</ul>
</li>
<li><strong>Images</strong>: Use similarly to links, but start with an exclamation mark, followed by
the alt text in brackets, and the URL in parentheses.
The <code>URL</code> is simply the location to the file.
It can be a location in your current directory or a location on the web.
If you're linking to an image file in your directory, use the <strong>relative path</strong> to the file
(relative from the repository's base directory).
If you're linking to an image on the web, use the full web address, beginning with <strong>https</strong>.</li>
<li>Examples:
<ul>
<li>Linking to an image file in the current directory:
<ul>
<li>For example, <code>![Alt text](image-url.jpg)</code></li>
</ul>
</li>
<li>Linking to an image file in a directory named <code>images</code> in the current directory's:
<ul>
<li>For example, <code>![Alt text](images/image-url.jpg)</code></li>
</ul>
</li>
<li>Linking to an image file on the web:
<ul>
<li>For example, <code>![Alt text](http://example.com/images/image-url.jpg)</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="code"><a class="header" href="#code">Code</a></h4>
<ul>
<li>
<p><strong>Inline Code</strong>: Use this small snippets of code in your main text;
use backticks to wrap your code: <code>`code`</code>.</p>
</li>
<li>
<p><strong>Code Blocks</strong>: For larger sections of code, use three backticks or indent with four spaces on separate lines.</p>
<p>```<br />
your code here<br />
```</p>
</li>
</ul>
<h4 id="blockquotes"><a class="header" href="#blockquotes">Blockquotes</a></h4>
<p>To create a blockquote, use the <code>&gt;</code> symbol before your text.
For nested blockquotes, use multiple <code>&gt;</code> symbols.</p>
<pre><code class="language-markdown">&gt; This is a blockquote.
&gt;&gt; This is a nested blockquote.
</code></pre>
<h4 id="horizontal-rules"><a class="header" href="#horizontal-rules">Horizontal Rules</a></h4>
<p>Create a horizontal line or rule by using three or more asterisks, dashes, or
underscores on a new line.</p>
<pre><code class="language-markdown">---
</code></pre>
<h4 id="additional-tips"><a class="header" href="#additional-tips">Additional Tips</a></h4>
<ul>
<li><strong>Whitespace and Line Breaks</strong>: To create a new line without starting a new paragraph by
ending a line with two or more spaces before hitting Enter.</li>
<li><strong>Escaping Markdown</strong>: To display a Markdown character, precede it with a
backslash (<code>\</code>). For example, <code>\*not italic\*</code>.</li>
</ul>
<p>Markdown's makes formatted text simple and readable, and is thus a great choice for for documentation and note-taking.
As you become more comfortable with these basics,
you'll find it a versatile tool for your writing needs.</p>
<h2 id="using-git"><a class="header" href="#using-git">Using Git</a></h2>
<h3 id="check-installed"><a class="header" href="#check-installed">Check Installed</a></h3>
<p>To begin to use <code>git</code>, log in to your remote system, and make sure <code>git</code> installed with the <code>which</code> command:</p>
<pre><code>which git
</code></pre>
<p>If the output produces a path to <code>git</code>, like <code>/usr/bin/git</code>, then it's installed.</p>
<p>If it's not installed, then you can install it with the <code>apt</code> command:</p>
<pre><code>sudo apt install git
</code></pre>
<h3 id="configuring-git"><a class="header" href="#configuring-git">Configuring Git</a></h3>
<p><strong>Note:</strong> The following <code>git</code> tutorial is based on the <a href="https://git-scm.com/docs/gittutorial">Git Documentation</a>.</p>
<p>First we want to configure <code>git</code> so that when we create or change files, it can track who made those changes.
We do that with the <code>git config</code> command.
We configure <code>git</code> by inputting our name:</p>
<pre><code>git config --global user.name "Sean Burns"
</code></pre>
<p>And then we add our email address:</p>
<pre><code>git config --global user.email sean@example.com
</code></pre>
<blockquote>
<p>Use your personal email address and not your work or university email address.
That way, it'll be easier to maintain your repository over the long run if you decide later to use a service like GitHub.</p>
</blockquote>
<p>We instruct <code>git</code> to use <code>main</code> as the name of our main branch:</p>
<pre><code>git config --global init.defaultBranch main
</code></pre>
<p>Finally, we can instruct <code>git</code> to use a specific editor when writing commit messages:</p>
<pre><code>git config --global core.editor micro
</code></pre>
<p>The above configurations will serve our purposes, but if interested,
more <code>git config</code> options are listed in the <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Configuration">documentation</a>.</p>
<h3 id="creating-and-initializing-a-project"><a class="header" href="#creating-and-initializing-a-project">Creating and Initializing a Project</a></h3>
<p>We absolutely <strong>do not want Git to manage our home directory</strong>, but
we do want it to manage a project directory in our home directory.
Let's start off by creating a directory for our project.
I'll call my directory <code>docs</code>, but you can use any name.
Be sure to use a good name (no spaces, no special characters, etc.):</p>
<pre><code>mkdir ~/docs
</code></pre>
<p>Then change to the <code>docs</code> directory:</p>
<pre><code>cd ~/docs
</code></pre>
<p>Next we initialize the project directory, which places all content in this directory under revision control:</p>
<pre><code>git init
</code></pre>
<p>If you run the <code>ls -a</code> command, you will see a new hidden directory called <code>.git</code>.
In most cases, you don't do anything with this directory.
It's mainly where <code>git</code> keeps tabs of changes in your project directory.</p>
<h3 id="adding-content"><a class="header" href="#adding-content">Adding Content</a></h3>
<p>Using your text editor of choice, create a new file.
In the following example, I'll create and open a file called <code>lamp.md</code> using the <code>vim</code> text editor.
Use whichever text editor you like.
Be sure you're still in your project directory.</p>
<pre><code>vim lamp.md
</code></pre>
<p>Add some content, and then save and exit.
I'll add just a simple header line:</p>
<pre><code># LAMP Documentation
</code></pre>
<p>We can use the <code>git status</code> command to view how <code>git</code> sees the changes:</p>
<pre><code>git status
</code></pre>
<p>Read the output closely.
The output names your branch, notes that changes have not been staged,
instructs you how to stage them (<code>git add</code>), instructs you how to undo the changes
(<code>git restore &lt;file&gt;</code>), and tells you which files have been modified.</p>
<p>Now we can instruct <code>git</code> to stage the new content, which means that <code>git</code> takes a snapshot of the changes:</p>
<pre><code>git add lamp.md
</code></pre>
<p>The <code>git add</code> command <strong>stages</strong> the new content.
Run the <code>git status</code> command again, and it shows you which files have been staged and need to be committed.
It also shows the command to undo the staged changes (<code>git restore --stage &lt;file&gt;</code>).</p>
<p>We permanently track the content using the <code>git commit -m</code> command.
The <code>-m</code> option allows us to enter a commit message, which is placed inside quotes.
This message should be relatively brief, but it should describe the changes you made:</p>
<pre><code>git commit -m "created lamp.md doc file and added header info"
</code></pre>
<p>Finally, running the <code>git status</code> command will show that there's nothing to commit, aka, all is done.</p>
<h3 id="tracking-changes"><a class="header" href="#tracking-changes">Tracking Changes</a></h3>
<p>Now that we've made a commit to our project, we can use the <code>git log</code> command to view our <code>git</code> history:</p>
<pre><code>git log
</code></pre>
<p>We can see how this log changes when we edit our file.
In the example below, I re-open the file and add a date to it:</p>
<pre><code>vim lamp.md
</code></pre>
<p>Add date to file, then save and exit:</p>
<pre><code># LAMP Documentation

August 24, 2025
</code></pre>
<p>Re-stage the new content:</p>
<pre><code>git add lamp.md
</code></pre>
<blockquote>
<p>If you have made changes to multiple files, you can name all the files with <code>git add</code>,
like so: <code>git add file1.md file2.md file3.md</code>, or you can make changes to all files at once:
<code>git add .</code></p>
</blockquote>
<p>Before committing the content, you can see a <strong>diff</strong> of the changes:</p>
<pre><code>git diff --cached
</code></pre>
<p>If satisfied, you can now commit the changes:</p>
<pre><code>git commit -m "added date to file"
</code></pre>
<p>Now you can see the new commit message in the logs:</p>
<pre><code>git log
</code></pre>
<p>You can see the difference between the changes in the file with the following command:</p>
<pre><code>git log -p
</code></pre>
<p>And you can view a more detailed summary of commits:</p>
<pre><code>git log --stat --summary
</code></pre>
<h3 id="undoing-committed-changes-pre-commit"><a class="header" href="#undoing-committed-changes-pre-commit">Undoing Committed Changes: Pre-Commit</a></h3>
<p>Sometimes we realize that we do not want to commit a change even after we've saved the file(s).
The following two commands are useful for undoing changes <strong>after files have been staged</strong> but <strong>before files are committed</strong>.</p>
<p>First, let's add a new line to our file:</p>
<pre><code># LAMP Documentation

August 24, 2025

There are my notes.
</code></pre>
<p>Then stage the file:</p>
<pre><code>git add lamp.md
</code></pre>
<p>If we run <code>git status &lt;file&gt;</code>, we'll see that the file has been staged but not committed.
The following command unstages the file:</p>
<pre><code>git restore --staged &lt;file&gt;
</code></pre>
<p>Once the file has been unstaged, we can use the following command to restore the file to its last commit version:</p>
<pre><code>git restore &lt;file&gt;
</code></pre>
<p>We saw how files were modified with <code>git diff</code> command.
In the following command, we can see how unstaged content has changed based on the prior commit:</p>
<pre><code>git diff HEAD
</code></pre>
<p>After staging a file, you can use the <code>git diff</code> command to see how content has changed in a file:</p>
<pre><code>git diff --cached
</code></pre>
<h4 id="summary"><a class="header" href="#summary">Summary</a></h4>
<ul>
<li><code>git restore --staged &lt;file&gt;</code> : uncommits a file(s)</li>
<li><code>git restore &lt;file&gt;</code> : restores file to last committed version</li>
</ul>
<h3 id="undoing-committed-changes-post-commit"><a class="header" href="#undoing-committed-changes-post-commit">Undoing Committed Changes: Post-Commit</a></h3>
<p>If we need to undo a change after content has been committed with <code>git commit -m</code>,
then we have to use the <code>git reset</code> command.
This makes sense when you view the output of <code>git log</code>, which only shows changes that have been committed,
and not changes to files that have simply been modified or staged.
When content has been modified and committed, the changes have become part of the version history.
Thus to undo a committed change, we have to undo the history that <code>git</code> tracks.
In some cases, especially when collaborating with others, this can have serious implications,
which is why we have a separate command for undoing commits.</p>
<p>There are several ways to undo a commit with <code>git reset</code>.
To undo the most recent commit, we can use the following command,
which puts the file back into staged version.</p>
<pre><code>git reset --soft HEAD~1
</code></pre>
<p>Likewise, to undo the two most recent commits, we change the number to 2:</p>
<pre><code>git reset --soft HEAD~2
</code></pre>
<p>With the <code>--soft</code> option, all changes to files remain, but the commit history is cleared.</p>
<p>We can use the following command to undo changes permanently:</p>
<pre><code>git reset --hard &lt;commit_numer&gt;
</code></pre>
<p>The commit number can be found in the output of <code>git log</code>, and we only need the first eight digits:</p>
<pre><code>git log
</code></pre>
<p>And the output is something like:</p>
<pre><code>commit 048cd90e48036b82667e46d5b2ded21fa86c0e80 (HEAD -&gt; main)
Author: Sean Burns &lt;email@example.com&gt;
Date: Sun Aug 24 10:58:50 2025 --400

    &lt;commit message&gt;

commit 0062b4c187b8096857373f7880315e8e9aa8ce9c
Author: Sean Burns &lt;email@example.com&gt;
Date:   Sun Aug 24 10:54:34 2025 -0400

    created lamp.md doc file and added header info
</code></pre>
<p>To revert back to the first commit:</p>
<pre><code>git reset --hard 0062b4c1
</code></pre>
<p>Now, all changes to the file have been undone except for the changes made when the file was first created.
We can see that with the following <code>git log</code> command:</p>
<pre><code>git log
</code></pre>
<p>Output:</p>
<pre><code>commit 0062b4c187b8096857373f7880315e8e9aa8ce9c
Author: Sean Burns &lt;email@example.com&gt;
Date:   Sun Aug 24 10:54:34 2025 -0400

    created lamp.md doc file and added header info
</code></pre>
<p>Before we reset the version history, you can use <code>git diff</code> with those commit numbers.
In the following, I compare a prior version with the most recent commit ("HEAD"):</p>
<pre><code>git diff 048cd90e HEAD
</code></pre>
<p>Be careful about using <code>git reset</code> because you could lose important changes.</p>
<h3 id="git-workflow"><a class="header" href="#git-workflow">Git Workflow</a></h3>
<p>The benefit of <code>git</code> is in developing a workflow with it.
Basically, for a single person, we follow these steps:</p>
<p>For a new project:</p>
<ol>
<li><code>mkdir project_directory</code> : create a new project directory</li>
<li><code>cd project_directory</code> : change to the new project directory</li>
<li><code>git init</code> : initialize project directory</li>
</ol>
<p><code>git init</code> only needs to be run once.
Afterwards, for working in that project directory:</p>
<ol>
<li>Edit a text file with your text editor of choice, and save and quit the editor when done.</li>
<li><code>git add &lt;file&gt;</code></li>
<li><code>git commit -m "commit message"</code></li>
</ol>
<p>If necessary, use the undo commands when or if necessary:</p>
<ol>
<li><code>git restore &lt;file&gt;</code> : after editing</li>
<li><code>git restore --stage &lt;file&gt; : undo after staging with </code>git add`</li>
<li><code>git reset --soft HEAD~1</code> : undo the most recent commit, saving all changes to files</li>
<li><code>git reset --hard &lt;commit_number&gt; : undo to the commit number (based on </code>git log`), undoing all file changes</li>
</ol>
<h2 id="conclusion-10"><a class="header" href="#conclusion-10">Conclusion</a></h2>
<p>In summary, Git is powerful tool for documentation and version control.
For sysadmins, <code>git</code> is useful for managing configuration files, automation scripts,
server deployment guides, maintenance procedures, and probably more.</p>
<p>Remember to:</p>
<ol>
<li>Adhere to clear file naming conventions.</li>
<li>Use Markdown formatting for structuring and documenting content in files.</li>
</ol>
<p>And most importantly, start documenting everything with a <code>git</code> based workflow.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bash-scripting"><a class="header" href="#bash-scripting">Bash Scripting</a></h1>
<p>By the end of this section, you will:</p>
<ol>
<li>Understand Bash as both a command and scripting language: Recognize the dual
functionality of Bash, allowing you to automate tasks and manage scripts
efficiently within a Linux environment.</li>
<li>Work with variables and arrays in Bash: Learn to declare and use variables,
apply command substitution, and manage arrays for more complex scripting
tasks.</li>
<li>Apply conditional expressions for decision-making: Use conditional operators
such as &amp;&amp;, ||, and if; then; else statements to control the flow of your
scripts based on conditions and outcomes.</li>
<li>Implement loops to automate repetitive tasks: Utilize looping structures,
such as for, to automate actions that need to be repeated under certain
conditions or across arrays.</li>
<li>Write and execute Bash scripts with the correct structure: Include essential
elements like the shebang (<code>#!/usr/bin/env bash</code>) at the start of your
scripts, ensuring portability and clarity in execution.</li>
<li>Test conditions in Bash scripts: Understand how to test for specific
conditions in scripts, such as file existence or the comparison of
variables, to build more reliable and functional scripts.</li>
<li>Validate and improve Bash scripts: Learn how to use tools like <code>shellcheck</code> to
check for errors in your Bash scripts and ensure adherence to best practices
through style guides.</li>
</ol>
<h2 id="getting-started-4"><a class="header" href="#getting-started-4">Getting Started</a></h2>
<p>It's time to get started on Bash scripting.
So far, we've been working on the Linux commandline.
Specifically, we have been working in the <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash</a> shell.
Wikipedia refers to Bash as a <strong>command language</strong>.
This means that Bash is used as a commandline language but also as a scripting language.
The main purpose of Bash is to write small applications/scripts that analyze text (e.g., log files) and automate jobs.
However, it can be used for a variety of other purposes.</p>
<h2 id="variables"><a class="header" href="#variables">Variables</a></h2>
<p>One of the most important abilities of any programming or scripting language is to be able to declare a variable.
Variables enable us to attach some value to a name.
That value may be temporary, and it's used to pass information to other parts of a program.</p>
<p>In Bash, we declare a variable with the name of the variable, an equal sign, and then the value of the variable within double quotes.
Do not insert spaces between the variable and assignment.
In the following code snippet, which can be entered on the commandline, I create a variable named <code>NAME</code> and assign it the value <code>Sean</code>.
I create another variable named <code>BACKUP</code>  and assign it the value <code>/media</code>.
Then I use the <code>echo</code> and <code>cd</code> commands to test the variables:</p>
<pre><code>NAME="Sean"
BACKUP="/media"
echo "My name is ${NAME}"
echo "${BACKUP}"
cd "${BACKUP}"
pwd
cd
</code></pre>
<p>Variables may include values that may change given some context.
For example, if we want a variable to refer to today's day of week, we can use <a href="https://www.gnu.org/software/bash/manual/html_node/Command-Substitution.html">command substitution</a>.
This "allows the output of a command to replace the command name" (see <code>man bash</code>).
In the following, I use the <code>date +%A</code> command to assign the current day of the week to the variable named <strong>TODAY</strong>.
The output at the time this variable is set will differ if it is set on a different day.</p>
<pre><code>TODAY="$(date +%A)"
echo "${TODAY}"
</code></pre>
<blockquote>
<p>By default, variables in Bash are global.
If you are working within functions and want a variable to only be available within the function,
you can declare it as local using <code>local var_name=value</code>.</p>
</blockquote>
<p>Curly braces are not strictly necessary when calling a Bash variable, but they offer benefits when we start to use things like <a href="https://tldp.org/LDP/Bash-Beginners-Guide/html/sect_10_02.html">array variables</a>.
See:</p>
<ul>
<li><a href="https://www.howtogeek.com/725657/how-to-use-brace-expansion-in-linuxs-bash-shell/">How to use curly braces in Bash</a></li>
<li><a href="https://www.linuxjournal.com/content/bash-brace-expansion">Brace Expansion</a></li>
</ul>
<p>For example, let's look at basic <strong>brace expansion</strong>, which can be used to generate arbitrary strings:</p>
<pre><code>echo {1..5}
echo {5..1}
echo {a..l}
echo {l..a}
</code></pre>
<p>Another example: using brace notation, we can generate multiple sub-directories at once.
Start off in your home directory, and:</p>
<pre><code>mkdir -p homework/{drafts,notes}
cd homework
ls
</code></pre>
<p>But more than that, they allow us to deal with arrays (or lists).
Here I create a variable named <code>seasons</code>, which holds an <strong>array</strong>, or multiple values: <code>winter spring summer fall</code>.
Bash lets me access parts of that array.
In the following the <code>[@]</code> refers to the entire array and the <code>[n]</code> refers to subscript in the array.</p>
<pre><code>seasons=(winter spring summer fall)
echo "${seasons[@]}"
echo "${seasons[1]}"
echo "${seasons[2]}"
echo "${seasons[-1]}"
</code></pre>
<p>See <a href="https://devhints.io/bash#parameter-expansion">Parameter expansions</a> for more advanced techniques.</p>
<h2 id="conditional-expressions"><a class="header" href="#conditional-expressions">Conditional Expressions</a></h2>
<p>Whether working on the commandline, or writing scripts in a text editor, it's sometimes useful to be able to write multiple commands on one line.
There are several ways to do that.
We can include a list of commands on one line in Bash where each command is separated by a semicolon.
In the following example, the <code>cd</code> command will run and then the <code>ls -lt</code> command will run.</p>
<pre><code>cd ; ls -lt
</code></pre>
<p>We can also use <a href="https://ss64.com/bash/syntax-execute.html">conditional expressions</a> and apply logic with <code>&amp;&amp;</code> (<strong>Logical AND</strong>) or <code>||</code> (<strong>Logical OR</strong>).</p>
<p>Here, <code>command2</code> is executed if and only if <code>command1</code> is successful:</p>
<pre><code>command1 &amp;&amp; command2
</code></pre>
<p>Here, <code>command2</code> is executed if and only if <code>command1</code> fails:</p>
<pre><code>command1 || command2
</code></pre>
<p>In essence, <code>&amp;&amp;</code> and <code>||</code> are short-circuit operators.
This means that if the first command in <code>command1 &amp;&amp; command2</code> fails, <code>command2</code> <strong>will not</strong> be executed.
Conversely, if the first command in <code>command1 || command2</code> succeeds, <code>command2</code> <strong>will</strong> be executed.</p>
<p>In the example below, lines starting with a <code>#</code> indicate a comment that is not evaluated by <code>bash</code>:</p>
<pre><code># if documents/ does not exist, then the echo statement will not run
cd documents &amp;&amp; echo "success" 
# if documents/ does not exist, then the echo statement will run
cd documents || echo "failed"
</code></pre>
<p>We can combine these operators:</p>
<pre><code>cd test &amp;&amp; pwd || echo "no such directory"
mkdir test
cd test &amp;&amp; pwd || echo "no such directory"
</code></pre>
<h2 id="shebang-or-hashbang"><a class="header" href="#shebang-or-hashbang">Shebang or Hashbang</a></h2>
<p>When we start to write scripts, the first thing we add is a <a href="https://en.wikipedia.org/wiki/Shebang_(Unix)">shebang</a> or hashbang at line one.
The {she,hash}bang tells the shell what program needs to run.
We can do declare it a couple of ways.
First, we can use the path to <code>env</code>, which runs the program in a modified environment that is named after <code>env</code>.
In the following {she,hash}bang, we declare that modified environment to be the <code>bash</code> shell:</p>
<pre><code>#!/usr/bin/env bash
</code></pre>
<blockquote>
<p>If we were writing a Python script, then we could declare it to be: <code>#!/usr/bin/env python3</code>.</p>
</blockquote>
<p>The above is more portable, but alternatively, you could put the direct path to Bash:</p>
<pre><code>#!/usr/bin/bash
</code></pre>
<blockquote>
<p>On <a href="https://posix.opengroup.org/">POSIX</a> compliant systems, the <code>env</code> program should always be located at <code>/usr/bin/env</code>.
However, even on POSIX compliant systems, <code>bash</code> may be located in different paths.
On some Linux distributions, it's located at <code>/usr/bin/bash</code>.
On others, it may be located at <code>/bin/bash</code>.
On BSD OSes, like FreeBSD, <code>bash</code> might be installed at <code>/usr/local/bin/bash</code>.
Thus, by using the <code>#!/usr/bin/env bash</code> shebang, you help ensure that your <code>bash</code> program is portable across different OSes.</p>
</blockquote>
<p>Even for small scripts, it's helpful to follow a consistent style.
A well-written script is easier to maintain and understand.
Consider checking out style guides early on, like the <a href="https://google.github.io/styleguide/shellguide.html">Google Shell Style Guide</a>.
This will help ensure your scripts remain clean and readable.</p>
<h2 id="looping"><a class="header" href="#looping">Looping</a></h2>
<p>Looping is a common way to repeat an instruction until some specified condition is met.
There are several looping methods in Bash that include: : <code>for</code>, <code>while</code>, <code>until</code>, and <code>select</code>.
The <code>for</code> loop is often the most useful.
In the following toy looping example, we instruct <code>bash</code> to assign the letter <strong>i</strong> to the sequence <strong>1,2,3,4,5</strong>.
Each time it assigns <strong>i</strong> to those numbers, it <code>echo</code>s them to standard output:</p>
<pre><code>for i in {1..5} ; do
  echo "i = ${i}"
done
</code></pre>
<blockquote>
<p>Note that I take advantage of brace expansion in the above for loop.</p>
</blockquote>
<p>You might notice in the <code>echo</code> statement above that I use <code>${i}</code> instead of <code>$i</code>.
While the latter is possible, using <code>${i}</code> ensures proper variable expansion, particularly when using loops within strings or complex expressions.
For example, <code>${}</code> ensures that <code>i</code> is correctly interpreted as a variable and not part of a larger string.</p>
<p>Using the above <code>for</code> loop, we can create a rudimentary timer by calling the <code>sleep</code> command to pause after each count:</p>
<pre><code>for i in {5..1} ; do
  echo "T minus ${i}" &amp;&amp; sleep 1
done ; echo "BLAST OFF!"
</code></pre>
<blockquote>
<p>Note that I take advantage of brace expansion again, but this time
reversing the ordering, as well as conditional execution.</p>
</blockquote>
<p>The <code>sleep</code> command is particularly useful in automation tasks where you want to pause execution between steps, such as monitoring scripts,
where you might poll a resource at intervals, or in timed alerts.</p>
<p>We can loop through the variable arrays, too.
In the following <code>for</code> loop, I loop through the <strong>seasons</strong> variable first introduced above:</p>
<pre><code>#!/usr/bin/env bash

seasons=(winter spring summer fall)
for i in "${seasons[@]}" ; do
  echo "I hope you have a nice ${i}."
done
</code></pre>
<blockquote>
<p>Note that I added the {she,hash}bang in the above example.
I do this to make it clear that this is the kind of <code>for</code> loop that I would want to write in a text editor.</p>
</blockquote>
<h2 id="testing"><a class="header" href="#testing">Testing</a></h2>
<p>Sometimes we will want to test certain conditions.
There are two parts to this, we can use <code>if; then ; else</code> commands, and we can also use the double square brackets: <code>[[</code>.
There are a few ways to get documentation on these functions.
See the following:</p>
<pre><code>man test
help test
help [
help [[
help if
</code></pre>
<blockquote>
<p>Between <code>[</code> and <code>[[</code>, I generally prefer to use the <code>[[</code> syntax, as demonstrated below.
It's less error-prone and allows for more complex conditional checks.
However, <code>[[</code> is specific to <code>bash</code> and thus slightly less portable than <code>[</code>.</p>
</blockquote>
<p>We can test integers:</p>
<pre><code>if [[ 5 -ge 3 ]] ; then
  echo "true"
else
  echo "false"
fi
</code></pre>
<p>Reverse it to return the else statement:</p>
<pre><code>if [[ 3 -ge 5 ]] ; then
  echo "true"
else
  echo "false"
fi
</code></pre>
<p>We can test strings.
Run the command <code>nano amihome.sh</code> and type the script below into the file.
Save and exit.
Change the file's permissions: <code>chmod 766 amihome.sh</code>.
Then move the file to <code>/usr/local/bin</code> with the following command:
<code>sudo mv amihome.sh /usr/local/bin</code></p>
<pre><code>#!/usr/bin/env bash

if [[ "$HOME" = "$PWD" ]] ; then
 echo "You are home."
else
 echo "You are not home, but I will take you there."
 cd "$HOME" || exit
 echo "You are now $PWD."
 pwd
fi
</code></pre>
<p>Now you can run the file by typing at the command prompt: <code>amihome.sh</code>.</p>
<p><strong>IMPORTANT</strong>: Running the above commands in a script won't result in changing your directory
outside the script to your home directory.
This is because of what Bash calls <code>subshells</code>.
Subshells are a forked processes.
So the script will do things in those other directories, but once the script exits,
you will remain in the directory where you ran the script.
If you want to execute a script in the current shell so that changes like <code>cd</code> persist after the script runs,
you can use the <code>source</code> command to run the script.
For example:</p>
<pre><code>source script.sh
</code></pre>
<p>We can test file conditions.
Let's first create a file called <strong>paper.txt</strong> and a file called <strong>paper.bak</strong>.
We will add some trivial content to <strong>paper.txt</strong> but not to the <strong>paper.bak</strong>.
The following <code>if</code> statement will test if <strong>paper.txt</strong>  has a more recent modification date.
If so, it'll back up the file with the <code>cp</code> and echo back its success:</p>
<pre><code>if [[ "$HOME/paper.txt" -nt "$HOME/paper.bak" ]] ; then
  cp "$HOME/paper.txt" "$HOME/paper.bak" &amp;&amp; echo "Paper is backed up."
fi
</code></pre>
<p>Here's a script that prints info depending on which day of the week it is.
Let's save it in a text file and call it <code>schedule.sh</code>:</p>
<pre><code>#!/usr/bin/env bash

day1="Tue"
day2="Thu"
day3="$(date +%a)"

if [[ "$day3" = "$day1" ]] ; then
  printf "\nIf %s is %s, then class is at 9:30am.\n" "$day3" "$day1"
elif [[ "$day3" = "$day2" ]] ; then
  printf "\nIf %s is %s, then class is at 9:30am.\n" "$day3" "$day2"
else
  printf "\nThere is no class today."
fi
</code></pre>
<p>Finally, you can check your shell scripts using the <code>shellcheck</code> shell script analysis tool.
First you will need to install it:</p>
<pre><code>sudo apt -y install shellcheck
</code></pre>
<p>Then use it on shell script files you create.
For example, let's say I have a script in a file named <strong>backup.sh</strong>, I can use the <code>shellcheck</code> command to find any errors:</p>
<pre><code>shellcheck backup.sh
</code></pre>
<p>If there are errors, <code>shellcheck</code> will tell you what they are and provide a link to documentation on the error.</p>
<p>If you become seriously interested in <code>bash</code> scripting, then you should check out the various style guides that exist.
For example, see the <a href="https://google.github.io/styleguide/shellguide.html">Shell Style Guide</a> that was authored by coders at Google.</p>
<h2 id="resources"><a class="header" href="#resources">Resources</a></h2>
<p>I encourage you to explore some useful guides and cheat sheets on Bash scripting:</p>
<ul>
<li><a href="https://tldp.org/LDP/abs/html/index.html">Advanced Bash-Scripting Guide</a></li>
<li><a href="https://devhints.io/bash">Bash scripting cheatsheet</a></li>
<li><a href="https://www.shellcheck.net/">Bash shellcheck</a></li>
<li><a href="https://www.freecodecamp.org/news/shell-scripting-crash-course-how-to-write-bash-scripts-in-linux/">Shell Scripting for Beginners</a></li>
<li><a href="https://fedoramagazine.org/bash-shell-scripting-for-beginners-part-1/">Bash Shell Scripting for Beginners</a></li>
<li><a href="https://cs.lmu.edu/~ray/notes/bash/">Introduction to Bash</a></li>
</ul>
<h2 id="conclusion-11"><a class="header" href="#conclusion-11">Conclusion</a></h2>
<p>In this lecture, we've covered the basics of Bash scripting, including working with variables, loops, and conditionals.
These tools form the foundation for automating tasks and creating powerful scripts.
Continue practicing by writing small scripts for your own workflow, and explore the resources and style guides provided to deepen your understanding.</p>
<h2 id="summary-1"><a class="header" href="#summary-1">Summary</a></h2>
<p>In this demo, we learned about:</p>
<ul>
<li>creating and referring to variables</li>
<li>conditional expressions with <code>&amp;&amp;</code> and <code>||</code></li>
<li>adding the <strong>shebang</strong> or <strong>hashbang</strong> at the beginning of a script</li>
<li>looping with the <code>for</code> statement</li>
<li>testing with the <code>if</code> statement</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="managing-the-system"><a class="header" href="#managing-the-system">Managing the System</a></h1>
<p>Now that we have the basics of the command line interface down, it's time to learn some systems administration.
In this section, we learn how to:</p>
<ul>
<li>expand storage space</li>
<li>create new user and group accounts and manage those accounts</li>
<li>install and remove software, and</li>
<li>manage that software and other processes.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="expanding-storage"><a class="header" href="#expanding-storage">Expanding Storage</a></h1>
<p>By the end of this section, you will be able to:</p>
<ol>
<li><strong>Understand Virtual Machine Storage Expansion</strong>: Gain practical knowledge on how to add additional storage to a virtual machine (VM) by creating and attaching a persistent disk.</li>
<li><strong>Disk Formatting and Mounting</strong>: Learn the process of formatting a non-boot disk with the <strong>ext4</strong> filesystem and mounting it to a VM for expanded storage capacity.</li>
<li><strong>Filesystem Configuration</strong>: Develop skills in configuring a VM's filesystem for automatic mounting using the <code>/etc/fstab</code> file to ensure persistence across reboots.</li>
<li><strong>Efficient Resource Management</strong>: Understand how to delete unnecessary disks and manage cloud storage costs, ensuring efficient use of resources.</li>
<li><strong>Command Line Proficiency</strong>: Improve proficiency with essential command line tools such as <code>mkfs.ext4</code>, <code>mount</code>, <code>umount</code>, <code>mkdir</code>, and editing configuration files with a text editor.</li>
<li><strong>Storage Pricing Awareness</strong>: Gain insight into the cost considerations of adding additional storage in cloud environments, with practical examples of pricing.</li>
</ol>
<h2 id="getting-started-5"><a class="header" href="#getting-started-5">Getting Started</a></h2>
<p>I'm sure all or most of you have needed extra disk storage at some point (USB drives, optical disks, floppies???).
Such needs are no different for systems administrators, who often are responsible for managing, monitoring, or storing large amounts of data.</p>
<p>The disk that we created for our VM is small (10 GB), and that's fine for our needs, albeit quite small in many real world scenarios.
To address this, we can add a persistent disk that is much larger.
In this section, we will add a disk to our VM, mount it onto the VM's filesystem, and format it.
Extra storage does incur extra cost.
So at the end of this section, I will show you how to delete the extra disk to avoid that if you want.</p>
<p>We will essentially follow the Google Cloud tutorial to add a non-boot disk to our VM, but with some modification:</p>
<p><a href="https://cloud.google.com/compute/docs/disks/add-persistent-disk">Add a persistent disk to your VM</a></p>
<blockquote>
<p>Note: the main disk used by our VM is the <strong>boot disk</strong>.
The boot disk contains the
software required to boot the system.
All of our computers (desktops, laptops, tablets, phones, etc.),regardless of which operating system they run, have some kind of boot system.</p>
</blockquote>
<h2 id="creating-a-disk"><a class="header" href="#creating-a-disk">Creating a Disk</a></h2>
<p>In the Google Cloud console, first make sure you are working in your course project.
Then navigate to <strong>Compute Engine</strong>, and visit the <strong>Disks</strong> page in the <strong>Storage</strong> section.
If asked, click on <strong>Enable</strong> for Compute Engine API, which may take a minute or so to enable.</p>
<p>Once there, follow these steps:</p>
<ol>
<li>Note down the <strong>Zone</strong> for the current disk, which is your boot disk (e.g., mine is <strong>us-central1-c</strong>).</li>
<li>Click on <strong>CREATE DISK</strong>.</li>
<li>Under <strong>Name</strong>, add a preferred name.
<ul>
<li>For example, you can name it <strong>backup1</strong>.</li>
</ul>
</li>
<li>Under <strong>Location</strong>, choose <strong>Single zone</strong>.
<ul>
<li>This is about data safety, which we are not concerned about for a course project. If we were, then we would select other options here.</li>
</ul>
</li>
<li>Select the same <strong>Zone</strong> (and thus <strong>Region</strong>) as your VM instance.
<ul>
<li>This is important because with our current configuration, we can't use disks in different regions and zones.</li>
</ul>
</li>
<li>Under <strong>Source</strong>, select <strong>Blank disk</strong>.</li>
<li>Under <strong>Disk settings</strong>, select <strong>Balanced persistent disk</strong>.</li>
<li>Under <strong>Size</strong>, change this to 10GB.
<ul>
<li>You can actually choose larger sizes, but be aware that <a href="https://cloud.google.com/compute/all-pricing#disk">disk pricing</a> is $0.10 per GB.</li>
<li>At that cost, 100 GB = $10 / month.</li>
</ul>
</li>
<li>Under <strong>Data Protection</strong>, click on <strong>Enable snapshot schedule</strong>.</li>
<li>Under <strong>Encryption</strong>, make sure <strong>Google-managed encryption key</strong> is selected.</li>
<li>Click <strong>Create</strong> to create your disk, and then wait while the disk is created.</li>
</ol>
<h2 id="adding-the-disk-to-our-vm"><a class="header" href="#adding-the-disk-to-our-vm">Adding the Disk to our VM</a></h2>
<p>Now that we have created our disk, we need to <strong>mount</strong> it onto our filesystem so that it's available to our VM.
Conceptually, this process is like inserting a new USB drive into our computer.</p>
<p>To add the new disk to our VM, follow these steps:</p>
<ol>
<li>Return and select <strong>Compute Engine</strong> from the sidebar and then visit the <strong>VM instances page</strong>.</li>
<li>Click on the <strong>Name</strong> of your VM. This takes you to the <strong>VM instance details</strong> page.</li>
<li>Click on the <strong>Edit</strong> button at the top of the details page.</li>
<li>Scroll down to the <strong>Additional disks</strong> section, and click on <strong>+ ATTACH EXISTING DISK</strong>.</li>
<li>A panel will open on the right side of your browser.</li>
<li>Click on the drop down box and select the disk, by name, you created.</li>
<li>Leave the defaults as-is.</li>
<li>Click on the <strong>SAVE</strong> button.</li>
<li>Then click on the <strong>SAVE</strong> button on the details page.</li>
</ol>
<p>If you return to the <strong>Disks</strong> page in the <strong>Storage</strong> section, you will now see that the new disk is in use by our VM.</p>
<h2 id="formatting-and-mounting-a-non-boot-disk"><a class="header" href="#formatting-and-mounting-a-non-boot-disk">Formatting and Mounting a Non-Boot Disk</a></h2>
<h3 id="formatting-our-disk"><a class="header" href="#formatting-our-disk">Formatting Our Disk</a></h3>
<p>In order for our VM to make use of the extra storage, the new drive must be formatted and mounted.
Different operating systems use different filesystem formats.
You may already know that macOS uses the <a href="https://support.apple.com/guide/disk-utility/file-system-formats-dsku19ed921c/mac">Apple File System (APFS)</a> by default and that Windows uses the <a href="https://docs.microsoft.com/en-us/windows-server/storage/file-server/ntfs-overview">New Technology File System (NTFS)</a>.
Linux is no different, but uses different file systems than macOS and Windows.
There are many formatting technologies that we can use in Linux, but we'll use the <a href="https://ext4.wiki.kernel.org/index.php/Main_Page">ext4 (fourth extended filesystem)</a> format.
This is recommended for Google Cloud, and it is also a stable and common one for Linux.</p>
<p>In this section, we will closely follow the steps outlined under the <a href="https://cloud.google.com/compute/docs/disks/add-persistent-disk"><strong>Formatting and mounting a non-boot disk on a Linux VM</strong></a> section.
I replicate those instructions below, but I highly encourage you to read through the instructions on Google Cloud and here:</p>
<ol>
<li>Use the <code>gcloud compute ssh</code> command that you have previously used to connect to your VM.</li>
<li>When you have connected to your VM, run the <code>lsblk</code> command.
<ul>
<li>You will see devices named <strong>loop0</strong>, etc.</li>
<li>For our purposes, these are devices are not interesting and can be safely ignored.</li>
<li>You can ignore them with either of the following commands:
<ul>
<li><code>lsblk -e 7</code> : This command removes all device numbers that have the number <strong>7</strong>.</li>
<li><code>lsblk | grep -v "^loop"</code> : This command uses <code>grep</code> to return devices without the name <strong>loop</strong> at the beginning of the line.</li>
</ul>
</li>
<li>For our purposes, we are interested in the drives named: <strong>sda</strong> and <strong>sdb</strong>.</li>
<li><strong>sda</strong> is the name of the main disk, which is also the boot disk.
<ul>
<li>This disk should have three partitions: <strong>sda1, sda14, sda15</strong>.</li>
<li>The <strong>MOUNTPOINT</strong> for <strong>sda1</strong> is <code>/</code>. This means that <strong>sda1</strong> is mounted at the root level of the filesystem.</li>
<li>Since it's mounted, this means it's in use. In fact, our filesystem (directory structure and files) are located in this partition.</li>
</ul>
</li>
<li><strong>sdb</strong> represents the attached disk we just added.
<ul>
<li>After we format this drive, there will be an <strong>sdb1</strong>, which signifies the drive has been partitioned.</li>
<li>After formatting, we will mount this partition on a different mountpoint.</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>To format our disk for the <strong>ext4</strong> filesystem, we will use the <code>mkfs.ext4</code> (see <code>man mkfs.ext4</code> for details).
The Google Cloud instructions tell us to run the command below.
(<strong>It's important to understand these commands as much as possible and not just copy and paste them</strong>):</p>
<pre><code>sudo mkfs.ext4 -m 0 -E lazy_itable_init=0,lazy_journal_init=0,discard /dev/DEVICE_NAME
</code></pre>
<p>But replace <strong>DEVICE_NAME</strong> with the name of our device.
My device's name is <strong>sdb</strong>, which we saw with the output of the <code>lsblk</code> command; therefore, the specific command I run is:</p>
<pre><code>sudo mkfs.ext4 -m 0 -E lazy_itable_init=0,lazy_journal_init=0,discard /dev/sdb
</code></pre>
<p>Again, please read <code>man mkfs.ext4</code> for details, but in short, the command and options above mean that we're creating a clean ext4 filesystem,
we're using all the disk space, we're fully wiping and initializing the filesystem structures and doing so up front, which is safer and slower), and
we clearing any unused space, which is good for SSDs.</p>
<h3 id="mounting-our-disk"><a class="header" href="#mounting-our-disk">Mounting Our Disk</a></h3>
<p>Now that our disk has been formatted in <strong>ext4</strong>, I can mount it.</p>
<blockquote>
<p>Note: to <strong>mount</strong> a disk simply means to make the disk's filesystem available so that we can use it for accessing, storing, etc files on the disk.
Whenever we insert a USB drive, a DVD drive, etc into our computers, the OS you use should mount that disk automatically so that you can access and use that disk.
Conversely, when we remove those drives, the OS <strong>unmounts</strong> them.
For our virtual machines, we have to manually mount the storage disk with the <code>mount</code> and unmount it with the <code>umount</code> command.
Note that the <code>umount</code> command is not <strong>unmount</strong>.</p>
</blockquote>
<p>You will recall that we have <a href="03-filesystem-file-management.html">discussed filesystems earlier</a> and
that the term is a bit confusing since it refers to both the directory hierarchy and also the formatting type (e.g., ext4).
I discussed how Windows assigns drives letters (<code>A:</code>, <code>B:</code>, etc.) when attaching new drives, like a USB drive.
Unlike Windows, I mentioned that in Linux and Unix (e.g., macOS), when we add an additional disk, its filesystem gets added onto our existing system.
That is, it becomes part of the directory hierarchy and under the <code>/</code> top level part of the hierarchy.
In practice, this means that we have to create the <strong>mountpoint</strong> for our new disk, and we do that first with the <code>mkdir</code> command.
The Google Console documentation instructs us to use the following command:</p>
<pre><code>sudo mkdir -p /mnt/disks/MOUNT_DIR
</code></pre>
<p>And to replace <strong>MOUNT_DIR</strong> with the directory we want to create.
Since my added disk is named <strong>disk-1</strong>, I'll call it that:</p>
<pre><code>sudo mkdir -p /mnt/disks/disk-1
</code></pre>
<p>Now we can <code>mount</code> the disk to that directory. Per the instructions on Google Console, and given that my added drive has the device name <strong>sdb</strong>,
I use the following command:</p>
<pre><code>sudo mount -o discard,defaults /dev/sdb /mnt/disks/disk-1
</code></pre>
<p>We also need to change the modifications, and grant access for additional users:</p>
<pre><code>sudo chmod 777 /mnt/disks/disk-1
</code></pre>
<p>We can test that it exists and is accessible with the <code>lsblk</code> and the <code>cd</code> commands.
The <code>lsblk</code> command should show that <strong>sdb</strong> is mounted at <code>/mnt/disks/disk-1</code>, and we can <code>cd</code> (change directory) to it:</p>
<pre><code>cd /mnt/disks/disk-1
</code></pre>
<h3 id="automounting-our-disk"><a class="header" href="#automounting-our-disk">Automounting Our Disk</a></h3>
<p>Our disk is mounted, but if the computer (VM) gets rebooted, we would have to manually re-mount the additional drive.
To avoid this and automount the drive upon reboot, we edit the <code>/etc/fstab</code> file.</p>
<blockquote>
<p>Note that the file is named <strong>fstab</strong> and that it's located in the <strong>/etc</strong> directory.
Therefore the full path is <code>/etc/fstab</code></p>
</blockquote>
<p>The <strong>fstab</strong> file is a configuration file that provides information to the OS about the filesystems the OS can mount and where.
The standard information <strong>fstab</strong> contains includes the name (or label) of the device being mounted,
the mountpoint (e.g., <code>/mnt/disks/disk-1</code>), the filesystem type (e.g., <strong>ext4</strong>), and various other mount options.
See <code>man fstab</code> for more details.
For devices to mount automatically upon boot, they have to be listed in this file.
That means we need to edit this file.</p>
<p>Again, here we're following the Google Cloud instructions:</p>
<p>Before we edit system configuration files, however, always create a backup.
We'll use the <code>cp</code> command to create a backup of the <strong>fstab</strong> file.</p>
<pre><code>sudo cp /etc/fstab /etc/fstab.backup
</code></pre>
<p>Next we use the <code>blkid</code> command to get the UUID (universally unique identifier) number for our new device.
Since my device is <code>/dev/sdb</code>, I'll use that:</p>
<pre><code>sudo blkid /dev/sdb
</code></pre>
<p>The output should look something like this <strong>BUT NOTE that your UUID value will be DIFFERENT</strong>:</p>
<pre><code>/dev/sdb: UUID="3bc141e2-9e1d-428c-b923-0f9vi99a1123" TYPE="ext4"
</code></pre>
<p>We need to add UUID to <code>/etc/fstab</code> plus other information.
The Google Cloud documentation explicitly guides us here.
We can add that directly to our <code>fstab</code> file by redirecting the output of the <code>blkid</code> command to that file.
<strong>NOTE and BEWARE: You have to use TWO ANGLE BRACKETS in the following command, or else you will ERASE the contents of that file!!!</strong></p>
<pre><code>sudo su
blkid /dev/sdb &gt;&gt; /etc/fstab
exit
</code></pre>
<blockquote>
<p>Alternatively, we can use <code>nano</code> to make the edit by copying and pasting the UUID at the end.</p>
</blockquote>
<p>And then edit the file with additional mount information at the bottom:</p>
<pre><code>sudo nano /etc/fstab
</code></pre>
<p>And then add the information:</p>
<pre><code>UUID=3bc141e2-9e1d-428c-b923-0f9vi99a1123 /mnt/disks/disk-1 ext4 discard,defaults,nofail 0 2
</code></pre>
<p>Save and exit <code>nano</code>.
And that's it!
If you reboot your VM, or if your VM rebooted for some reason, the extra drive we added should automatically mount upon reboot.
If it doesn't, then it may mean that the drive failed, or that there was an error (i.e., typo) in the configuration.</p>
<p>Let's check if it's automounted upon reboot:</p>
<pre><code>sudo reboot now
</code></pre>
<p>Wait a minute, and log back in to check.
Then run the <code>lsblk</code> command to see if the new drive is recognized and mounted at <code>/mnt/disks/disk-1</code>:</p>
<pre><code>lsblk
</code></pre>
<h3 id="delete-the-disk"><a class="header" href="#delete-the-disk">Delete the Disk</a></h3>
<p>You are welcome to keep the disk attached to the VM.
But if you do not want to incur any charges for it, which would be about $1 / month at 10 GB, then we can delete it.</p>
<p>To delete the disk, first delete the line that we added in <code>/etc/fstab</code>, unmount it, and then delete the disk in the Google Cloud console.</p>
<p>To unmount the disk, we use the <code>umount</code> command:</p>
<pre><code>sudo umount /mnt/disks/disk-1
</code></pre>
<p>Check if it's unmounted:</p>
<pre><code>lsblk
</code></pre>
<p>Then we need to delete the disk in the Google Cloud console.</p>
<ol>
<li>Go to the <strong>VM instances</strong> page.</li>
<li>Click on the VM instance's name, which should be a hyperlinked.</li>
<li>This goes to the <strong>VM instances detail</strong> page.</li>
<li>Click on the <strong>Edit</strong> button at the top of the page.</li>
<li>Scroll down to the <strong>Additional disks</strong> section.</li>
<li>Click the <strong>X</strong> to delete the additional disk.</li>
<li>Click on <strong>Save</strong>.</li>
<li>Return to <strong>Compute Engine</strong> and then the <strong>Disk</strong> section in the left-hand navigation pane.</li>
<li>Check the disk to delete, and then Delete it.
<ul>
<li>Make sure you delete the backup disk and not the main OS disk!</li>
</ul>
</li>
</ol>
<h2 id="conclusion-12"><a class="header" href="#conclusion-12">Conclusion</a></h2>
<p>In this section we learned how to expand the storage of our VM by creating a new virtual drive and adding it to our VM.
We also learned how to format the drive in the <strong>ext4</strong> filesystem format, and mount the drive at <code>/mnt/disks/disk-1</code>.
Finally, we learned how to then edit <code>/etc/fstab</code> to automount the drive.</p>
<p>In addition to using the Google Cloud console, the commands we used in this section include:</p>
<ol>
<li><code>ssh</code>  : to connect to the remote VM</li>
<li><code>sudo</code> : to run commands as the administrator</li>
<li><code>mkfs.ext4</code> : to create an <strong>ext4</strong> filesystem on our new drive</li>
<li><code>mkdir -p</code> : to create multiple directories under <code>/mnt</code></li>
<li><code>mount</code> : to mount manually the new drive</li>
<li><code>umount</code> : to unmount manually the new drive</li>
<li><code>chmod</code> : to change the mountpoint's file permission attributes</li>
<li><code>cd</code> : to change directories</li>
<li><code>cp</code> : to copy a file</li>
<li><code>nano</code> : to use the text editor <code>nano</code> to edit <code>/etc/fstab</code></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="managing-users-and-groups"><a class="header" href="#managing-users-and-groups">Managing Users and Groups</a></h1>
<ol>
<li><strong>Understanding User and Group Management</strong>: Learn how to create, modify, and delete user accounts and groups
on a Linux system using essential tools like <code>useradd</code>, <code>userdel</code>, <code>groupadd</code>, and <code>groupdel</code>.</li>
<li><strong>Working with System Files</strong>: Gain familiarity with critical system files like <code>/etc/passwd</code>, <code>/etc/shadow</code>, and
<code>/etc/group</code>, and understand how user, password, and group information is stored and managed.</li>
<li><strong>Customizing User Account Settings</strong>: Modify default settings for new user accounts by editing configuration files
such as <code>/etc/skel</code> and <code>/etc/adduser.conf</code> to allow for customization of new user environments.</li>
<li><strong>Password and Account Security</strong>: Develop skills in securing user accounts by setting password expiration policies and managing password lifetimes through the <code>/etc/shadow</code> file and commands like <code>passwd</code> and <code>chage</code>.</li>
<li><strong>Group-Based Permissions and Shared Resources</strong>: Learn to create and manage groups, assign users to groups, and configure shared directories with appropriate permissions to facilitate collaborative work among users.</li>
<li><strong>File Permissions and Directory Management</strong>: Understand how to change ownership and permissions of directories using tools like <code>chmod</code> and <code>chgrp</code> to control access based on user and group roles.</li>
<li><strong>Practical User Management Tools</strong>: Apply hands-on experience using utilities such as <code>gpasswd</code>, <code>su</code>, <code>sudo</code>, and
<code>nano</code> to manage users and groups, edit system files, and adjust account settings on a Linux system.</li>
</ol>
<h2 id="getting-started-6"><a class="header" href="#getting-started-6">Getting Started</a></h2>
<p>If you're like me, you have user accounts everywhere.
I have accounts on my phone and my laptop.
I have a Google account, a GitHub account, an account at my public library, an account at Costco.
I have a university account that let's me use the same login across multiple university systems, including email and our learning management systems.
I have a lot of user accounts, like you probably do.</p>
<p>For many of those accounts, I have access to some things and not to others.
For my university, I can submit grades to the registrar for my classes, but I can't submit grades to the registrar for my colleagues' classes.
Lots of professors serve on lots of committees.
I can access files for the committees I'm a member of, but not for those where I'm not a member.
However, various administrators, like my unit director, can access all those files.</p>
<p>In order to define what a user can do with their account, systems implement <strong>authentication</strong> and <strong>authorization</strong> mechanisms.
Authentication and authorization are fundamental concepts in system security and resource management, and they serve distinct but connected purposes.
<strong>Authentication</strong> is the process of verifying a user's identity.
When I attempt to login to my university system, it asks, "who are you?", and I reply with my credentials, which are my username and password.</p>
<p><strong>Authorization</strong> determines what an authenticated user is allowed to do.
Once I am authenticated on my university system, it asks, "what can you do?"
Then the system checks various permissions to allow certain actions and not others or access to certain resources and not others.</p>
<p>These basic concepts are true across all operating systems and services.
How these concepts are implemented vary, though.
In this section, we will learn about the commands that we use to <strong>authenticate</strong> and <strong>authorize</strong> users on a Linux server.</p>
<h2 id="the-man-pages"><a class="header" href="#the-man-pages">The <code>man</code> pages</a></h2>
<p>Before we begin, you need to know about the <code>man</code> pages.
The <code>man</code> (short for <em>manual</em>) pages are internal documentation on just about every part of your system.
You can read the manual for the commands on your system and for many of the special files on your system.
For example, you can read the manual on the <code>ls</code> command with <code>man ls</code>.
Or you can read the manual on the <code>chmod</code> command with <code>man chmod</code>.
You can also read the manual on the manual, which you'd invoke with the <code>man man</code> command.
Much of what I know about the commands in this book, I learned from their <code>man</code> pages, such as:</p>
<ul>
<li><code>man date</code></li>
<li><code>man glob</code></li>
<li><code>man grep</code></li>
<li><code>man bash</code></li>
<li><code>man regex</code></li>
<li>and more!</li>
</ul>
<p>The <code>man</code> pages are categorized by sections, which are explained in the <code>man man</code> page.
Each section is denoted by a number.
The first section, denoted by the number 1, contains <code>man</code> pages on executable programs or shell commands.
The fifth section, denoted by the number 5, contains <code>man</code> pages on file formats and conventions.
There are nine total sections.
In the case where a command and a system file each have the same name,
then we need to specify the section number when invoking <code>man</code> for those pages.
For example, use <code>man 1 crontab</code> to read the <code>man</code> page for the <code>crontab</code> executable, which is located at <code>/usr/bin/crontab</code>.
Use <code>man 5 crontab</code> to read the <code>man</code> page for the <strong>crontab</strong> file, which is locate at <code>/etc/crontab</code>.
At the bottom of many <code>man</code> pages,
there is a <strong>See Also</strong> section that helps to identify alternate manual pages for these commands.
We can also use the <code>apropos</code> command to identify <code>man</code> pages written across multiple sections.
For example, the <code>apropos crontab</code> command will show the following results:</p>
<pre><code>crontab (1)          - maintain crontab files for individual users (Vixie Cron)
crontab (5)          - tables for driving cron
</code></pre>
<p>You can make the <code>man</code> pages easier to read by installing an additional program called <code>bat</code>.
The <code>bat</code> program is a drop-in replacement for the <code>cat</code> command but comes with syntax highlighting and more.
To install <code>bat</code>, do:</p>
<pre><code>sudo apt install bat
</code></pre>
<p>Then use <code>nano</code> (or your favorite text editor) to open your <code>$HOME/.bashrc</code> file:</p>
<pre><code>nano $HOME/.bashrc
</code></pre>
<p>And add the following line at the end, which will add some color to the <code>man</code> pages:</p>
<pre><code>export MANPAGER="sh -c 'col -bx | batcat -l man -p'"
</code></pre>
<p>Once you've closed and saved your <code>$HOME/.bashrc</code> file, you need to source it:</p>
<pre><code>source $HOME/.bashrc
</code></pre>
<p>Now <code>man</code> pages will look better.</p>
<p>Additionally, since <code>bat</code> is a drop-in replacement for the <code>cat</code> command, you can also use it to view or concatenate files.
The full command is <code>batcat [FILE]</code>, where <strong>[FILE]</strong> is the name of the file or files to view.</p>
<h2 id="the-passwd-file"><a class="header" href="#the-passwd-file">The passwd file</a></h2>
<p>On every system there will be some place where information about users is stored.
On a Linux system, user account information is stored in the file <code>/etc/passwd</code>.
You should take a moment to read about this file in its <code>man</code> page.
However, if you run <code>man passwd</code>, you will by default get the <code>man</code> page on the <code>/usr/bin/passwd</code> command.
We want to read about the <strong>passwd</strong> file located at <code>/etc/passwd</code>,
which is in section 5, the section about file formats and conventions:</p>
<pre><code>man 5 passwd
</code></pre>
<p>Let's take a look at a single line of the file.
Below I show the output of my user account:</p>
<pre><code>grep "sean" /etc/passwd
</code></pre>
<p>And the output:</p>
<pre><code>sean:x:1000:1000:sean,,,:/home/sean:/bin/bash
</code></pre>
<p>Per the <code>man 5 passwd</code> page, we know that the line starting with <strong>sean</strong> is a colon separated line.
That means that the line is composed of multiple fields each separated by a colon (which is perfect for <code>awk</code> to parse).</p>
<p><code>man 5 passwd</code> tells us what each field indicates.
The first field is the login name, which in this case is <strong>sean</strong>.
The second field, marked <strong>x</strong>, marks the password field.
This file does not contain the password, though.
The passwords, which are <a href="https://auth0.com/blog/adding-salt-to-hashing-a-better-way-to-store-passwords/">hashed and salted</a>, for users are stored in the <code>/etc/shadow</code> file.
Th <code>/etc/shadow</code> file can only be read by the root user (or using the <code>sudo</code> command).</p>
<blockquote>
<p>Hashing a file or a string of text is a process of running a hashing algorithm on the file or text.
If the file or string is copied exactly, byte for byte, then hashing the copy will return the same value.
If anything has changed about the file or string, then the hash value will be different.
By implication, this means that if two users on a system use the same password, then the hash of each will be equivalent.
Salting a hashed file (or file name) or string of text is a process of adding random data to the file or string.
Each password will have a unique and mostly random salt added to it.
This means that even if two users on a system use the same password, salting their passwords will result in unique values.</p>
</blockquote>
<p>The third column indicates the user's numerical ID, and the fourth column indicates the users' group ID.
The fifth column repeats the login name, but could also serve as a comment field.
Comments are added using certain commands (discussed later).
The fifth field identifies the user's home directory, which is <strong>/home/sean</strong>.
The sixth field identifies the user's default shell, which is <code>/bin/bash</code>.</p>
<p>The <strong>user name or comment</strong> field merely repeats the login name here, but it can hold specific types of information.
We can add comments using the <code>chfn</code> command.
Comments include the user's full name, their home and work phone numbers, their office or room number, and so forth.
To add a full name to user <strong>sean</strong>'s account, we use the <strong>-f</strong> option:</p>
<pre><code>sudo chfn -f "Sean Burns" sean 
</code></pre>
<p>The <strong>/etc/passwd</strong> file is a standard Linux file, but data in the file will change depending on the Linux distribution.
For example, the user and group IDs above start at 1000 because <strong>sean</strong> is the first human account on the system.
This is a common starting numerical ID, but it could be different on other Linux or Unix-like distributions.
The home directory could be different on other systems, too;
for example, the default could be located at <strong>/usr/home/sean</strong>.
Also, other shells exist besides <code>bash</code>, like <a href="https://www.zsh.org/">zsh</a>, which is now the default shell on macOS;
so other systems may default to different shell environments.</p>
<h2 id="the-shadow-file"><a class="header" href="#the-shadow-file">The shadow file</a></h2>
<p>The <strong>/etc/passwd</strong> file does not contain any passwords but a simple <strong>x</strong> to mark the password field.
Passwords on Linux are stored in <strong>/etc/shadow</strong> and are hashed with <strong>sha512</strong>, which is indicated by <strong>$6$</strong>.
You need to be root to examine the shadow file or use <code>sudo</code>:</p>
<p>The fields are (see <code>man 5 shadow</code>):</p>
<ul>
<li>login name (username)</li>
<li>encrypted password</li>
<li>days since 1/1/1970 since password was last changed</li>
<li>days after which password must be changed</li>
<li>minimum password age</li>
<li>maximum password age</li>
<li>password warning period</li>
<li>password inactivity period</li>
<li>account expiration date</li>
<li>a reserved field</li>
</ul>
<p>The <strong>/etc/shadow</strong> file should not be edited directly.
If we want to set a warning that a user's password will expire,
we could use the <code>passwd</code> command (see <code>man passwd</code> for options), or the <code>chage</code> command.
The following command would make it so the user <strong>sean</strong> is warned that their password will expire in 14 days:</p>
<pre><code>passwd -w 14 sean 
</code></pre>
<p>Running this or the <code>chage</code> command will update the <code>/etc/shadow</code> file, but
it may also communicate the change to other parts of the system, depending on what's installed.
So again, do not directly edit the <code>/etc/shadow</code> file.</p>
<h2 id="the-group-file"><a class="header" href="#the-group-file">The group file</a></h2>
<p>The <strong>/etc/group</strong> file holds group information about the entire system (see <code>man 5 group</code>).
By default the file can be viewed by anyone on a system, but
there is also a <code>groups</code> command that will return the groups for a user (see: <code>man groups</code>).
Running the <code>groups</code> command by itself will return a list of group memberships your account belongs to.
One of those groups will be a group with the same name as your username.</p>
<h2 id="management-tools"><a class="header" href="#management-tools">Management Tools</a></h2>
<p>There are different ways to create new users and groups, and
the following list includes most of the utilities to help with this.
Note that, based on the names of the utilities, some of them are repetitive.</p>
<ul>
<li>useradd (8) - create a new user or update default new user information</li>
<li>usermod (8) - modify a user account</li>
<li>userdel (8) - delete a user account and related files</li>
<li>groupadd (8) - create a new group</li>
<li>groupdel (8) - delete a group</li>
<li>groupmod (8) - modify a group definition on the system</li>
<li>gpasswd (1) - administer /etc/group and /etc/gshadow</li>
<li>adduser.conf (5) - configuration file for adduser(8) and addgroup(8) .</li>
<li>adduser (8) - add a user or group to the system</li>
<li>deluser (8) - remove a user or group from the system</li>
<li>delgroup (8) - remove a user or group from the system</li>
<li>chgrp (1) - change group ownership</li>
</ul>
<p>The numbers within parentheses above indicate the <code>man</code> section.
Therefore, to view the man page for the <code>userdel</code> command:</p>
<pre><code>man 8 userdel
</code></pre>
<h2 id="authentication"><a class="header" href="#authentication">Authentication</a></h2>
<h3 id="modify-default-new-user-settings"><a class="header" href="#modify-default-new-user-settings">Modify default new user settings</a></h3>
<p>Let's modify some default user account settings for new users, and then we'll create a new user account.</p>
<p>Before we proceed, let's review some important configurations that establish some default settings:</p>
<ul>
<li><code>/etc/skel</code></li>
<li><code>/etc/adduser.conf</code></li>
</ul>
<p>The <code>/etc/skel</code> directory defines the home directory for new users.
Whatever files or directories exist in this directory at the time a new user account is created
will result in those files and directories being created in the new user's home directory.
In other words, the contents of this directory serve as a template for new user directories.
We can view the contents using the following command:</p>
<pre><code>ls -a /etc/skel/
</code></pre>
<p>The <code>/etc/adduser.conf</code> file defines the default parameters for new users.
It's in this file where the default starting user and group IDs are set,
where the default home directory is located (e.g., in <code>/home/</code>),
where the default shell is defined (e.g., <code>/bin/bash</code>),
where the default permissions are set for new home user directories (e.g., <code>0755</code>) and more.</p>
<p>Let's change some defaults for <code>/etc/skel</code>.
We need to use <code>sudo [command]</code> since this directory and its contents are owned by the <code>root</code> user.
First, we'll edit the default <strong>.bashrc</strong> file:</p>
<pre><code>sudo nano /etc/skel/.bashrc
</code></pre>
<p>We want to add the following lines at the end of the file.
This file is a configuration file for <code>/bin/bash</code>, and will be interpreted by Bash.
Lines starting with a hash mark are comments:</p>
<pre><code># Dear New User,
#
# I have made the following settings
# to make your life a bit easier:
#
# make "c" a shortcut for "clear"
alias c='clear'
</code></pre>
<p>Save and exit the file.</p>
<p>Use <code>nano</code> again to create a README file.
This file will be added to the home directories of all new users.
Add any welcome message you want to add, plus any guidelines for using the system.
Then save and exit the file.</p>
<pre><code>sudo nano /etc/skel/README
</code></pre>
<h3 id="add-new-user-account"><a class="header" href="#add-new-user-account">Add new user account</a></h3>
<p>After writing (saving) and exiting <code>nano</code>, we can go ahead and create a new user named <strong>linus</strong>.</p>
<pre><code>sudo adduser linus
</code></pre>
<p>We'll be prompted to enter a password for the new user, plus comments (full name, phone number, etc).
Any of these can be skipped by pressing enter.
You can see from the output of the <code>grep</code> command below that I added some extra information:</p>
<pre><code>grep "linus" /etc/passwd
linus:x:1003:1004:Linus Torvalds,333,555-123-4567,:/home/linus:/bin/bash
</code></pre>
<p>We may want to set up some password conditions to help keep the new user account secure.
To do that, we can modify the minimum days before the password can be changed, the maximum days before the password expires,
the number of days before the user gets a warning to change their password, and the number of days of inactivity when the password is locked.
The <code>passwd</code> command can set some of these parameters, but the <code>chage</code> command is a bit more powerful:</p>
<pre><code>sudo chage -m 7 -M 90 -W 14 -I 14 linus
</code></pre>
<p>See <code>man chage</code> for details, but:</p>
<ul>
<li><code>-m 7</code> sets the minimum password age to 7 days before the user can change their password.</li>
<li><code>-M 90</code> sets the maximum age of the password to 90 days.</li>
<li><code>-W 14</code> provides a 14 day warning to the user that the password will expire.</li>
<li><code>-I 14</code> locks the account after 14 days of inactivity.</li>
</ul>
<p>You can see these values by grepping the shadow file:</p>
<pre><code>sudo grep "linus" /etc/shadow
</code></pre>
<p>To log in as the new user, use the <code>su</code> command and enter the password you used when creating the account:</p>
<pre><code>su linus
</code></pre>
<p>To exit the new user's account, use the <code>exit</code> command:</p>
<pre><code>exit
</code></pre>
<p>As a sysadmin, you will want to regularly review and audit the <code>/etc/passwd</code> and the <code>/etc/shadow</code> files to ensure only
authorized users have access to the system.</p>
<p>Before proceeding, repeat the above process for a user named <strong>sean</strong>, or use a different username and adjust as necessary as you proceed.</p>
<h2 id="authorization"><a class="header" href="#authorization">Authorization</a></h2>
<p>Let's say we've created our users and now we want to give them access to some additional resources.
For example, we can set up a shared directory on the system that multiple users can access and use.
To do that, we will begin to work with groups and file/directory permissions.</p>
<h3 id="add-users-to-a-new-group"><a class="header" href="#add-users-to-a-new-group">Add users to a new group</a></h3>
<p>Because of the default configuration defined in <strong>/etc/adduser.conf</strong>, the <strong>linus</strong> user only belongs to a group of the same name.
Let's create a new group that both <strong>linus</strong> and <strong>sean</strong> belong to.
We'll call this <strong>developers</strong>.
Then we'll add both <strong>sean</strong> and <strong>linus</strong> to that group.
For that, we'll use the <code>gpasswd -a</code> command and option.
We'll also make the user <strong>sean</strong> the group administrator using the <code>-A</code> option (see <code>man gpasswd</code> for more details).</p>
<pre><code>sudo groupadd developers
sudo gpasswd -a sean developers
sudo gpasswd -a linus developers
sudo gpasswd -A sean developers
grep "developers" /etc/group
</code></pre>
<blockquote>
<p>Note: if a user is logged in when you add them to a group,
they need to logout and log back in before the group membership goes into effect.
Also, unlike some command options, we can't stack the following the <code>-aA</code> options with <code>gpasswd</code>.
I.e., they have to be run separately.</p>
</blockquote>
<h3 id="create-a-shared-directory"><a class="header" href="#create-a-shared-directory">Create a shared directory</a></h3>
<p>One of the benefits of group membership is that members can work in a shared directory.</p>
<p>Let's make the <code>/srv/developers</code> a shared directory.
The <code>/srv</code> directory already exists, so we only need to create the <code>developers</code> subdirectory:</p>
<pre><code>sudo mkdir /srv/developers
</code></pre>
<p>Now we change ownership of the directory so that it's group owned by the <code>developers</code> group that we created:</p>
<pre><code>sudo chgrp developers /srv/developers
</code></pre>
<p>The directory ownership should now reflect that it's owned by the <code>developers</code> group:</p>
<pre><code>ls -ld /srv/developers
</code></pre>
<p>The default permissions are currently set to <code>0755</code>.
To allow group members to read and write to the above directory, we need to use the <code>chmod</code> command in a way we haven't yet.
Specifically, we add a leading <code>2</code> that sets the group identity.
The <code>770</code> indicates that the user and group owners of the directory (but not <strong>others</strong>)
have read, write, and execute permissions for the directory:</p>
<pre><code>sudo chmod 2770 /srv/developers
</code></pre>
<p>This first digit, the <code>2</code> above, is the <code>setgid</code> (set group ID) bit.
Setting this ensures that any files or subdirectories created within <code>/srv/developers</code>
inherit the group ownership of the parent directory.
In this case, that's the <code>developers</code> group.
This is useful for group collaboration.
By setting this, either <code>linus</code> or <code>sean</code> can add, modify, and delete files in the <code>/srv/developers</code> directory.</p>
<h3 id="user-account-and-group-deletion"><a class="header" href="#user-account-and-group-deletion">User account and group deletion</a></h3>
<p>You can keep the additional user and group on your system, but know that you can also remove them.
The <code>deluser</code> and <code>delgroup</code> commands offer great options and may be preferable to the others utilities
(see <code>man deluser</code> or <code>man delgroup</code>).</p>
<p>If we want to delete the new user's account and the new group, these are the commands to use.
The first command will create an archival backup of <strong>linus</strong>' home directory and remove the home directory and any files in it.</p>
<pre><code>deluser --backup --remove-home linus
</code></pre>
<p>The following command will delete the developers group:</p>
<pre><code>delgroup developers
</code></pre>
<h2 id="conclusion-13"><a class="header" href="#conclusion-13">Conclusion</a></h2>
<p>Knowing how to manage user accounts and manage passwords are key sysadmin skills.
They are needed to provide collaborative environments and
to keep our systems secure through <strong>authentication</strong> and <strong>authorization</strong>.
While the methods to manage these things vary by operating system, the basic concepts are the same across OSes and services.</p>
<p>Although the basic concepts hold true across systems, things get a bit more complex for enterprise systems.
On enterprise systems running Windows, <a href="https://en.wikipedia.org/wiki/Active_Directory">Active Directory (AD)</a> is used for both <strong>authentication</strong> and <strong>authorization</strong>.
On enterprise systems running Linux,
the <a href="https://en.wikipedia.org/wiki/Lightweight_Directory_Access_Protocol">Lightweight Directory Access Protocol (LDAP)</a> system is used to store and manage user credentials.
<strong>LDAP</strong> can be integrated with <strong>AD</strong> to enable Linux systems to use <strong>AD</strong> for centralized user management.
Other technologies exist that facilitate user and resource management.
They include:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Kerberos_(protocol)">Kerberos</a></li>
<li><a href="https://en.wikipedia.org/wiki/Pluggable_authentication_module">PAM (Pluggable Authentication Module</a></li>
<li><a href="https://en.wikipedia.org/wiki/System_Security_Services_Daemon">SSSD (System Security Services Daemon)</a></li>
</ul>
<p>In this section, we learned about important user management files like
<code>/etc/passwd</code>, <code>/etc/shadow</code>, <code>/etc/group</code>, <code>/etc/skel</code>, and <code>/etc/adduser.conf</code>.
We continued to use <code>nano</code> (or your preferred editor) to edit new configuration files,
specifically <code>/etc/skel</code> and <code>/etc/adduser.conf</code>.
We dove deeper into exploring how the <code>man</code> pages work.
We also learned how to create new Linux user accounts, modify those accounts password parameters,
assign those accounts to groups, and create a share directory for those accounts for collaboration.</p>
<p>We covered the following new commands:</p>
<ul>
<li><code>adduser</code>: add a user or group to the system</li>
<li><code>chage</code>: change user password expiry information</li>
<li><code>chfn</code>: change real user name and information</li>
<li><code>chgrp</code>: change group ownership</li>
<li><code>delgroup</code>: remove a user or group from the system</li>
<li><code>deluser</code>: remove a user or group from the system</li>
<li><code>gpasswd</code>: administer <code>/etc/group</code> and <code>/etc/gshadow</code></li>
<li><code>groupadd</code>: create a new group</li>
<li><code>passwd</code>: the password file</li>
<li><code>su</code>: run a command with substitute user and group ID</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="managing-software"><a class="header" href="#managing-software">Managing Software</a></h1>
<p>By the end of this section, you should understand:</p>
<ol>
<li><strong>Package Management</strong>: Modern Linux distributions use package managers like <code>apt</code> for software management,
similar to app stores on mobile devices.</li>
<li><strong>APT Basics</strong>: Essential commands include <code>apt update</code> to refresh the package list,
<code>apt upgrade</code> to install available updates, and <code>apt install</code> to add new packages.</li>
<li><strong>Installing Software</strong>: Besides <code>apt</code>, software can also be installed from source,
as <code>.deb</code> packages with <code>dpkg</code>, or as <code>snap</code>, <code>flatpak</code>, or <code>appimage</code> packages for broader compatibility.</li>
<li><strong>Maintaining Your System</strong>: Use <code>apt autoremove</code> to clean up unused dependencies, and <code>apt clean</code> or
<code>apt autoclean</code> to clear out cached packages to free up disk space.</li>
<li><strong>Package Information</strong>: Use <code>apt show</code> for package details, <code>apt policy</code> for version information, and
<code>apt search</code> to find packages by name or keyword.</li>
<li><strong>Removal Options</strong>: <code>apt remove</code> uninstalls packages, while <code>apt purge</code> also removes configuration files.</li>
<li><strong>Script Automation</strong>: Common update and cleanup tasks can be automated with a bash script and
run with <code>sudo</code> for ease of use.</li>
<li><strong>APT Logs</strong>: Review <code>apt</code> activity by checking <code>/var/log/apt/history.log</code>.</li>
<li><strong>Manual Reading</strong>: For deeper understanding, consult the <code>man apt</code> manual page.</li>
</ol>
<h2 id="getting-started-7"><a class="header" href="#getting-started-7">Getting Started</a></h2>
<p>Many modern Linux distributions offer some kind of package manager to install, manage, and remove software.
These package management systems interact with curated and audited central repositories of software
that are collected into <strong>packages</strong>.
They also provide a set of tools to learn about the software that exists in these repositories.</p>
<blockquote>
<p>If <strong>package management</strong> seems like an odd concept to you, it's just a way to manage software installation.
It's very similar to the way that Apple and Google distribute software via the App Store and Google Play.</p>
</blockquote>
<h3 id="apt"><a class="header" href="#apt">APT</a></h3>
<p>On Debian based systems, which includes Ubuntu, we use <code>apt</code>, <code>apt-get</code>, and <code>apt-cache</code> to manage most software installations.
For most cases, you will simply want to use the <code>apt</code> command.
It is meant to combine the functionality commonly used with <code>apt-get</code> and <code>apt-cache</code>.</p>
<h3 id="dpkg"><a class="header" href="#dpkg">DPKG</a></h3>
<p>We can also install software from source code or from pre-built binaries.
On Debian and Ubuntu, we can install (if we trust it) pre-built binaries distributed on the internet as <strong>.deb</strong> files.
These are comparable to <code>.dmg</code> files for macOS and to <strong>.exe</strong> files for Windows.
When installing <code>.deb</code> files, we generally use the <code>dpkg</code> command,
although it's possible to use <code>apt</code> to install these files, too.</p>
<h3 id="source-code"><a class="header" href="#source-code">Source Code</a></h3>
<p>Installing software from source code often involves compiling the software.
It's usually not difficult to install software this way.
However, it can become complicated to manage software that's installed from source code
simply because it means managing dependencies.
This means we would need to manually track new patches or versions of the software.</p>
<h3 id="snap-flatpak-and-appimage"><a class="header" href="#snap-flatpak-and-appimage">Snap, Flatpak, and AppImage</a></h3>
<p>Another way to install software is to use <code>snap</code> or <code>flatpak</code> systems or <code>appimage</code> files.
These are newer ways of packaging programs that involves packaging a program and all of its dependencies
as self-contained packages.
The main audience seems to be aimed at IoT, embedded devices, and desktop/laptop systems.
If you see <strong>loop</strong> devices in the output of the <code>lsblk</code> command, this is the result of the <code>snap</code> system.
See the <a href="https://snapcraft.io/">Snap</a>, <a href="https://flatpak.org/">Flatpak</a>, and <a href="https://appimage.org/">AppImage</a> sites for example applications.</p>
<h3 id="language-package-managers"><a class="header" href="#language-package-managers">Language Package Managers</a></h3>
<p>In addition to the above, some programming languages provide their own mechanisms to install packages.
In many cases, these packages may be installed with the <code>apt</code> command,
but the packages that <code>apt</code> will install tend to be older (but more stable)
than the packages that a programming language will install.
For example, Python has the <code>pip</code> or <code>pip3</code> command to install and remove Python libraries.
The R programming language has the <code>install.packages()</code>, <code>remove.packages()</code>, and
the <code>update.packages()</code> commands to install R libraries.</p>
<p>Despite all these ways to install, manage, remove, and update software,
we will focus on using the <code>apt</code> command, which is pretty straightforward.</p>
<h2 id="using-apt"><a class="header" href="#using-apt">Using APT</a></h2>
<p>Let's look at the basic <code>apt</code> commands.</p>
<h3 id="apt-update"><a class="header" href="#apt-update"><code>apt update</code></a></h3>
<p>Before installing any software, we need to update the index of packages that are available for the system.
We do so with:</p>
<pre><code>sudo apt update
</code></pre>
<h3 id="apt-upgrade"><a class="header" href="#apt-upgrade"><code>apt upgrade</code></a></h3>
<p>When we update the package index, we will be informed if we need to upgrade any packages.
If any upgrades are available, we run the following command:</p>
<pre><code>sudo apt upgrade
</code></pre>
<h3 id="apt-search"><a class="header" href="#apt-search"><code>apt search</code></a></h3>
<p>We may know a package's name when we're ready to install it, but we also may not.
To search for a package, we use the following syntax, replacing <code>[package name]</code> with search terms:</p>
<pre><code>apt search [package-name]
</code></pre>
<blockquote>
<p>Package names will never have spaces between words.
Rather, if a package name has more than one word, each word will be separated by a hyphen.</p>
</blockquote>
<p>In practice, say I'm curious if there are any console based games:</p>
<pre><code>apt search ncurses game
</code></pre>
<blockquote>
<p>I added <strong>ncurses</strong> to my search query because the <a href="https://en.wikipedia.org/wiki/Ncurses">ncurses</a> library
is often used to create console-based applications.</p>
</blockquote>
<h3 id="apt-show"><a class="header" href="#apt-show"><code>apt show</code></a></h3>
<p>The above command returns a list that includes a game called <strong>ninvaders</strong>, which is a console-based Space Invaders like game.
To get additional information about this package, we use the <code>apt show [package-name]</code> command:</p>
<pre><code>apt show ninvaders
</code></pre>
<p>If we want to see what a package needs or depends on, then we can use the following command:</p>
<pre><code>apt-cache depends ninvaders
</code></pre>
<h3 id="apt-policy"><a class="header" href="#apt-policy"><code>apt policy</code></a></h3>
<p>To get a list of various versions that are available to download, we can use the <code>apt policy</code> command:</p>
<pre><code>apt policy ninvaders
</code></pre>
<h3 id="apt-install"><a class="header" href="#apt-install"><code>apt install</code></a></h3>
<p>It's quite simple to install the package called <strong>ninvaders</strong>:</p>
<pre><code>sudo apt install ninvaders
</code></pre>
<h3 id="apt-remove-or-apt-purge"><a class="header" href="#apt-remove-or-apt-purge"><code>apt remove</code> or <code>apt purge</code></a></h3>
<p>To remove an installed package, we can use either the <code>apt remove</code> or the <code>apt purge</code> commands.
Sometimes when a program is installed, configuration files get installed with it in the <code>/etc</code> directory.
The <code>apt purge</code> command removes those configuration files but the <code>apt remove</code> command does not.
Both commands are offered because sometimes it is useful to keep those configuration files.</p>
<pre><code>sudo apt remove ninvaders
</code></pre>
<p>Or:</p>
<pre><code>sudo apt purge ninvaders
</code></pre>
<blockquote>
<p>Other fun terminal based games include: <code>tint</code> (a tetris clone), <code>ttysolitaire</code>, and <code>bsdgames</code>,
the latter installs multiple console based games such as <code>backgammon, </code>go-fish<code>, </code>hangman<code>, and more. All of these will be installed in </code>/usr/games`.</p>
</blockquote>
<h3 id="apt-autoremove"><a class="header" href="#apt-autoremove"><code>apt autoremove</code></a></h3>
<p>All big software requires other software to run.
This other software are called <a href="https://queue.acm.org/detail.cfm?id=3344149">dependencies</a>.
The <code>apt show [package-name]</code> command will list a program's dependencies, as well as the <code>apt-cache depends</code> command.
However, when we remove software when using the <code>apt remove</code> or <code>apt purge</code> commands,
the dependencies, even if no longer needed, are not necessarily removed.
To remove them and restore disk space, we do:</p>
<pre><code>sudo apt autoremove
</code></pre>
<h3 id="apt-clean-or-apt-autoclean"><a class="header" href="#apt-clean-or-apt-autoclean"><code>apt clean</code> or <code>apt autoclean</code></a></h3>
<p>When we install software using the <code>apt</code> command, the installed packages are stored locally.
We don't necessarily need those once the binaries have been installed.
Or we may want to remove them especially if we're removing the binaries.
The <code>apt clean</code> and <code>apt autoclean</code> commands clear up that local cache of packages.
We use either of these commands to free up disk space.</p>
<p>Between the two, the <code>apt clean</code> command <strong>removes all package files</strong> that are stored in <code>/var/cache/apt/archives</code>.
But the <code>apt autoclean</code> <strong>only removes package files that can no longer be downloaded</strong>.
I generally use the <code>apt clean</code> command to free up more disk space.
I will only use <code>apt autoclean</code> if I want to keep an package to older software, but this is rare.</p>
<p>To use:</p>
<pre><code>sudo apt clean
</code></pre>
<p>Or:</p>
<pre><code>sudo apt autoclean
</code></pre>
<h3 id="apt-history"><a class="header" href="#apt-history">apt history</a></h3>
<p>Unfortunately, the <code>apt</code> command does not provide a way to get a history of how it's been used on a system.
This will change in the future when <code>apt</code> gets a <code>apt history-list</code> command and an <code>apt history-info</code> command
(Source: <a href="https://www.phoronix.com/news/Debian-APT-History-Command">Phoronix</a>).
In the meantime, the <code>apt</code> system keeps a log of its activity, and we can review that log file with the following command:</p>
<pre><code>less /var/log/apt/history.log
</code></pre>
<h2 id="daily-usage"><a class="header" href="#daily-usage">Daily Usage</a></h2>
<p>This all may seem complicated, but it's really not.
For example, to keep my systems updated, I run the following four commands on a daily or near daily basis:</p>
<pre><code>sudo apt update
sudo apt upgrade
sudo apt autoremove
sudo apt clean
</code></pre>
<p>You can add these commands to a script that we could call <code>update.sh</code> and put it in <code>/usr/local/bin</code>:</p>
<pre><code>#!/usr/bin/env bash

apt update &amp;&amp; apt upgrade &amp;&amp; apt autoremove &amp;&amp; apt clean
</code></pre>
<p>And then we make the file executable:</p>
<pre><code>sudo chmod 700 /usr/local/bin/update.sh`:
</code></pre>
<p>And execute/run it with the following command:</p>
<pre><code>sudo update.sh
</code></pre>
<h2 id="conclusion-14"><a class="header" href="#conclusion-14">Conclusion</a></h2>
<p>There are a variety of ways to install software on a Linux or Ubuntu system.
The common way to do it on Ubuntu is to use the <code>apt</code> command, which was covered in this section.</p>
<p>We'll come back to this command often because we'll soon install and setup a complete LAMP
(Linux, Apache, MariaDB, and PHP) server.
Until then, I encourage you to read through the manual page for <code>apt</code>:</p>
<pre><code>man apt
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="using-systemd"><a class="header" href="#using-systemd">Using systemd</a></h1>
<p>By the end of the section, you will know how to:</p>
<ol>
<li>Use <code>systemctl</code> to manage services on a Linux system,
including starting, stopping, enabling, and checking the status of services.</li>
<li>Understand the purpose of <code>systemd</code> as an init system and its role in booting, service management, and log handling.</li>
<li>Check the status and logs of specific services with <code>journalctl</code> and
use filters to narrow down log results by service, PID, or specific conditions.</li>
<li>Set up and manage <code>systemd</code> timers to automate tasks, such as scheduling scripts to run at specific times.</li>
<li>Explore and utilize additional <code>systemd</code> commands,
such as checking enabled services, suspending or rebooting the system, and examining boot times with <code>systemd-analyze</code>.</li>
<li>View and interpret system logs, search through them efficiently, and follow logs in real-time.</li>
<li>Create and configure custom <code>systemd</code> service and timer files for more tailored system automation.</li>
<li>Use <code>systemd</code> commands to troubleshoot system issues,
including identifying failed services and examining resource usage with <code>systemd-cgtop</code>.</li>
</ol>
<h2 id="getting-started-8"><a class="header" href="#getting-started-8">Getting Started</a></h2>
<p>When computers boot up, obviously some software manages that process.
On Linux and other Unix or Unix-like systems, this is usually handled via an <strong>init</strong> system.
For example, macOS uses <a href="https://en.wikipedia.org/wiki/Launchd">launchd</a> and many Linux distributions, including Ubuntu, use <a href="https://en.wikipedia.org/wiki/Systemd">systemd</a>.</p>
<p><strong>systemd</strong> does more than handle the startup process,
it also manages various services and connects the Linux kernel to various applications.
In this section, we'll cover how to use <strong>systemd</strong> to manage services and to review log files.</p>
<h2 id="manage-services"><a class="header" href="#manage-services">Manage Services</a></h2>
<p>When we install complicated software, like a web server (e.g., Apache2, Nginx), a SSH server (e.g., OpenSSH),
or a database server (e.g., mariaDB or MySQL), then it's helpful to have commands that manage that service:
the web service, the SSH service, the database service, etc.</p>
<p>For example, the <code>ssh</code> service is installed by default on our gcloud servers, and
we can check its status with the following <code>systemctl</code> command:</p>
<pre><code>systemctl status ssh
</code></pre>
<p>The output tells us a few things.
The line beginning with <code>Loaded</code> tells us that the SSH service is configured.
At the end of that line, it also tells us that it is <code>enabled</code>.
<code>Enabled</code> means that the service automatically starts when the system gets rebooted or starts up.</p>
<p>The line beginning with <code>Active</code> tells us that the service is <code>active (running)</code> and for how long.
We also can see the process ID (PID) for the service as well as how much memory it's using.</p>
<p>At the bottom of the output, we can see the recent log files.
We can view more of those log files using the <code>journalctl</code> command.
By default, running <code>journalctl</code> by itself will return all log files.
We can specify that we're interested in log files only for the ssh service.
We can specify using the PID number.
Replace <em>N</em> with the PID number attached to your ssh service:</p>
<pre><code>journalctl _PID=N
</code></pre>
<p>Or we can specify by service, or more specifically, its <strong>unit</strong> name:</p>
<pre><code>journalctl -u ssh
</code></pre>
<h3 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h3>
<p>Later we'll install the <a href="https://httpd.apache.org/">Apache web server</a>, and we will use <code>systemctl</code> to manage some aspects of this service.</p>
<p>In particular, we will use the following commands to:</p>
<ol>
<li>Check the state of the Apache service,</li>
<li>enable the Apache service to auto start on reboot,</li>
<li>start the service,</li>
<li>reload the service after editing its configuration files, and</li>
<li>stop the service.</li>
</ol>
<p>In practice, these work out to:</p>
<pre><code>systemctl status apache2
sudo systemctl enable apache2
sudo systemctl start apache2
sudo systemctl reload apache2
sudo systemctl stop apache2
</code></pre>
<p><code>systemctl</code> is a big piece of software, and there are other arguments the command will take.
See <code>man systemctl</code> for details.</p>
<p><strong>NOTE:</strong> Not all services support <code>systemctl reload [SERVICE]</code>.
You can check if a service is reloadable by checking its service file.
As an example:</p>
<pre><code>grep "ExecReload" /lib/systemd/system/ssh.service
</code></pre>
<p>You can peruse other services in <code>/lib/systemd/system</code>.</p>
<h2 id="examine-logs"><a class="header" href="#examine-logs">Examine Logs</a></h2>
<p>As mentioned, the <code>journalctl</code> command is part of the <code>systemd</code> software suite, and it is used to monitor system logs.</p>
<p>It's important to monitor system logs.
Log files help identify problems in the system or with various services.
For example, by monitoring the log entries for <strong>ssh</strong>, I can see all the attempts to break into the server.
Or if the Apache2 web server malfunctions for some reason, which might be because of a configuration error,
the logs will indicated how to identify the problem.</p>
<p>If we type <code>journalctl</code> at the command prompt, we are be presented with the logs for the entire system.
These logs can be paged through by pressing the space bar, the page up/page down keys, or the up/down arrow keys.
They can also be searched by pressing the forward slash <code>/</code> and then entering a search keyword.
To exit out of the pager, press <strong>q</strong> to quit.</p>
<pre><code>journalctl
</code></pre>
<p>It's much more useful to specify the field and to declare an option when using <code>journalctl</code>, like above with <code>ssh</code>
See the following man pages for details:</p>
<pre><code>man systemd.journal-fields
man journalctl
</code></pre>
<p>There are many fields and options we can use, but as an example,
we see that there is an option to view the more recent entries first:</p>
<pre><code>journalctl -r
</code></pre>
<p>Or we view log entries in reverse order, for users on the system, and since the last boot with the following options:</p>
<pre><code>journalctl -r --user -b 0
</code></pre>
<p>Or for the system:</p>
<pre><code>journalctl -r --system -b 0
</code></pre>
<p>I can more specifically look at the logs files for a service by using the <code>-u</code> option with <code>journalctl</code>:</p>
<pre><code>journalctl -u apache2
</code></pre>
<p>I can follow the logs in real-time (press <strong>ctrl-c</strong> to quit the real-time view):</p>
<pre><code>journalctl -f
</code></pre>
<h2 id="timers-automation"><a class="header" href="#timers-automation">Timers (Automation)</a></h2>
<p>Linux and Unix operating systems have long provided a way to automate processes.
Historically, the <code>cron</code> service has been used to automate jobs, but I do not cover it here.
Instead, we examine how to use <code>systemd</code> as a way to automate jobs using <strong>timers</strong>.</p>
<p>The <code>/var/log/auth.log</code> file logs all authentication attempts to the system.
We can create a script to look at the file and extract the invalid attempts to login to the system.</p>
<p>What if we could have that script run at specific times?
For example, what if we wanted to run that script every morning at 8AM and then log the output to a file for us to read?
We can do that with systemd timers.</p>
<p>First, let's create a very simple <code>auth.sh</code> script to do this job.
In the example below, I've set the location of the <code>auth.log</code> file and the output file,
added a check to be sure the file exists and/or can be read,
created two additional variables to record the start and end dates of the auth.log file, and
used <code>grep</code> again to look for invalid IP addresses in the log file,
wrote an <code>echo</code> statement to add some additional information, and
save the output in a file called <code>brute.log</code> in our <code>$HOME</code> directory.
The <code>${end_date}</code> and <code>${start_date}</code> variables were created after closely studying the <code>/var/log/auth.log</code> file.
This is a very basic file, and programming languages like <code>awk</code>, <code>perl</code>, or <code>python</code> might be better suited for this job,
but for <code>bash</code> sake:</p>
<pre><code>#!/usr/bin/env bash

LOG_FILE="${1:-/var/log/auth.log}"
OUT_FILE="${HOME}/brute.log"

if [[ ! -r "${LOG_FILE}" ]] ; then
    echo "Error: cannot read '${LOG_FILE}' (permission or file missing)." &gt;&amp;2
    echo "Try running with sudo or pass a readable log path." &gt;&amp;2
    exit 2
fi

END_DATE=$(grep -Eo "^[[:alpha:]]{3}[[:space:]]{1,2}[[:digit:]]{1,2}" "${LOG_FILE}" | tail -n1)
START_DATE=$(grep -Eo "^[[:alpha:]]{3}[[:space:]]{1,2}[[:digit:]]{1,2}" "${LOG_FILE}" | head -n1)

TOTAL_INVALID="$(grep -c "Invalid user" "${LOG_FILE}")"
INVALID_IPS="$(grep "Invalid user" "${LOG_FILE}" | \
    grep -Eo "[[:digit:]]+\.[[:digit:]]+\.[[:digit:]]+\.[[:digit:]]+" | \
    sort | uniq | wc -l)"

echo "
Log entry created on $(date +%c).
From ${START_DATE} to ${END_DATE}, there were ${TOTAL_INVALID} attempts to login to the system.
These came from ${INVALID_IPS} unique IPs.
" &gt;&gt; "${OUT_FILE}"

</code></pre>
<p>Next, to automate the execution of this script, we need to create two additional files.
First we create a <strong>service</strong> file.
This file defines the <strong>service</strong> that we want to execute.
Navigate to the systemd's service directory:</p>
<pre><code>cd /etc/systemd/system
</code></pre>
<p>And use <code>sudo nano</code> to create a file called <code>brute.service</code>:</p>
<pre><code>sudo nano brute.service
</code></pre>
<p>In the above file, we add the following information under two sections, a Unit section and a Service section.
The Unit section includes a description of the service and a list of the service's requirements.
The Service section declares the type of service, the location of the script to run, and the user to run the script under.
Feel free to use this but be sure to change your User information:</p>
<pre><code>[Unit]
Description="Summarize brute login attempts."
Requires=brute.timer

[Service]
Type=simple
ExecStart=/usr/local/bin/auth.sh
User=seanburns
</code></pre>
<p>See <code>man 5 systemd.service</code> for more details.</p>
<p>Next we need to create the <strong>timer</strong> file.
Using <code>sudo nano</code>, run the following command in the same directory as above:</p>
<pre><code>sudo nano brute.timer
</code></pre>
<p>In this file, add the following:</p>
<pre><code>[Unit]
Description="Timer for the brute login service."

[Timer]
OnCalendar=*-*-* 08:00:00
Persistent=true

[Install]
WantedBy=timers.target
</code></pre>
<p>See <code>man 5 systemd.timer</code> for more details.</p>
<p>Next we need to enable and start the timer.
To do that, we run two separate <code>systemctl</code> commands:</p>
<pre><code>sudo systemctl daemon-reload
</code></pre>
<p>And then enable the timer:</p>
<pre><code>sudo systemctl enable brute.timer
</code></pre>
<p>Start the timer:</p>
<pre><code>sudo systemctl start brute.timer
</code></pre>
<p>And finally, check the status of all timers:</p>
<pre><code>systemctl list-timers
</code></pre>
<p>Or check the status of our specific timer:</p>
<pre><code>systemctl status brute.timer
</code></pre>
<p>You can now check that your script ran after the next time your system's clock reaches 8AM.</p>
<h2 id="useful-systemd-commands"><a class="header" href="#useful-systemd-commands">Useful Systemd Commands</a></h2>
<p>You can see more of what <code>systemctl</code> or <code>journalctl</code> can do by reading through their documentation:</p>
<pre><code>man systemctl
man journalctl
</code></pre>
<p>You can check if a service if enabled:</p>
<pre><code>systemctl is-enabled apache2
</code></pre>
<p>You can reboot, poweroff, or suspend a system (suspending a system mostly makes sense for laptops and not servers):</p>
<pre><code>systemctl reboot
systemctl poweroff
systemctl suspend
</code></pre>
<p>To show configuration file changes to the system:</p>
<pre><code>systemd-delta
</code></pre>
<p>To list real-time control group process, resource usage, and memory usage:</p>
<pre><code>systemd-cgtop
</code></pre>
<ul>
<li>to search failed processes/services:</li>
</ul>
<pre><code>systemctl --state failed
</code></pre>
<ul>
<li>to list services</li>
</ul>
<pre><code>systemctl list-unit-files -t service
</code></pre>
<ul>
<li>to examine boot time:</li>
</ul>
<pre><code>systemd-analyze
</code></pre>
<h2 id="conclusion-15"><a class="header" href="#conclusion-15">Conclusion</a></h2>
<p>This is a basic introduction to <strong>systemd</strong>, which is composed of a suite of software to help manage booting a system,
managing services, and monitoring logs.</p>
<p>We'll put what we've learned into practice when we set up our LAMP servers.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="networking-and-security"><a class="header" href="#networking-and-security">Networking and Security</a></h1>
<p>Even if we do not work as network administrators,
system administrators need to know network basics.
In this section, we cover TCP/IP and other protocols
related to the internet protocol suite,
and how to protect our systems locally,
from external threats,
and how to create backups of our systems in case
of disaster.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="networking"><a class="header" href="#networking">Networking</a></h1>
<p>By the end of this section, you should know:</p>
<ol>
<li>The role of a system administrator in setting up, configuring, and monitoring networks,
from small LANs to larger networks that interface with external networks.</li>
<li>The structure and layers of the Internet Protocol Suite,
including the Link, Internet, Transport, and Application layers.</li>
<li>How the Address Resolution Protocol (ARP) is used to map IP addresses to MAC addresses, and
how to view network information using commands like <code>ip a</code> and <code>ip link</code>.</li>
<li>The distinction between public and private IP addresses, the ranges for private IPs, and
the concept of IP subnets.</li>
<li>How the Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) differ in handling data,
including typical use cases for each.</li>
<li>The basics of TCP and UDP headers, and how to examine network traffic using <code>tcpdump</code>.</li>
<li>The significance of ports in networking, common port numbers, and
how ports help direct traffic to specific services.</li>
<li>The concept of subnetting, including how subnet masks and
CIDR notation help define network boundaries and control the number of hosts on a network.</li>
<li>How to convert between binary and decimal for IP addressing,
as well as the importance of subnet masks and broadcast addresses.</li>
<li>The process of calculating available hosts in a subnet, including examples for both /24 and /16 subnet masks.</li>
</ol>
<h2 id="getting-started-9"><a class="header" href="#getting-started-9">Getting Started</a></h2>
<p>An important function of a system administrator is to set up, configure, and monitor a network.
This may involve planning, configuring, and connecting the devices on a local area network,
to planning and implementing a large network that interfaces with an outside network,
and to monitoring networks for various sorts of attacks, such as <a href="https://en.wikipedia.org/wiki/Denial-of-service_attack">denial of service attacks</a>.</p>
<p>In order to prepare for this type of work,
we need at least a basic understanding of how the internet works and how local devices interact with the internet.
In this section, we will focus mostly on internet addressing, but we will also devote some space to TCP and UDP, two protocols for transmitting data.</p>
<p>Connecting two or more devices together nowadays involves the TCP/IP or the UDP/IP protocols,
otherwise part of the <a href="https://en.wikipedia.org/wiki/Internet_protocol_suite">Internet protocol suite</a>.
This suite is an expression of the more generalized <a href="https://en.wikipedia.org/wiki/OSI_model">OSI communication model</a>.</p>
<p>The internet protocol suite is framed as a series of layers beginning with a lower layer, called the <strong>link layer</strong>,
that interfaces with internet capable hardware, to the highest layer, called the <strong>application layer</strong>,
e.g., the web (<code>http</code>).</p>
<p>The <strong>link layer</strong> describes the local area network.
Devices connected locally, e.g., via Ethernet cables or local wifi, comprise the link layer.
The link layer connects to the <strong>internet layer</strong>.
Data going into or out of a local network must be negotiated between these two layers.</p>
<p>The <strong>internet layer</strong> makes the internet possible since it provides functionality to transmit data among multiple networks possible.
The internet is, in fact, a network of networks.
The primary characteristic of the internet layer is the <strong>IP address</strong>, which currently comes in two versions:
IPv4 (a 32 bit number) and IPv6 (a 128 bit number).
IP addresses are used to locate hosts on a network.</p>
<p>The <strong>transport layer</strong> makes the exchange of data on the internet possible.
There are multiple protocols for the transport layer, but the two main ones are <a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol">UDP</a> and <a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol">TCP</a>.
Very generally, the <a href="https://www.cloudflare.com/learning/ddos/glossary/user-datagram-protocol-udp/">UDP</a> places priority on data reaching its destination over the integrity of data.
For example, streaming video, Voice-over-IP (VOIP), and online gaming are often transported via UDP
because the loss of some pixels or some audio is acceptable for end users.
<a href="https://www.cloudflare.com/learning/ddos/glossary/tcp-ip/">TCP</a> is used when the integrity of the data is important.
If the data cannot be transmitted without error, then the data won't reach its final destination until the error is corrected.
As an example, purchases, bank exchanges, etc use TCP since financial transactions must be exact.</p>
<p>The <strong>application layer</strong> provides the ability to use the internet in particular ways.
For example, the <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">HTTP</a> protocol enables the <strong>web</strong>.
The <strong>web</strong> is thus an <strong>application</strong> of the internet.
Likewise, the <strong>SMTP</strong>, <strong>IMAP</strong>, and <strong>POP</strong> protocols provide the basis for email exchange,
<strong>DNS</strong> maps IP addresses to domain names, and we use <strong>SSH</strong> to connect to our virtual machines.</p>
<blockquote>
<p>By <strong>application</strong>, we simply mean that these protocols provide the functionality for applications.
They are not themselves considered user applications, like a web browser.</p>
</blockquote>
<h2 id="the-internet-protocol-suite"><a class="header" href="#the-internet-protocol-suite">The Internet Protocol Suite</a></h2>
<h3 id="link-layer"><a class="header" href="#link-layer">Link Layer</a></h3>
<h4 id="arp-address-resolution-protocol"><a class="header" href="#arp-address-resolution-protocol">ARP (Address Resolution Protocol)</a></h4>
<p><strong>ARP</strong> (Address Resolution Protocol) is a protocol at the link layer and is used to map network addresses,
like an IP address, to ethernet addresses.
An ethernet address is more commonly referred to as the MAC or Media Access Control address, or the hardware address.
Routers use MAC addresses to enable communication inside networks (w/in subnets or local area networks)
so that computers within a local network can talk to each other on these subnets.
Networks are designed so that IP addresses are associated with MAC addresses before systems can communicate over a network.
Each of your internet capable devices, your smartphone, your laptop, your internet connected toaster, has a MAC address.</p>
<p>To get the MAC address for a specific computer, we can use the following commands:</p>
<pre><code>ip a
</code></pre>
<p>Or:</p>
<pre><code>ip link
</code></pre>
<blockquote>
<p>In the above command, <code>ip</code> is the command and <code>a</code> or <code>link</code> are considered objects
(see <code>man ip</code> for details).
Note that <code>ip a</code> and <code>ip link</code> provide slightly different views of network interfaces.</p>
</blockquote>
<p>The MAC addresses are reported on the <strong>link/ether</strong> line.</p>
<p>On my virtual server, the <code>ip link</code> command produces two <strong>numbered</strong> sections of output.
The first section refers to the <code>lo</code> or loopback device.
This is a special device that allows the computer to communicate with itself, and
it always has a MAC address of 00:00:00:00:00:00.
The next section on the machine refers to the ethernet card (e.g., <code>ens4</code>), and
this represents the hardware for system's wired connection to the internet.
The MAC address is reported on the indented line below.
See <code>man systemd.net-naming-scheme</code> for more details.</p>
<p>We can get the IP information with the following command:</p>
<pre><code>ip a
</code></pre>
<p>The <code>ip a</code> command reports both the MAC and IP addresses for the same devices.
Here it reports that the <code>lo</code> device has the IP address of 127.0.0.1.
It always has this IP.
On my Google Cloud machine, I get an IP address like <code>10.128.0.2/32</code> for the <code>ens4</code> device.
This is a <strong>private IP address</strong>, which means it can only be used to locate the machine on the subnet.</p>
<p>The following two commands help identify parts of the local network (or subnet) and the routing table.</p>
<pre><code>ip neigh
ip route
</code></pre>
<p>The <code>ip neigh</code> command produces the ARP cache.
This represents the other machines yours sees on the local network.
At the very least, it'll report the IP address for the router your machine uses.</p>
<p>The <code>ip route</code> command is used to define how data is routed on the network but can also define the routing table.
Both of these commands are more commonly used on Linux-based routers.</p>
<p>These details enable the following scenario:
A router gets configured to use a specific <strong>network address</strong> when it's brought online.
It searches the sub network for connected MAC addresses.
It then assigns each of those MAC addresses an available IP address based on the available network address.
Those network addresses are private IP addresses and will fall within a specific range
(as discussed below).</p>
<h3 id="internet-layer"><a class="header" href="#internet-layer">Internet Layer</a></h3>
<h4 id="ip-internet-protocol"><a class="header" href="#ip-internet-protocol">IP (Internet Protocol)</a></h4>
<p>The Internet Protocol is used to uniquely identify a host on a network and place that host at a specific location (its IP <strong>address</strong>).
If that network is subnetted (i.e., routed), then a host's IP address will have a subnet or private IP address.
This private IP address will not be directly exposed to the Internet.</p>
<p>Remember this: public IP addresses are distinct from private IP addresses.
Public IP addresses are accessible on the internet.
Private IP addresses are not, but they are accessible on subnets or local area networks.</p>
<p>Private IP address ranges are <strong>reserved</strong> address ranges.
This means no public internet device will have an IP address within these ranges.
The private address ranges include:</p>
<div class="table-wrapper"><table><thead><tr><th>Start Address</th><th>End Address</th><th>Network Size</th></tr></thead><tbody>
<tr><td>10.0.0.0</td><td>10.255.255.255</td><td>Large</td></tr>
<tr><td>172.16.0.0</td><td>172.31.255.255</td><td>Medium</td></tr>
<tr><td>192.168.0.0</td><td>192.168.255.255</td><td>Small</td></tr>
</tbody></table>
</div>
<p>If you have a router at home, and examine the IP address for any of your devices connected to that router,
like your phone or computer, you will see that it will have an address within one of the ranges above.
For example, it might have an IP address like <strong>192.168.0.4</strong>.
This is a common IP address number assigned by a home router.</p>
<p>The difference between these ranges largely rests on the number of hosts they can accommodate.
The <strong>10.X.X.X</strong> private range can assign more IP addresses (more hosts) on its network
than the <strong>172.X.X.X</strong> range can, and the latter more than the <strong>192.168.X.X</strong> range.
This is why you'll see the <strong>10.0.0.0</strong> IP range on bigger networks, like a university's network.
We'll talk more about subnetwork sizes, shortly.</p>
<h4 id="example-private-ip-usage"><a class="header" href="#example-private-ip-usage">Example Private IP Usage</a></h4>
<p>Let's say my campus desktop's IP address is <strong>10.163.34.59/24</strong> via a wired connection.
And my office neighbor has an IP address of <strong>10.163.34.65/24</strong> via their wired connection.
Both IP addresses are private because they fall within the
<strong>10.0.0.0 to 10.255.255.255</strong> range.
And it's likely they both exist on the same subnet since they share the first three <strong>octets</strong>:
<strong>10.163.34.XX</strong>.</p>
<p>However, if we both, using our respective wired connected computers,
searched Google for <em>what's my IP address</em>,
we will see that we share the same public IP address, which will be something like <strong>128.163.8.25</strong>.
We know that is a public IP address because it does not fall within the ranges listed above.</p>
<p>By entailment and without any additional information,
we know that all traffic coming from our computers and going out to the internet looks like it's coming
from the same IP address (<strong>128.163.8.25</strong>).
And in reverse, all traffic coming from outside our network first goes to <strong>128.163.8.25</strong>
before it's routed to our respective computers via the router.</p>
<p>Let's say I switch my computer's network connection to the campus's wifi network.
When I check with <code>ip a</code>, I find that the computer now has a private IP address of <strong>10.47.34.150/16</strong>.
You can see the pattern is different with this IP address than it was when it was connected via wire.
The reason it has a different pattern is because the laptop is now on an different subnet.
This wireless subnet was configured to allow more hosts to connect to it since it must allow for more devices
(i.e., laptops, phones, etc).
When I searched Google for my IP address from this laptop,
it reports <strong>128.163.238.148</strong>.
Since this is a different public IP address from above, it indicates that the university owns a range of public IP address spaces.</p>
<p>Here's a visual diagram of what this network looks like:</p>
<figure>
<img src="images/18-network.png"
alt="Network diagram"
title="Network diagram">
<figcaption>
Fig. 1. This figure contains a network switch, which is used to route traffic within a subnet.
The switch relies solely on MAC addresses and not IP addresses to determine the location of devices on its subnet.
The router acts as the interface between the private network and the public network and
is managing two subnets: a wired and a wireless one.
</figcaption>
</figure>
<h4 id="using-the-ip-command"><a class="header" href="#using-the-ip-command">Using the <code>ip</code> Command</a></h4>
<p>The <code>ip</code> command can do more than provide us information about our network.
We can also use it to turn a connection to the network on or off (and more).
The commands below show how we disable and then enable a connection on a machine.
Note that <strong>ens4</strong> is the name of my network card/device.
We probably have the same device names, but note that it might be different.</p>
<pre><code>sudo ip link set ens4 down
sudo ip link set ens4 up
</code></pre>
<blockquote>
<p>Don't run those commands on your Google Cloud servers otherwise your connection will be dropped and
you'll have to reboot the system from the web console.</p>
</blockquote>
<h3 id="transport-layer"><a class="header" href="#transport-layer">Transport Layer</a></h3>
<p>The internet (IP) layer does not transmit content, like web pages or video streams.
This is the work of the transport layer.
As discussed previously, the two most common transport layer protocols are <strong>TCP</strong> and <strong>UDP</strong>,
but <a href="https://en.wikipedia.org/wiki/Category:Transport_layer_protocols">there are more</a>.</p>
<h4 id="tcp-transmission-control-protocol"><a class="header" href="#tcp-transmission-control-protocol">TCP, Transmission Control Protocol</a></h4>
<p><em>TCP</em> or Transmission Control Protocol is responsible for the transmission of data and
for making sure the data arrives at its destination w/o errors.
If there are errors, the data is re-transmitted or halted in case of failure.
Much of the data sent over the internet is sent using TCP.</p>
<h4 id="udp-user-datagram-protocol"><a class="header" href="#udp-user-datagram-protocol">UDP, User Datagram Protocol</a></h4>
<p>The <strong>UDP</strong> or User Datagram Protocol performs a similar function as TCP, but
it does not error check and data may get lost.
UDP is useful for conducting voice over internet calls or for streaming video, such as through YouTube,
which uses a type of UDP transmission called <strong>QUIC</strong> that has builtin encryption.</p>
<h4 id="tcp-and-udp-headers"><a class="header" href="#tcp-and-udp-headers">TCP and UDP Headers</a></h4>
<p>The above protocols send data <strong>packets</strong> for TCP <strong>datagrams</strong> for UDP, but
<a href="https://www.cloudflare.com/learning/network-layer/what-is-a-packet/">these terms may be used interchangeably</a>.
Packets for both protocols include header information to help route the data across the internet.
TCP includes <a href="https://www.imperva.com/learn/ddos/tcp-transmission-control-protocol/">ten fields</a> of header data, and UDP includes <a href="https://www.imperva.com/learn/ddos/udp-user-datagram-protocol/">four fields</a>.</p>
<p>We can see this header data using the <code>tcpdump</code> command, which requires <code>sudo</code> or being <strong>root</strong> to use.
The first part of the IP header contains the source address,
then comes the destination address, and so forth.
Aside from a few other parts, this is the primary information in an IP header.</p>
<p>If you want to use <code>tcpdump</code>, <strong>you should use it on your local computer and not on your Google Cloud instance</strong>.
I'm not sure how Google will respond to this kind of activity because it might be deemed malicious.
But to use it, first we identify the IP number of a host,
which we can do with the <code>ping</code> command, and then run <code>tcpdump</code>:</p>
<pre><code>ping -c1 www.uky.edu
sudo tcpdump host 128.163.35.46
</code></pre>
<p>While that's running, we can type that IP address in our web browser, or enter <strong>www.uky.edu</strong>, and
watch the output of <code>tcpdump</code>.</p>
<p>TCP headers include port information and other mandatory fields for both source and destination servers.
The SYN, or synchronize, message is sent when a source or client requests a connection.
The ACK, or acknowledgment, message is sent in response, along with a SYN message,
to acknowledge the request for a connection.
Then the client responds with an additional ACK message.
This is referred to as the <a href="https://www.geeksforgeeks.org/tcp-3-way-handshake-process/">TCP three-way handshake</a>.
In addition to the header info,
TCP and UDP packets include the data that's being sent (e.g., a webpage) and error checking if it's TCP.</p>
<h4 id="ports"><a class="header" href="#ports">Ports</a></h4>
<p>TCP and UDP connections use ports to bind internet traffic to specific IP addresses.
Specifically, a <strong>port</strong> associates a process with an application
(and is part of the <strong>application layer</strong> of the internet suite),
such as a web service or outgoing email.
That is, ports provide a way to distinguish and filter internet traffic (web, email, etc) through an IP address.
For example, port 80 is the default port for unencrypted HTTP traffic.
Thus, all traffic going to IP address 10.0.5.33:80 means that this is <strong>HTTP</strong> traffic for the HTTP web service.
Note that the port info is attached to the end of the IP address via a colon.</p>
<p>Other common ports include:</p>
<ul>
<li>21: FTP</li>
<li>22: SSH</li>
<li>25: SMTP</li>
<li>53: DNS</li>
<li>143: IMAP</li>
<li>443: HTTPS</li>
<li>587: SMTP Secure</li>
<li>993: IMAP Secure</li>
</ul>
<p>A list of the default ports/protocols on your Linux systems is contained in the following file:</p>
<pre><code>less /etc/services
</code></pre>
<p>See also the Wikipedia page: <a href="https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers">List of TCP and UDP port numbers</a></p>
<h2 id="ip-subnetting"><a class="header" href="#ip-subnetting">IP Subnetting</a></h2>
<p>Let's now return to the internet layer and discuss one of the major duties of a systems administrator: subnetting.</p>
<p>Subnets are used to carve out smaller and more manageable subnetworks out of a larger network.
They are created using routers that have this capability (e.g., commercial use routers) and
certain types of network switches.</p>
<h3 id="private-ip-ranges"><a class="header" href="#private-ip-ranges">Private IP Ranges</a></h3>
<p>When subnetting local area networks, recall that we work with the private IP ranges:</p>
<div class="table-wrapper"><table><thead><tr><th>Start Address</th><th>End Address</th></tr></thead><tbody>
<tr><td>10.0.0.0</td><td>10.255.255.255</td></tr>
<tr><td>172.16.0.0</td><td>172.31.255.255</td></tr>
<tr><td>192.168.0.0</td><td>192.168.255.255</td></tr>
</tbody></table>
</div>
<p>It's important to be able to work with IP addresses like those listed above in order to subnet;
and therefore, we will need to learn a bit of IP math along the way.</p>
<h4 id="ip-meaning"><a class="header" href="#ip-meaning">IP Meaning</a></h4>
<p>An IPv4 address is 32 bits (8 x 4), or four bytes, in size.
In human readable context, it's usually expressed in the following, decimal-based, notation style:</p>
<ul>
<li><strong>192.168.1.6</strong></li>
<li><strong>172.16.3.44</strong></li>
</ul>
<p>Each set of numbers separated by a dot is referred to as an <strong>octet</strong>.
An <strong>octet</strong> is a group of 8 <strong>bits</strong>.
Eight <strong>bits</strong> equals a single <strong>byte</strong>.
By implication, 8 gigabits equals 1 gigabyte, and 8 megabits equals 1 megabyte.
We use these symbols to note the terms:</p>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>Symbol</th></tr></thead><tbody>
<tr><td>bit</td><td><em>b</em></td></tr>
<tr><td>byte</td><td>B</td></tr>
<tr><td>octet</td><td><em>o</em></td></tr>
</tbody></table>
</div>
<p>Each bit is represented by either a 1 or a 0.
For example, the first address above in binary is:</p>
<ul>
<li><strong>11000000.10101000.00000001.00000110</strong> is <strong>192.168.1.6</strong></li>
</ul>
<p>Or:</p>
<div class="table-wrapper"><table><thead><tr><th>Byte</th><th>Decimal Value</th></tr></thead><tbody>
<tr><td>11000000</td><td>192</td></tr>
<tr><td>10101000</td><td>168</td></tr>
<tr><td>00000001</td><td>1</td></tr>
<tr><td>00000110</td><td>6</td></tr>
</tbody></table>
</div>
<h3 id="ip-math"><a class="header" href="#ip-math">IP Math</a></h3>
<p>When doing IP math, one easy way to do it is to simply remember that
each bit in each of the above bytes is a placeholder for the following values:</p>
<pre><code>128 64 32 16 8 4 2 1
</code></pre>
<p>Alternatively, from low to high:</p>
<div class="table-wrapper"><table><thead><tr><th>base-2</th><th>Output</th></tr></thead><tbody>
<tr><td>2<sup>0</sup></td><td>1</td></tr>
<tr><td>2<sup>1</sup></td><td>2</td></tr>
<tr><td>2<sup>2</sup></td><td>4</td></tr>
<tr><td>2<sup>3</sup></td><td>8</td></tr>
<tr><td>2<sup>4</sup></td><td>16</td></tr>
<tr><td>2<sup>5</sup></td><td>32</td></tr>
<tr><td>2<sup>6</sup></td><td>64</td></tr>
<tr><td>2<sup>7</sup></td><td>128</td></tr>
</tbody></table>
</div>
<p>It's helpful to work backward.
For IP addresses, all octets are 255 or less (256 total, from 0 to 255) and
therefore do not exceed 8 bits or places.
To convert the integer 192 to binary:</p>
<pre><code>1 * 2^7 = 128
1 * 2^6 =  64 (128 + 64 = 192)
</code></pre>
<p>Then STOP.
There are no values left, and so the rest are zeroes.
Thus: 11000000</p>
<p>Our everyday counting system is base-10, but binary is base-2, and
thus another way to convert binary to decimal is to multiple each bit (1 or 0)
by the power of base two of its placeholder:</p>
<pre><code>(0 * 2^0) = 0 +
(0 * 2^1) = 0 +
(0 * 2^2) = 0 +
(0 * 2^3) = 0 +
(0 * 2^4) = 0 +
(0 * 2^5) = 0 +
(1 * 2^6) = 64 +
(1 * 2^7) = 128 = 192
</code></pre>
<p>Another way to convert to binary: simply subtract the numbers from each value.
As long as there is something remaining or the placeholder equals the remainder of the previous subtraction,
then the bit equals 1.
So:</p>
<ul>
<li>192 - 128 = 64 -- therefore the first bit is equal to 1.</li>
<li>Now take the leftover and subtract it:</li>
<li>64 - 64 = 0 -- therefore the second bit is equal to 1.</li>
</ul>
<p>Since there is nothing remaining, the rest of the bits equal 0.</p>
<h3 id="subnetting-examples"><a class="header" href="#subnetting-examples">Subnetting Examples</a></h3>
<p>Subnetting involves dividing a network into two or more subnets.
When we subnet, we first identify the number of hosts (i.e., the size of the subnet) we will require on the subnet.
For starters, let's assume that we need a subnet that can assign at most 254 IP addresses
to the devices attached to it via the router.</p>
<p>In order to do this, we need two additional IP addresses:
the <strong>subnet mask</strong> and the <strong>network address/ID</strong>.
The <strong>network address</strong> identifies the network and
the <strong>subnet mask</strong> marks the boundary between the network and the hosts.
Knowing or determining the subnet mask allows us to determine how many hosts can exist on a network.
Both the network address and the subnet mask can be written as IP addresses, but
these IP addresses cannot be assigned to computers on a network.</p>
<p>When we have determined these IPs, we will know the <strong>broadcast address</strong>.
This is the last IP address in a subnet range, and it also cannot be assigned to a connected device/host.
The <strong>broadcast address</strong> is used by a router to communicate to all connected devices on the subnet.</p>
<p>For our sake, let's work through this process backwards;
that is, let's identify and describe a network that we are already connected to and
for which we already know a device's private IP address.
We'll work with example private IP addresses that exist on separate subnets.</p>
<h4 id="example-ip-address-1-1921681624"><a class="header" href="#example-ip-address-1-1921681624">Example IP Address 1: 192.168.1.6/24</a></h4>
<p>Using the private IP address 192.168.1.6,
let's derive the network mask and the network address (or ID) from this IP address.
First, convert the decimal notation to binary.
State the mask, which is <strong>/24</strong>, or <strong>255.255.255.0</strong>.
And then derive the network addressing using an <strong>bitwise logical AND</strong> operation:</p>
<pre><code>11000000.10101000.00000001.00000110 IP              192.168.1.6
11111111.11111111.11111111.00000000 Mask            255.255.255.0
-----------------------------------
11000000.10101000.00000001.00000000 Network Address 192.168.1.0
</code></pre>
<p>Note the mask has 24 ones followed by 8 zeroes.
The /24 is used as <a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">CIDR</a> notation and marks the network portion of the IP address.
The remaining 8 bits are for the host addresses.</p>
<ul>
<li>192.168.1.6/24</li>
</ul>
<p>For Example 1, we thus have the following subnet information:</p>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>IP</th></tr></thead><tbody>
<tr><td>Netmask/Mask</td><td>255.255.255.0</td></tr>
<tr><td>Network ID</td><td>192.168.1.0</td></tr>
<tr><td>Start Range</td><td>192.168.1.1</td></tr>
<tr><td>End Range</td><td>192.168.1.254</td></tr>
<tr><td>Broadcast</td><td>192.168.1.255</td></tr>
</tbody></table>
</div>
<h4 id="example-ip-address-2-10160387524"><a class="header" href="#example-ip-address-2-10160387524">Example IP Address 2: 10.160.38.75/24</a></h4>
<p>For example 2, let's start off with a private IP address of 10.160.38.75 and a mask of /24:</p>
<pre><code>00001010.10100000.00100110.01001011 IP               10.160.38.75
11111111.11111111.11111111.00000000 Mask            255.255.255.0
-----------------------------------
00001010.10100000.00100110.00000000 Network Address   10.160.38.0
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>IP</th></tr></thead><tbody>
<tr><td>Netmask/Mask</td><td>255.255.255.0</td></tr>
<tr><td>Network ID</td><td>10.160.38.0</td></tr>
<tr><td>Start Range</td><td>10.160.38.1</td></tr>
<tr><td>End Range</td><td>10.160.38.254</td></tr>
<tr><td>Broadcast</td><td>10.160.38.255</td></tr>
</tbody></table>
</div>
<h4 id="example-ip-address-3-1721616224"><a class="header" href="#example-ip-address-3-1721616224">Example IP Address 3: 172.16.1.62/24</a></h4>
<p>For example 3, let's start off with a private IP address of 172.16.1.62 and a mask of /24:</p>
<pre><code>10101100 00010000 00000001 00100111 IP                172.16.1.62
11111111 11111111 11111111 00000000 Mask            255.255.255.0
-----------------------------------
10101100 00010000 00000001 00000000 Network Address    172.16.1.0
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>IP</th></tr></thead><tbody>
<tr><td>Netmask/Mask</td><td>255.255.255.0</td></tr>
<tr><td>Network ID</td><td>172.16.1.0</td></tr>
<tr><td>Start Range</td><td>172.16.1.1</td></tr>
<tr><td>End Range</td><td>172.16.1.254</td></tr>
<tr><td>Broadcast</td><td>172.16.1.255</td></tr>
</tbody></table>
</div>
<h4 id="determine-the-number-of-hosts"><a class="header" href="#determine-the-number-of-hosts">Determine the Number of Hosts</a></h4>
<p>To determine the number of hosts on a CIDR /24 subnet, we look at the start and end ranges.
In all three of the above examples, the start range begins with X.X.X.1 and ends with X.X.X.254.
Therefore, there are 254 maximum hosts allowed on these subnets because 1 to 254, inclusive of 1 and 254, is 254.</p>
<h4 id="example-ip-address-4-10052316"><a class="header" href="#example-ip-address-4-10052316">Example IP Address 4: 10.0.5.23/16</a></h4>
<p>The first three examples show instances where the CIDR is set to /24.
This only allows 254 maximum hosts on a subnet.
If the CIDR is set to /16, then we can theoretically allow 65,534 hosts on a subnet.</p>
<p>For example 4, let's start off then with a private IP address of 10.0.5.23 and a mask of /16:</p>
<pre><code>00001010.00000000.00000101.00010111 IP Address: 10.0.5.23
11111111.11111111.00000000.00000000 Mask:       255.255.0.0
-----------------------------------------------------------
00001010.00000000.00000000.00000000 Network ID: 10.0.0.0
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>IP</th></tr></thead><tbody>
<tr><td>IP Address</td><td>10.0.5.23</td></tr>
<tr><td>Netmask/Mask</td><td>255.255.0.0</td></tr>
<tr><td>Network ID</td><td>10.0.0.0</td></tr>
<tr><td>Start Range</td><td>10.0.0.1</td></tr>
<tr><td>End Range</td><td>10.0.255.254</td></tr>
<tr><td>Broadcast</td><td>10.0.255.255</td></tr>
</tbody></table>
</div>
<p>Since the last two octets/bytes now vary, we count up by each octet.
Therefore, the number of hosts is:</p>
<div class="table-wrapper"><table><thead><tr><th>IPs</th><th></th></tr></thead><tbody>
<tr><td>10.0.0.1</td><td></td></tr>
<tr><td>10.0.0.255</td><td>= 256</td></tr>
<tr><td>10.0.1.1</td><td></td></tr>
<tr><td>10.0.255.255</td><td>= 256</td></tr>
</tbody></table>
</div>
<ul>
<li>Number of Hosts = 256 x 256 = 65536</li>
<li>Subtract Network ID (1) and Broadcast (1) = 2 IP addresses</li>
<li>Number of Usable Hosts = 256 x 256 - 2 = 65534</li>
</ul>
<h3 id="ipv6-subnetting"><a class="header" href="#ipv6-subnetting">IPv6 subnetting</a></h3>
<p>We're not going to cover IPv6 subnetting, but if you're interested,
this is a nice article: <a href="https://supportforums.cisco.com/document/66991/ipv6-subnetting-overview-and-case-study">IPv6 subnetting overview</a></p>
<h2 id="conclusion-16"><a class="header" href="#conclusion-16">Conclusion</a></h2>
<p>As a systems administrator, it's important to have a basic understanding of how networking works,
and the basic models used to describe the internet and its applications.
System administrators have to know how to create subnets and defend against various network-based attacks.</p>
<p>In order to acquire a basic understanding, this section covered topics that included:</p>
<ul>
<li>the internet protocol suite
<ul>
<li>link layer</li>
<li>internet layer</li>
<li>transport layer</li>
</ul>
</li>
<li>IP subnetting
<ul>
<li>private IP ranges</li>
<li>IP math</li>
</ul>
</li>
</ul>
<p>In the next section, we extend upon this and discuss the domain name system (DNS) and domain names.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dns-and-domain-names"><a class="header" href="#dns-and-domain-names">DNS and Domain Names</a></h1>
<p>By the end of this section, you should know:</p>
<ul>
<li>The purpose of DNS and its role as the "phone book" of the internet.</li>
<li>The structure of domain names, including fully qualified domain names (FQDNs).</li>
<li>How DNS paths work, including root domains, top-level domains (TLDs), second-level domains, and third-level subdomains.</li>
<li>The different types of DNS records and their purposes.</li>
<li>How to use common tools like <code>dig</code>, <code>host</code>, <code>nslookup</code>, and <code>whois</code> for DNS-related tasks.</li>
</ul>
<h2 id="getting-started-10"><a class="header" href="#getting-started-10">Getting Started</a></h2>
<p>The DNS (<strong>domain name system</strong>) is referred to as the phone book of the internet.
It's responsible for mapping IP addresses to memorable names.
Thus, instead of having to remember:</p>
<p>https://128.163.35.46</p>
<p>We can instead remember this:</p>
<p>https://www.uky.edu</p>
<p>System administrators need to know about DNS because they may be responsible for administering a domain name system on their network,
and/or they may be responsible for setting up and administrating web site domains.
Either case requires a basic understanding of DNS.</p>
<h2 id="dns-intro-videos"><a class="header" href="#dns-intro-videos">DNS Intro Videos</a></h2>
<p>To help you get started, watch these two YouTube videos and read the text on recursive DNS:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=mpQZVYPuDGU">How a DNS Server (Domain Name System) works (YouTube)</a></li>
<li><a href="https://www.youtube.com/watch?v=cwT82ibOM2Q">DNS Records (YouTube)</a></li>
<li><a href="https://www.cloudflare.com/learning/dns/what-is-recursive-dns/">What is recursive DNS?</a></li>
</ul>
<h2 id="fqdn-the-fully-qualified-domain-name"><a class="header" href="#fqdn-the-fully-qualified-domain-name">FQDN: The Fully Qualified Domain Name</a></h2>
<p>The structure of the domain name system is like the structure of the UNIX/Linux file hierarchy;
that is, it is like an inverted tree.</p>
<p>Specifically, the fully qualified domain name (FQDN) starts a period at the end of
the top-level domain to indicate the root of the DNS hierarchy,
like the <code>/</code> in the Unix/Linux file system.
Although modern browsers often omit this trailing period,
it remains part of the identification of domain names within DNS systems.</p>
<p>Thus, for Google's main page, the FQDN is: <code>www.google.com.</code></p>
<p>And the parts include, which narrow as they are added:</p>
<pre><code>.           root domain
com         top-level domain (TLD)
google      second-level domain
www         third-level domain
</code></pre>
<p>This is important to know so that you understand how the <strong>Domain Name System</strong> works and
how DNS servers are responsible for their part of the network.</p>
<h3 id="root-domain"><a class="header" href="#root-domain">Root Domain</a></h3>
<p>The root domain is managed by root name servers.
These servers are listed on the <a href="https://www.iana.org/domains/root/servers">IANA</a> (Internet Assigned Numbers Authority) website, but
are managed by multiple operators.
The root servers manage the root domain, alternatively referred to as the zone, or
the <code>.</code> at the end of the <code>.com.</code>, <code>.edu.</code>, etc.</p>
<h4 id="alternative-dns-root-systems"><a class="header" href="#alternative-dns-root-systems">Alternative DNS Root Systems</a></h4>
<p>It's possible to have <a href="https://en.wikipedia.org/wiki/Alternative_DNS_root">alternate internets</a> by using outside root name servers.
This is not common, but it happens.
Read about a few of them here:</p>
<ul>
<li>opennic: <a href="https://www.opennicproject.org/">https://www.opennicproject.org/</a></li>
<li>alternic: <a href="https://en.wikipedia.org/wiki/AlterNIC">https://en.wikipedia.org/wiki/AlterNIC</a></li>
</ul>
<p>As an example, Russia is building its own alternate internet based on a separate DNS root system.
When completed, this will create a large, second internet that would be inaccessible to the rest of the world
without reconfiguring network devices, servers, DNS resolvers, etc.
You can read about in this <a href="https://spectrum.ieee.org/tech-talk/telecom/internet/could-russia-really-build-its-own-alternate-internet">IEEE Spectrum article</a>.</p>
<h3 id="top-level-domain-tld"><a class="header" href="#top-level-domain-tld">Top Level Domain (TLD)</a></h3>
<p>We are all familiar with top level domains.
These generic TLD names are the kinds that include:</p>
<ul>
<li>.com</li>
<li>.gov</li>
<li>.mil</li>
<li>.net</li>
<li>.org</li>
</ul>
<p>There are also <a href="https://en.wikipedia.org/wiki/Country_code_top-level_domain">country coded TLDs (ccTLDs)</a> such as:</p>
<ul>
<li>.ca (Canada)</li>
<li>.mx (Mexico)</li>
<li>.jp (Japan)</li>
<li>.uk (United Kingdom)</li>
<li>.us (United States)</li>
</ul>
<p>And they can be combined; e.g., <code>.com.mx</code>.</p>
<p>We can get a total count of current domain names using the command below,
which outputs 1,445 (as of October 2024):</p>
<pre><code>curl -s https://data.iana.org/TLD/tlds-alpha-by-domain.txt | sed '1d' | wc -l
</code></pre>
<blockquote>
<p>The <a href="https://curl.se/">curl</a> command is a powerful alternative to the <code>wget</code> command.
The two applications share basic functionality but also have their own use cases.
<code>curl</code> by default does not save a retrieved file.
Add the <code>-o</code> option to save a file: <code>curl -o [URLs]</code>.</p>
</blockquote>
<p>Visit the <code>iana.org</code> link in the code block above to peruse the list of TLDs.</p>
<h3 id="second-level-domain-names"><a class="header" href="#second-level-domain-names">Second Level Domain Names</a></h3>
<p>In the Google example of <code>www.google.com</code>, the second level domain is <code>google</code>.
The second level domain, the TLD together, and any further subdomains form the
<a href="https://en.wikipedia.org/wiki/Fully_qualified_domain_name">fully qualified domain name (FQDN)</a>.
Other examples of second level domains include:</p>
<ul>
<li><strong>redhat</strong> in <strong>redhat.com</strong></li>
<li><strong>debian</strong> in <strong>debian.org</strong>.</li>
<li><strong>wikipedia</strong> in <strong>wikipedia.org</strong></li>
<li><strong>uky</strong> in <strong>uky.edu</strong></li>
</ul>
<h3 id="third-level-domain-names--subdomains"><a class="header" href="#third-level-domain-names--subdomains">Third Level Domain Names / Subdomains</a></h3>
<p>When you've purchased (leased) a top and second level domain like <code>ubuntu.com</code>,
you can choose whether to add third level domains.
For example, <code>www</code> is a third level domain or subdomain.
If you owned <code>example.org</code>,
you could dedicate a separate server (or a cluster of machines) to <code>www.example.org</code> that
resolves to a different location, or
<code>www.example.org</code> could resolve to the second-level domain <code>example.org</code>.
That is:</p>
<ul>
<li>The server located at <code>www.debian.org</code> can point to the server located at <code>debian.org</code>, or</li>
<li>The server located at <code>www.debian.org</code> can point to a completely different server (website).</li>
</ul>
<p>That is, <code>www.debian.org</code> could be configured to point to a different server than <code>debian.org</code> does,
meaning that each domain could host separate websites or services.
This would be like how <code>maps.google.com</code> points to a different site than <code>mail.google.com</code>.
Yet both <code>maps</code> and <code>mail</code> are subdomains of <code>google.com</code>.
However, it has been a convention since the beginning of the web
that third-level domains marked by <code>www</code> point to their top level domains.
However, this is not true for other subdomains.</p>
<p>For example:</p>
<ul>
<li><code>google.com</code> resolves to <code>www.google.com</code></li>
<li>but <code>google.com</code> does not resolve to:
<ul>
<li><code>drive.google.com</code>, or</li>
<li><code>maps.google.com</code>, or</li>
<li><code>mail.google.com</code></li>
</ul>
</li>
</ul>
<p>Because these subdomains provide different but specific services.</p>
<h2 id="dns-paths"><a class="header" href="#dns-paths">DNS Paths</a></h2>
<p>A recursive DNS server, which is usually managed by an ISP,
is the first DNS server to be queried in the DNS system.
This is the <strong>resolver server</strong> in the first video above.
This server queries itself (recursive) to check if the domain to IP mapping has been cached
(remembered/stored) in its system.</p>
<p>If it hasn't been cached, then the DNS query is <em>forwarded</em> to a root server.
There are thirteen root servers.</p>
<pre><code>echo {a..m}.root-servers.net.
a.root-servers.net. b.root-servers.net. c.root-servers.net. d.root-servers.net. e.root-servers.net. f.root-servers.net. g.root-servers.net. h.root-servers.net. i.root-servers.net. j.root-servers.net. k.root-servers.net. l.root-servers.net. m.root-servers.net.
</code></pre>
<blockquote>
<p>The <code>echo {a..m}.root-servers.net</code> command has nothing to do with DNS.
I'm using brace expansion in Bash to simply list the root servers.</p>
</blockquote>
<p>When a DNS query is forwarded to a root server,
the root server identifies the next server to query,
depending on the top level domain (.com, .net, .edu, .gov, etc.).
If the site ends in <code>.net</code>, then the next server might be something like: <code>a.gtld-servers.net.</code>
Or if the top level domain ends in <code>.edu</code>, then the <code>a.edu-servers.net.</code> server might be queried.
Or if the top level domain ends in <code>.gov</code>, then it could be <code>a.gov-servers.net.</code>.
And so forth.</p>
<p>Those top level domains will know where to send the query next.
In many cases, the next path is to send the query to a custom domain server.
For example, Google's custom name servers are: <strong>ns1.google.com</strong> to <strong>ns4.google.com</strong>.
UKY's custom name servers are: <strong>sndc1.net.uky.edu</strong> and <strong>sndc2.net.uky.edu</strong>.
Finally, those custom name servers will know the IP address that maps to the domain.</p>
<p>We can use the <code>dig</code> command to query the non-cached DNS paths.
Let's say we want to follow the DNS path for <code>google.com</code>.
We can start by querying any <a href="https://www.iana.org/domains/root/servers">root server</a>.
In the output, we want to pay attention to the QUERY field, the ANSWER field, and the Authority Section.
We continue to use the <code>dig</code> command until the ANSWER field returns a number greater than 0.
The following commands query one of the root servers,
which points us to one of the authoritative servers for <strong>.com</strong> sites,
which points us to Google's custom nameserver, which finally provides an answer,
in fact six answers, or six IP address that all map to <strong>google.com</strong>.</p>
<p>Step by step.
First we query the root server and specify that we're interested in the DNS path for <code>google.com</code>:</p>
<pre><code>dig @e.root-servers.net google.com
</code></pre>
<p>The output shows that <code>ANSWER: 0</code> (or no answer) so we keep digging.
The <code>ADDITIONAL SECTION</code> points us to the next servers in the DNS path.
We can pick one and query that:</p>
<pre><code>dig @a.gtld-servers.net google.com
</code></pre>
<p>Again, we see that <code>ANSWER: 0</code>, so we keep digging.
The <code>ADDITIONAL SECTION</code> points us to the next servers in the DNS path, which are Google's name servers.
We pick one and query that:</p>
<pre><code>dig @ns1.google.com google.com
</code></pre>
<p>Here we see <code>ANSWER: 6</code>, which is greater than zero.
Now we know the DNS path.</p>
<p>The output for the final <code>dig</code> command lists six servers.
Google and other major organizations often use multiple servers for load balancing,
redundancy, and better geographic distribution of requests.
These servers are indicated by the <strong>A records</strong> in the DNS output.</p>
<p>Many large organizations, especially ISPs, function as <strong>autonomous systems (AS)</strong>.
These systems are large collections of IP networks under the control of a single organization and
they work to present a common routing policy to the internet.
Remember that the internet is an internet of internets!</p>
<p>We can get more information about Google as an autonomous system by locating its <strong>AS number</strong> or <strong>ASN</strong>.
We do this by using the <code>whois</code> command on one of the IP addresses listed
in the final <code>ANSWER SECTION</code> from the last output:</p>
<pre><code>whois 142.250.31.113
</code></pre>
<p>The output should include <code>OriginAS: AS15169</code>.
This is Google's ASN.
Autonomous systems need to communicate with other autonomous systems.
This is managed by the <strong>Border Gateway Protocol (BGP)</strong>.
This is a core routing protocol that manages how packets are routed
across the internet between autonomous systems.
BGP's role is to determine the <strong>best path</strong> for data to travel from one AS to another.
BGP therefore functions as the "postal service of the internet."
For a humorous (but real) take on BGP, see <a href="https://www.youtube.com/watch?v=cOE2miIh1_o">The Internet's Most Broken Protocol</a>.</p>
<p>Alternatively, we can query UKY's:</p>
<pre><code>dig @j.root-servers.net. uky.edu
dig @b.edu-servers.net. uky.edu
dig @sndc1.net.uky.edu. uky.edu
</code></pre>
<p>We can also get this path information using <code>dig</code>'s trace command:</p>
<pre><code>dig google.com +trace
</code></pre>
<p>There are a lot of <a href="https://www.geeksforgeeks.org/dig-command-in-linux-with-examples/">ways to use the dig command</a>, and you can test and explore them on your own.</p>
<h3 id="dns-record-types"><a class="header" href="#dns-record-types">DNS Record Types</a></h3>
<p>The <strong>A record</strong> in the <code>dig</code> output from the above examples shows
the mapping between the hostname and the IPv4 address.
There are other types of internet records, and
we can use the <code>dig</code> command to get information about these additional record types.
Some of the more useful records include:</p>
<ul>
<li>IN:       Internet Record</li>
<li>SOA:      Start of Authority: describes the site's DNS entries, or the
primary name server and the responsible contact information</li>
<li>NS:       Name Server: state the name servers that provide DNS resolution</li>
<li>A:        Address records: provides mapping hostname to IPv4 address</li>
<li>AAAA:     Address records: provides mapping hostname to IPv6 address</li>
<li>TXT:      TXT records contain verification data for various services</li>
<li>MX:       Mail exchanger: the MX record maps to email servers.</li>
<li>PTR:    Pointer record: provides mapping from IP Address to Hostname. This is
like the opposite of an <strong>A record</strong> and allows us to do reverse lookups..</li>
<li>CNAME:  Canonical name: this is used to alias one domain name to another,
such as <code>www.uky.edu</code> to <code>uky.edu</code> (see discussion above).</li>
</ul>
<p>To get as much information from the <code>dig</code> command at one time, we use the following <code>dig</code> command:</p>
<pre><code>dig uky.edu ANY
</code></pre>
<h3 id="dns-toolbox"><a class="header" href="#dns-toolbox">DNS Toolbox</a></h3>
<p>It's important to be able to troubleshoot DNS issues.
To do that, we have a few utilities available.
Read the <code>man</code> pages for each one:</p>
<h4 id="host-command"><a class="header" href="#host-command"><code>host</code> Command</a></h4>
<p>The <code>host</code> command is used to perform DNS lookups and returns information about a domain name or IP address.
Specifically, the <code>host</code> command resolves hostnames to IP Address; or IP addresses to hostnames.</p>
<p>The following command <strong>queries</strong> the domain name <code>uky.edu</code> and
returns the IP address associated with that domain name:</p>
<pre><code>host uky.edu
uky.edu has address 128.163.35.46
</code></pre>
<p>With the <code>-t</code> option, you can get IP address information for specific record types.
The following queries the <code>MX</code> records (email servers) for the respective domains:</p>
<pre><code>host -t MX uky.edu
host -t MX dropbox.com
host -t MX netflix.com
host -t MX wikipedia.org
</code></pre>
<p>For example, <code>host -t MX uky.edu</code> tells us that UKY uses Outlook for <code>uky.edu</code> email addresses, and
<code>host -t MX g.uky.edu</code> tells us that UKY uses the Google for <code>g.uky.edu</code> email addresses.</p>
<h4 id="dig-command"><a class="header" href="#dig-command"><code>dig</code> Command</a></h4>
<p>As discussed above, the <code>dig</code> command (Domain Information Groper) is used to retrieve DNS records,
and provides detailed information about how DNS resolution occurs.</p>
<p>We can use <code>dig</code> to query <code>uky.edu</code> (I've removed extraneous output):</p>
<pre><code>dig uky.edu
;; ANSWER SECTION:
uky.edu.		3539	IN	A	128.163.35.46
</code></pre>
<ul>
<li><strong>ANSWER SECTION</strong>: This contains the result of our query.</li>
<li><strong>Domain</strong> (<code>uky.edu</code>): The domain name being queried.</li>
<li><strong>TTL</strong> (<code>3539</code>): Time to Live, or how long the result is cached.</li>
<li><strong>IN</strong>: Internet class.</li>
<li><strong>A</strong>: Record type, in this case this refers to an IPv4 address.</li>
<li><strong>IP Address</strong> (<code>128.163.35.46</code>): The IP address that corresponds to the queried domain.</li>
</ul>
<p>We can use <code>dig</code> to examine other record types in the following ways:</p>
<pre><code>dig uky.edu MX
dig www.uky.edu CNAME
</code></pre>
<h4 id="nslookup-command"><a class="header" href="#nslookup-command"><code>nslookup</code> Command</a></h4>
<p>The <code>nslookup</code> command queries internet name servers interactively to find DNS-related information about a domain.</p>
<pre><code>nslookup
&gt; uky.edu
&gt; Server:   127.0.0.53
&gt; Address:  127.0.0.53#53

Non-authoritative answer:
Name:   uky.edu
Address: 128.163.35.46
&gt; exit
</code></pre>
<p>Explanation:</p>
<ul>
<li><strong>Server</strong>: The DNS server used for the lookup. In this case, the server is
<code>127.0.0.53</code>, which falls within the loopback address range (<code>127.0.0.0/8</code>).
This is used by <code>systemd-resolved</code>, which is a local DNS resolver and caching
service that handles DNS lookups on our systems.</li>
<li><strong>Address</strong>: The number <code>53</code> after the <code>#</code> represents the <strong>port number</strong>
(see <code>/etc/services</code> for list of port numbers). This port number is the
standard for DNS queries. So, <code>127.0.0.53#53</code> indicates that the DNS server
listening at <code>127.0.0.53</code> is accepting requests on port 53.</li>
<li><strong>Non-authoritative answer</strong>: This indicates that the response is coming from
a cache, and not directly from an authoritative DNS server.</li>
<li><strong>NAME</strong> (<code>uky.edu</code>) and <strong>Address</strong> (<code>128.163.35.46</code>): The domain name and
the corresponding IP address.</li>
</ul>
<h4 id="resolvectl"><a class="header" href="#resolvectl"><code>resolvectl</code></a></h4>
<p>Because of the role that <code>systemd</code> has here,
we can use the <code>resolvectl status</code> command to determine which external DNS servers are used behind the scenes.</p>
<p>First, we get the network card we're using for internet connection:</p>
<pre><code>ip a
</code></pre>
<p>Now we can identify the current DNS server:</p>
<pre><code>resolvectl status ens4
</code></pre>
<h4 id="whois-command"><a class="header" href="#whois-command"><code>whois</code> Command</a></h4>
<p>The <code>whois</code> command is used to look up information about who owns a particular domain name or IP address.</p>
<pre><code>whois uky.edu | less
</code></pre>
<p>Example, abbreviated output:</p>
<pre><code>Domain Name: UKY.EDU

Registrant:
    University of Kentucky
    118 Hardmon Building
    Lexington, KY 40506
    USA

Name Servers:
	SNDC1.NET.UKY.EDU
	SNDC2.NET.UKY.EDU
</code></pre>
<ul>
<li><strong>Domain Name</strong>: The domain you queried.</li>
<li><strong>Registrant</strong>: The organization that registered the domain.</li>
<li><strong>Name Servers</strong>: The authoritative name servers for the domain.</li>
</ul>
<p>While the <code>whois</code> command is a useful tool for retrieving information about domain ownership,
it's important to note that some domain owners choose to keep their information private.
Many domain registrars offer privacy protection services,
which replace the owner's contact information with generic information to protect their identity.
As a result, the output of a <code>whois</code> query may not always reveal the true owner of a domain,
showing only the registrar's privacy service instead.
This is particularly common for personal or small business domains to protect against spam or unwanted contact.</p>
<h4 id="the-resolveconf-file"><a class="header" href="#the-resolveconf-file">The <code>resolve.conf</code> File</a></h4>
<p>The <code>resolve.conf</code> file contains local resolver info.
That is, it contains your your DNS information.</p>
<pre><code>man -f  resolv.conf
resolv.conf (5) - resolver configuration file
cat /etc/resolv.conf
resolvectl status
</code></pre>
<h2 id="conclusion-17"><a class="header" href="#conclusion-17">Conclusion</a></h2>
<p>In the same way that phones have phone numbers to uniquely identify them,
servers on the internet use IP addresses to enable communication.
Since we're only human, we don't remember every phone number that we dial or every IP address that we visit.
In order to make such things human friendly, we use names instead.</p>
<p>Nameservers and DNS records act as the phone book and phone book entries of the internet.
Note that I refer to the <strong>internet</strong> and not the <strong>web</strong> here.
The web is strictly defined or limited to the HTTP/HTTPS protocol, and
there are protocols at the <a href="https://en.wikipedia.org/wiki/Application_layer">OSI application layer</a>.
For example, email servers may also have domain names and
IP addresses to resolve and use protocols like POP, IMAP, and SMTP.</p>
<p>In this section, we covered the basics of DNS that include:</p>
<ul>
<li>FQDN: the Fully Qualified Domain Name</li>
<li>Root domains</li>
<li>Top level domains (TLDs) and Country Code TLDS (ccTLDs)</li>
<li>Second level and third level domains/subdomains</li>
<li>DNS paths, and</li>
<li>DNS record types</li>
</ul>
<p>We also looked at several command line tools to query for information about the domain name system.</p>
<p>For web-based DNS tools, see <a href="https://viewdns.info/">ViewDNS.info</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="local-security"><a class="header" href="#local-security">Local Security</a></h1>
<p>By the end of this section, you should know:</p>
<ul>
<li>The purpose of a <code>chroot</code> environment and how it enhances local security by restricting users to a defined directory.</li>
<li>How to create a basic <code>chroot</code> directory and structure it to mimic a limited root file system.</li>
<li>How to set up and test the <code>chroot</code> environment to ensure users are confined to their pseudo-root directory.</li>
<li>The process for identifying and copying necessary binaries and their dependencies into a <code>chroot</code>.</li>
<li>Basic troubleshooting techniques for common issues that may arise when setting up or entering a <code>chroot</code>.</li>
<li>The limitations of <code>chroot</code> for security and how it serves as a foundational concept for containerization technologies like Docker.</li>
<li>How to configure SSH to restrict specific user groups to a <code>chroot</code> environment for added security.</li>
</ul>
<h2 id="getting-started-11"><a class="header" href="#getting-started-11">Getting Started</a></h2>
<p>Security challenges predominantly emanate from network interactions;
however, we also need to safeguard a system from potential internal threats.
This can be achieved by enforcing file permissions and ensuring that users lack certain types of access,
such as <code>sudo</code> privileges.</p>
<p>Take, for instance, the program <code>/usr/bin/gcc</code>.
<code>gcc</code> serves as the GNU C and C++ compiler.
This means it translates C or C++ source code into executable programs (like <code>exe</code> programs on Windows computers).
Unrestricted access to this compiler could potentially allow users
to create programs capable of compromising the system
(I know, based on personal experience).</p>
<p>In the following section, we will shift focus to external threats and learn about setting up a firewall.
In this section, we focus on internal threats and learn how to create a <strong>chroot</strong> environment.
This is a specialized environment that restricts user operations or processes to a defined directory,
thereby bolstering system security.
By understanding how to set up a <code>chroot</code> environment,
we will learn an effective strategy that mitigates risks stemming from within the system.
(A <code>chroot</code> environment can also be used to mitigate external threats.)</p>
<h2 id="chroot"><a class="header" href="#chroot">chroot</a></h2>
<p>As we all know, the Linux file system has a root directory <code>/</code>, and
under this directory are other directories like <code>/home</code>, <code>/bin</code>, and so forth.
A <code>chroot</code> (<strong>change root</strong>) environment is a way to create a fake root directory
at some specific location in the directory tree, and
then build an environment in that pseudo root directory that offers some applications.
Once that environment is setup, we can confine a user account(s) to that pseudo directory, and
when they login to the server,
they will only be able to see (e.g., with the <code>cd</code> command) what's in that pseudo root directory and
only be able to use the applications that we've made available in that chroot.</p>
<p>Thus, a <code>chroot</code> is a technology used to change the "apparent root <code>/</code> directory for a user or a process" and
confine that user to that location on the system.
A user or process that is confined to the <code>chroot</code> cannot easily see or access the rest of the file system and
will have limited access to the binaries (executables/apps/utilities) on the system.
From its <code>man</code> page:</p>
<pre><code>chroot (8) - run command or interactive shell with special root directory
</code></pre>
<p>Although it is not security proof, it does have some useful security use cases.
To mitigate external threats, some use <code>chroot</code> to contain DNS or <a href="https://tldp.org/LDP/solrhe/Securing-Optimizing-Linux-RH-Edition-v1.3/chap29sec254.html">web</a> servers, for example.</p>
<p><code>chroot</code> is also the conceptual basis for some kinds of virtualization technologies that are common today,
like <a href="https://en.wikipedia.org/wiki/Docker_(software)">Docker</a>.</p>
<p>And Unix-like operating systems, like FreeBSD, employ more advanced but comparable technologies
like <a href="https://docs.freebsd.org/en/books/handbook/jails/">Jails</a>.</p>
<h2 id="creating-a-chroot"><a class="header" href="#creating-a-chroot">Creating a chroot</a></h2>
<p>In this tutorial, we are going to create a <code>chroot</code>.</p>
<ol>
<li>
<p>First, we create a new directory for our chroot. That directory will be
located at <code>/mustafar</code> (but it could be elsewhere). Note that the normal
root directory is <code>/</code>, but for the chroot, the root directory will be
<code>/mustafar</code> even though it will appear as <code>/</code> in the <code>chroot</code>.</p>
<p>Depending on where we create the chroot, we want to check the permissions of
the new directory and make sure it's owned by root. If not, use <code>chown root:root /mustafar</code> to set it.</p>
<p>Create directory:</p>
<pre><code>sudo mkdir /mustafar
</code></pre>
<p>Check user and group ownership:</p>
<pre><code>ls -ld /mustafar
</code></pre>
</li>
<li>
<p>We want to make the <code>bash</code> shell available in the chroot. To do that, we
create a <code>/bin</code> directory in <code>/mustafar</code>, and copy <code>bash</code> to that directory.</p>
<pre><code>which bash
sudo mkdir /mustafar/bin
sudo cp /usr/bin/bash /mustafar/bin/
</code></pre>
<p><strong>ALTERNATIVELY</strong>: use command substitution to copy <code>bash</code>:</p>
<pre><code>sudo mkdir /mustafar/bin
sudo cp $(which bash) /mustafar/bin
</code></pre>
</li>
<li>
<p>Large software applications have dependencies, aka libraries. We need to
copy those libraries to our chroot directory so applications, like <code>bash</code>, can run.</p>
<p>To identify libraries needed by <code>bash</code>, we use the <code>ldd</code> command:</p>
<pre><code>ldd /usr/bin/bash
</code></pre>
<p><strong>Do not copy and paste!! Output (output may vary depending on your system):</strong></p>
<pre><code>linux-vdso.so.1 (0x00007fff2ab95000)
libtinfo.so.6 =&gt; /lib/x86_64-linux-gnu/libtinfo.so.6 (0x00007fbec99f6000)
libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fbec97ce000)
/lib64/ld-linux-x86-64.so.2 (0x00007fbec9ba4000)
</code></pre>
<p>Ignore the first item in the output (<code>linux-vdso.so.1</code>). But we will need
the libraries in the last three lines.</p>
</li>
<li>
<p>Next we create directories for these libraries in <code>/mustafar</code> that match or
mirror the directories they reside in. For example, in the above <code>ldd</code>
output, two directory paths are highlighted: <code>/lib/x86_64-linux-gnu</code> and
<code>/lib64</code>. Therefore, we need to create directories with those names in
<code>/mustafar</code>.</p>
<p>To do that, use the <code>mkdir</code> command to create a
<code>/mustafar/lib/x86_64-linux-gnu/</code> directory and a <code>/mustafar/lib64</code> for
the libraries. We need to name the library directories after the originals
to stay consistent with the main environment.</p>
<pre><code>sudo mkdir -p /mustafar/lib/x86_64-linux-gnu
</code></pre>
<p>And then:</p>
<pre><code>sudo mkdir /mustafar/lib64
</code></pre>
<p>Then we proceed to <strong>copy</strong> (not move!) the libraries to their respective
directories in the <strong>/mustafar</strong> directory:</p>
<pre><code>cd /mustafar/lib/x86_64-linux-gnu/
sudo cp /lib/x86_64-linux-gnu/libtinfo.so.6 .
sudo cp /lib/x86_64-linux-gnu/libc.so.6 .
cd /mustafar/lib64/
sudo cp /lib64/ld-linux-x86-64.so.2 .
</code></pre>
</li>
<li>
<p>Finally, we can test the <code>chroot</code>:</p>
<pre><code>sudo chroot /mustafar
</code></pre>
<p>If successful, you should see a new prompt like below:</p>
<pre><code>bash-5.1#
</code></pre>
<p>If you try running commands that are not part of Bash itself, you'll encounter some errors.</p>
<p>We do have access to some commands, like <code>help</code>, <code>dirs</code>, <code>pwd</code>, <code>cd</code>, and
more because these are <strong>builtin</strong> to <code>bash</code>. Utilities not builtin to
<code>bash</code> are not yet available in our chroot. These include <code>ls</code>, <code>cat</code>, <code>cp</code>, and more.
The following is a brief example of interacting in a limited chroot
environment with no outside utilities available:</p>
<pre><code>bash-5.1# ls
bash: ls: command not found
bash-5.1# help
bash-5.1# dirs
bash-5.1# pwd
bash-5.1# cd bin/
bash-5.1# dirs
bash-5.1# cd ../lib64/
bash-5.1# dirs
bash-5.1# cd ..
bash-5.1# for i in {1..4} ; do echo "$i" ; done
</code></pre>
<p>To exit the <code>chroot</code> environment, simply type <code>exit</code>:</p>
<pre><code>bash-5.1# exit
</code></pre>
</li>
</ol>
<h2 id="exercise"><a class="header" href="#exercise">Exercise</a></h2>
<p>Use the <code>ldd</code> command, to add additional binaries.
Make the following utilities/binaries available in the <code>/mustafar</code> chroot directory:</p>
<ul>
<li><code>ls</code></li>
<li><code>sleep</code></li>
</ul>
<h3 id="troubleshooting-common-chroot-setup-errors"><a class="header" href="#troubleshooting-common-chroot-setup-errors">Troubleshooting Common chroot Setup Errors</a></h3>
<p>When setting up a <code>chroot</code> environment, you may encounter an error like:</p>
<pre><code>chroot: failed to run command '/bin/bash': No such file or directory
</code></pre>
<p>This error often occurs if the <code>chroot</code> environment is missing critical files or directories,
such as the <code>bash</code> executable or its required libraries.
Here are some steps to resolve this:</p>
<ol>
<li>
<p><strong>Check for the Bash Binary</strong>: Ensure that the <code>bash</code> executable has been correctly copied to <code>/mustafar/bin/</code>:</p>
<pre><code>sudo ls /mustafar/bin/bash
</code></pre>
<p>If this file isn't there, go back to the step where you copy <code>bash</code> to the <code>chroot</code> directory.</p>
</li>
<li>
<p><strong>Verify Library Dependencies</strong>: The <code>bash</code> binary requires certain libraries to run.
Use the <code>ldd</code> command to list these dependencies and confirm they are copied to <code>/mustafar</code>:</p>
<pre><code>ldd /usr/bin/bash
</code></pre>
<p>Ensure each library listed is copied to the matching directory within <code>/mustafar</code>, such as <code>/mustafar/lib/x86_64-linux-gnu/</code> and <code>/mustafar/lib64/</code>.</p>
</li>
<li>
<p><strong>Correct File Structure</strong>: Confirm that your <code>chroot</code> directory structure mirrors the actual root structure.
The paths within <code>/mustafar</code> should match the paths of the dependencies found using <code>ldd</code>.</p>
</li>
</ol>
<p>After confirming these items, try running <code>chroot</code> again:</p>
<pre><code>sudo chroot /mustafar
</code></pre>
<p>If these checks don't resolve the issue,
double-check permissions on the <code>chroot</code> directory to ensure root ownership:</p>
<pre><code>sudo chown root:root /mustafar
</code></pre>
<h2 id="conclusion-18"><a class="header" href="#conclusion-18">Conclusion</a></h2>
<p>Systems need to be secure from the inside and out.
In order to secure from the inside, system users should be given access and permissions as needed.</p>
<p>In this section, we covered how to create a <strong>chroot</strong> environment.
The chroot confines users and processes to this pseudo root location.
It provides them limited access to the overall file system and to the software on the system.
We can use this chroot to confine users and processes, like <strong>apache2</strong> or human users.
Any user listed in <code>/etc/passwd</code> can be chrooted, and most users listed in that file are services.</p>
<p>Restricting a human user to a chrooted environment may not be necessary.
On a multi-user system, proper education and training about the policies and
uses of the system may be all that's needed.
Alternatively, when creating user accounts, we could make their default shell <code>rbash</code>, or <strong>restricted bash</strong>.
<code>rbash</code> limits access to a lot of Bash's main functions, and for added security,
it can be used in conjunction with <code>chroot</code>.
See <code>man rbash</code> for more details.</p>
<p>In summary, if a stricter environment is needed, you know how to create a basic <code>chroot</code> environment.</p>
<p><strong>Additional Sources:</strong></p>
<ul>
<li><a href="https://linuxconfig.org/how-to-automatically-chroot-jail-selected-ssh-user-logins">How to automatically chroot jail selected ssh user logins</a>.</li>
<li><a href="https://help.ubuntu.com/community/BasicChroot">BasicChroot</a></li>
<li><a href="https://www.linode.com/docs/guides/use-chroot-for-testing-on-ubuntu/">How to Use chroot for Testing on Ubuntu</a></li>
<li><a href="https://linuxhint.com/setup-linux-chroot-jails/">How To Setup Linux Chroot Jails</a></li>
</ul>
<h2 id="appendix-a-non-google-cloud-systems"><a class="header" href="#appendix-a-non-google-cloud-systems">Appendix A: Non-Google Cloud Systems</a></h2>
<p>Our user accounts and connections to our Google Cloud virtual instances are managed on the Google Cloud console,
and we reach these instances using the <code>gcloud compute ssh</code> command or through the web interface.
The <code>gcloud</code> command is special software that we installed on our personal systems and
authentication happens via our Google accounts.
However, on traditional remote systems,
we use <code>ssh</code> with its standard syntax, which is: <code>ssh user@domain.com</code> or <code>ssh user@&lt;ip_address&gt;</code>,
where <code>user</code> is the account name managed directly on the server and <code>domain.com</code> is the host name of the server.</p>
<p>On those traditional types of systems,
we can take advantage of <code>chroot</code> to isolate user accounts to a chrooted environment.
There are a number of ways to do this, but
below I demonstrate how to isolate users to a chrooted environment based on their group membership.</p>
<ol>
<li>
<p>Let's create a new user. After we create the new user, we will <code>chroot</code> that user going forward.</p>
<pre><code>sudo adduser vader
</code></pre>
</li>
<li>
<p>Create a new group called <code>mustafar</code>.
We can add users to this group that we want to jail in a chrooted environment.</p>
<pre><code>sudo groupadd mustafar
sudo usermod -a -G mustafar vader
groups vader
</code></pre>
</li>
<li>
<p>Edit <code>/etc/ssh/sshd_config</code> to direct users in the <code>chrootjail</code> group to the
<code>chroot</code> directory. Add the following line at the end of the file. Then
restart ssh server.</p>
<pre><code>sudo nano /etc/ssh/sshd_config
</code></pre>
<p>Then add:</p>
<pre><code>Match group mustafar
            ChrootDirectory /mustafar
</code></pre>
<p>Exit <code>nano</code>, and restart <code>ssh</code>:</p>
<pre><code>systemctl restart sshd
</code></pre>
</li>
<li>
<p>Test the <code>ssh</code> connection for the <code>vader</code> user.
Here I use <code>ssh</code> on the local system to connect to the local system, simply to test it.</p>
<pre><code>ssh vader@localhost
-bash-5.1$ ls
-bash: ls: command not found
exit
</code></pre>
<p>That works as expected. The user <code>vader</code> is now restricted to a special
directory and has limited access to the system or to any utilities on that
system.</p>
</li>
</ol>
<h2 id="appendix-b-additional-tools-for-securing-multi-user-shell-systems"><a class="header" href="#appendix-b-additional-tools-for-securing-multi-user-shell-systems">Appendix B: Additional Tools for Securing Multi-User Shell Systems</a></h2>
<p>In addition to <code>chroot</code> and <code>rbash</code>, other Linux tools can help secure multi-user, shell-accessible systems.
These tools can be used to restrict file modifications, monitor system changes, and limit user actions.
Together they provide an extra layer of control and protection.</p>
<ol>
<li>
<p><code>chattr</code> (Change File Attributes)</p>
<p>The <code>chattr</code> command changes file attributes on Linux filesystems. By
setting certain attributes on files, you can restrict users—even with
superuser permissions—from modifying critical files. This is particularly
useful for preventing accidental or malicious deletion or alteration of
configuration files and other sensitive data.</p>
<ul>
<li><strong>Common Usage</strong>: The most frequently used option is the <code>+i</code> (immutable) attribute, which prevents modification or deletion.</li>
</ul>
<pre><code>sudo chattr +i /path/to/important/file
</code></pre>
<p>Once this attribute is set, the file cannot be modified, renamed, or deleted until the attribute is removed with <code>chattr -i</code>.</p>
<ul>
<li><strong>Other Options</strong>: There are additional flags to explore, such as <code>+a</code>,
which allows only appending to a file, which is useful for log files that
should not be altered.</li>
</ul>
</li>
<li>
<p><code>lsattr</code> (List File Attributes)</p>
<p>The <code>lsattr</code> command is used to view the attributes set by <code>chattr</code>.
This command shows you which files are immutable or otherwise restricted.
It allows administrators to verify that critical files have the appropriate protections.</p>
<ul>
<li><strong>Common Usage</strong>:</li>
</ul>
<pre><code>lsattr /path/to/important/file
</code></pre>
<p>This command outputs a list of attributes and helps administrators quickly identify files that are protected or have special restrictions.</p>
</li>
<li>
<p><code>sudo</code> and <code>sudoers</code> Configuration</p>
<p>The <code>sudo</code> command grants specific users permission to execute commands as
superuser, but the <code>sudoers</code> file can also be configured to limit which
commands a user may execute with <code>sudo</code>. By restricting <code>sudo</code> permissions,
you can allow users access to only the commands they need to perform their roles.</p>
<ul>
<li><strong>Common Usage</strong>: Open the <code>sudoers</code> file with <code>visudo</code> to edit user permissions.
For example, to allow a user only to use <code>ls</code> and <code>cat</code> with <code>sudo</code>, add:</li>
</ul>
<pre><code>username ALL=(ALL) /bin/ls, /bin/cat
</code></pre>
</li>
<li>
<p><code>ulimit</code> (User Limits)</p>
<p>The <code>ulimit</code> command sets resource limits for user sessions, such as
maximum file sizes, number of open files, and CPU time. This is essential
in preventing users from consuming excessive resources, which could slow
down or crash the system.</p>
<ul>
<li><strong>Common Usage</strong>: To set a file size limit of 100MB for a session, use:</li>
</ul>
<pre><code>ulimit -f 100000
</code></pre>
<p>You can make these limits permanent for specific users by adding them to the user's
shell configuration file (e.g., <code>~/.bashrc</code>) or to the <code>/etc/security/limits.conf</code> file for global settings.
If you add them to a user's <code>~/.bashrc</code> file,
you can use the <code>chattr</code> command to prevent the user from editing that file.</p>
</li>
<li>
<p><code>faillock</code> and Account Lockout Policies</p>
<p><code>faillock</code> helps protect against brute-force attacks by locking user accounts after
a specified number of failed login attempts.
This can prevent unauthorized access to user accounts.</p>
<ul>
<li><strong>Common Usage</strong>: To set a policy that locks an account for 10 minutes after three failed login attempts,
edit <code>/etc/security/faillock.conf</code>:</li>
</ul>
<pre><code>deny = 3
unlock_time = 600
</code></pre>
<p>Then, restart your authentication services to apply the changes.</p>
</li>
<li>
<p><code>iptables</code> for Access Control</p>
<p>While traditionally used for network security,
<code>iptables</code> can also be configured to control user access to certain resources or services.
For example, you can restrict SSH access to specific IP addresses.
This reduces the attack surface on multi-user systems.</p>
<ul>
<li><strong>Common Usage</strong>: To limit SSH access to users coming from a specific IP address:</li>
</ul>
<pre><code>sudo iptables -A INPUT -p tcp --dport 22 -s &lt;allowed_ip&gt; -j ACCEPT
sudo iptables -A INPUT -p tcp --dport 22 -j DROP
</code></pre>
<p>On Debian-based systems, including Ubuntu,
you can use the <code>ufw</code> command (Uncomplicated Firewall) instead of <code>iptables</code>:</p>
<p>To permit SSH access (port 22) only from a specific IP address, use:</p>
<pre><code>sudo ufw allow from &lt;allowed_ip&gt; to any port 22
</code></pre>
<p>To block SSH access from all other IPs, use:</p>
<pre><code>sudo ufw deny 22
</code></pre>
<p>For example, to block SSH traffic from <code>192.168.1.100</code>, you would write:</p>
<pre><code>sudo ufw allow from 192.168.1.100` to any port 22
sudo ufw deny 22
</code></pre>
<p>Make sure <code>ufw</code> is active and running with these commands:</p>
<pre><code>sudo ufw enable
sudo ufw status
</code></pre>
</li>
</ol>
<p>Combined with <code>chroot</code> and <code>rbash</code>,
these create a layered approach to security for multi-user shell systems.
Each tool has specific use cases, and
together they help administrators establish a secure and controlled environment.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firewalls-and-backups"><a class="header" href="#firewalls-and-backups">Firewalls and Backups</a></h1>
<p>By the end of this section, you should know:</p>
<ol>
<li><strong>The Role of Firewalls in Network Security</strong>:
<ul>
<li>How firewalls control incoming (ingress) and outgoing (egress) traffic at different network layers.</li>
<li>The difference between link, IP, transport, and application layer rules.</li>
</ul>
</li>
<li><strong>Firewall Configuration in Cloud and Local Environments</strong>:
<ul>
<li>How to create, manage, and prioritize firewall rules in Google Cloud using the VPC network interface.</li>
<li>How to use Google Cloud's firewall capabilities to block specific types of traffic, such as ICMP (used by tools like <code>ping</code> and <code>traceroute</code>).</li>
</ul>
</li>
<li><strong>Understanding Google Cloud Firewall Features</strong>:
<ul>
<li>The concept of default VPC firewall rules and how to override them with higher priority rules.</li>
<li>How to configure firewall rules to enhance security at the network level.</li>
</ul>
</li>
<li><strong>Configuring Local Firewalls with Ubuntu's <code>ufw</code></strong>:
<ul>
<li>How to enable and disable <code>ufw</code> for local firewall management on Ubuntu systems.</li>
<li>Basic commands to allow or deny access to specific ports or services, such as SSH (port 22) or HTTP (port 80).</li>
<li>The use of application profiles in <code>/etc/ufw/applications.d</code> to simplify firewall rule creation for services like Apache.</li>
</ul>
</li>
<li><strong>Backup Strategies for Physical and Cloud Systems</strong>:
<ul>
<li>The difference between backing up virtual machines with Google Cloud snapshots and using local tools for bare metal systems.</li>
<li>How to create and manage Google Cloud snapshots for disaster recovery and replication purposes.</li>
</ul>
</li>
<li><strong>Using <code>rsync</code> for Backup and Synchronization</strong>:
<ul>
<li>How to use <code>rsync</code> to copy files and directories locally and to a remote server over SSH.</li>
<li>The effect of the trailing slash in <code>rsync</code> commands, and how it changes the behavior of the copy operation.</li>
<li>How to use the <code>--delete</code> option in <code>rsync</code> to synchronize directories by removing files that no longer exist in the source directory.</li>
</ul>
</li>
<li><strong>Understanding the Utility of Different Backup and Security Options</strong>:
<ul>
<li>When to use Google Cloud firewall versus a local firewall (<code>ufw</code>) and when to use snapshots versus tools like <code>rsync</code> based on your needs.</li>
<li>The advantages and limitations of each approach to both firewall management and backup strategies.</li>
</ul>
</li>
</ol>
<h2 id="getting-started-12"><a class="header" href="#getting-started-12">Getting Started</a></h2>
<p>Most security challenges come from outside of a local network, and the attack vectors are fairly broad.
To reduce our system's vulnerabilities,
a systems administrator must be able to handle the following kinds of tasks:</p>
<ul>
<li>firewall configuration and management</li>
<li>access control management</li>
<li>network monitoring and intrusion detection</li>
<li>patch management</li>
<li>VPN configuration and management</li>
<li>network segmentation</li>
<li>password and authentication policy enforcement</li>
<li>logging and auditing</li>
<li>security policies and documentation</li>
<li>incident response and disaster recovery planning</li>
<li>security vulnerability assessments</li>
<li>network hardening</li>
<li>encryption implementation</li>
<li>DNS security</li>
<li>endpoint security integration</li>
</ul>
<p>We have covered some of the tasks above.
For example, we learned how to create user accounts and password policies, and
both of these are a form of access control management.
We learned about sub-networking, which is a form of network segmentation.
We learned about the DNS system, which is a fundamental aspect of DNS security.
We touched on <code>bash</code> scripts, which can be created to automate log file evaluation,
which is helpful to understand logging and auditing.
We learned how to install software and keep our systems updated, which is a form of patch management.
Although we can only cover so much and there is a lot more to learn,
in this section we'll begin to learn firewall configuration and management.
We will also learn how to create systematic backups of our instances,
which is an important part of disaster recovery planning.</p>
<h2 id="firewalls"><a class="header" href="#firewalls">Firewalls</a></h2>
<p>A firewall program allows or denies connections for incoming (aka, <strong>ingress</strong>) or
outgoing (aka, <strong>egress</strong>) traffic.
Traffic can be controlled through the:</p>
<ul>
<li>link layer: a network interface such as an ethernet or wireless card,</li>
<li>IP layer: IPv4 or IPv6 address or address ranges,</li>
<li>transport layer: TCP, UDP, ICMP, etc., or</li>
<li>by the application layer via port numbers: HTTP (port 80), HTTPS (port 443), SSH (port 22), SMTP (port 465), etc.</li>
</ul>
<p>Firewalls have other abilities.
For example, they can be used to:</p>
<ul>
<li>place limits on the number of attempts to connect,</li>
<li>create virtual private networks, and</li>
<li>throttle bandwidth for certain applications, ports, etc.</li>
</ul>
<blockquote>
<p>As a side note, bare metal servers may have multiple ethernet network interface cards (NICs).
Each NIC would, of course, have its own MAC address, and therefore would be assigned different IP addresses.
Thus, at the link layer, incoming connections can be completely blocked on one card and
outgoing connections can be completely blocked on the other.</p>
</blockquote>
<p>To manage these connections, firewalls apply <strong>rules</strong>.
A rule may block all incoming connections, but
then allow SSH traffic through port 22, either via TCP or UDP, and
then further restrict SSH connections to a specific IP range.
And/or, another rule may block all incoming, unencrypted HTTP connections through port 80,
but allow all incoming, encrypted HTTPS connections through port 443.</p>
<h3 id="firewalls-on-google-cloud"><a class="header" href="#firewalls-on-google-cloud">Firewalls on Google Cloud</a></h3>
<p>Let's cover using Google Cloud to create a basic firewall rule.
This will prepare us for setting up new rules when we configure our <strong>LAMP</strong> servers in the next section.</p>
<blockquote>
<p>LAMP originally referred to <strong>Linux</strong>, <strong>Apache</strong>, <strong>MySQL</strong>, and <strong>PHP</strong>.
These four technologies together create a web server.
Technically, only Linux (or some other OS) and Apache (or some other web server software) are needed to serve a website.
At a basic level, all a web server does is open up an operating system's filesystem to the world.
But PHP and MySQL provide additional functionality, like the ability for a website to create an interaction between a user's input and with data in a relational database.
The <strong>M</strong> in LAMP may also refer to MariaDB, which is a fully open source clone of MySQL.
Other relational databases are usable, such as <a href="https://www.postgresql.org/">PostgreSQL</a> or <a href="https://www.sqlite.org/">SQLite</a>.
We'll use MariaDB later in this course.</p>
</blockquote>
<p>First review how our Google Cloud instances are <a href="https://cloud.google.com/vpc/docs/firewalls#more_rules_default_vpc">pre-populated with default firewall rules</a> at the network level.
Follow that with a review of the firewall <a href="https://cloud.google.com/vpc/docs/firewalls">documentation</a>, which provides an overview of the rules we'll use.</p>
<h4 id="block-the-ping-application"><a class="header" href="#block-the-ping-application">Block the <code>ping</code> application</a></h4>
<p>We'll begin by implementing a basic firewall rule where we block incoming <a href="https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol">ICMP traffic</a>.
ICMP traffic is used by several applications, such as <code>ping</code> and <code>traceroute</code>.
The <code>ping</code> command is a simple tool used to test whether a server at an IP address or domain is running.
It's therefore useful for error reporting and network diagnostics.
The <code>traceroute</code> command is used to display the path between two internet devices.
While both have their uses,
we may want to block that traffic to prevent others from gaining information about our servers.</p>
<blockquote>
<p>To see how this works, let's test <code>ping</code> first on your machines.
First, identify the public/external IP address of your Google Cloud virtual machine.
Let's say it's <code>34.345.345.222</code>.
Open your macOS <code>Terminal.app</code> or Windows Command or Powershell.
Then run the command: <code>ping 34.345.345.222</code> (of course, use your VM's external IP).
You should get a response.
To end the <code>ping</code> session, press <code>ctrl-c</code>.</p>
</blockquote>
<p>Now let's block ICMP traffic:</p>
<ol>
<li>In the Google Cloud Console, click on <strong>VPC network</strong> and select <strong>Firewall</strong>.</li>
<li>The default VPC firewall rules are listed that allow for HTTP, ICMP, RDP, and SSH traffic.</li>
<li>Priority settings are set for each rule. Lower numbers mean the rules have a higher priority.</li>
<li>The predefined rules allow for incoming ICMP traffic set at a priority level of 65534.</li>
<li>We could delete that, but we should leave these rules in place and create a higher priority rule that will supersede that.</li>
<li>Click on <strong>Create Firewall Rule</strong>.</li>
<li>For name, enter <strong>new-deny-icmp</strong>.</li>
<li>Keep priority at 1000.</li>
<li>Under <strong>Direction of traffic</strong>, keep as <strong>Ingress</strong>.</li>
<li>Under <strong>Action on match</strong>, select <strong>Deny</strong>.</li>
<li>Under <strong>Targets</strong>, select "Specified service account**.</li>
<li>In the <strong>Source IPv4</strong> ranges, enter <strong>0.0.0.0/0</strong> for all network traffic.</li>
<li>Under <strong>Protocols and ports</strong>, select <strong>Other</strong>, and type in <strong>icmp</strong> (use lowercase).</li>
<li>Click the <strong>Create</strong> button to create the rule.</li>
</ol>
<blockquote>
<p>Once the rule has been created, re-run the <code>ping</code> command.
You should not see any responses this time.</p>
</blockquote>
<p>Once you have tested this rule, feel free to keep or delete it.
To delete it, select the check box next to the rule, and then click the <strong>Delete</strong> button.
Once the rule is deleted, you can re-run the <code>ping</code> command to test if your server is responding again.</p>
<blockquote>
<p>Note: Google's Firewall rules, at extra cost, now offer the ability to block
specific domains (FQDN-based firewalls) and to block geographical regions.</p>
</blockquote>
<h3 id="os-firewall-applications"><a class="header" href="#os-firewall-applications">OS Firewall Applications</a></h3>
<p>In case you are working on firewalls on a specific machine instead of on the cloud,
then you would want to become familiar with Linux-based firewall applications.</p>
<p>On Ubuntu, the main firewall application is <a href="https://help.ubuntu.com/community/UFW">ufw</a>.
On RedHat-based distributions, the main firewall application is <a href="https://docs.fedoraproject.org/en-US/quick-docs/firewalld/">firewalld</a>.
Both of these firewall applications are user-friendly front-ends of the
<a href="https://www.netfilter.org/">iptables</a> firewall application, which is built into the Linux kernel.
Although we are using an Ubuntu distribution as our virtual machines,
Ubuntu's <code>ufw</code> firewall is disabled by default.
This is likely because it may be overkill to use both Google Cloud's firewall and Ubuntu's <code>ufw</code>.</p>
<blockquote>
<p>FreeBSD and OpenBSD, two non-Linux but Unix-like operating systems, offer <code>pf</code>:
<a href="https://docs.freebsd.org/en/books/handbook/firewalls/"><code>pf</code> on FreeBSD</a> and <a href="https://www.openbsd.org/faq/pf/"><code>pf</code> on OpenBSD</a>.
These BSD OSes are often used to build firewall servers.</p>
</blockquote>
<p><code>ufw</code> (Uncomplicated Firewall) is a user-friendly command-line firewall utility.
It simplifies firewall configuration on Debian-based Linux operating systems, such as Ubuntu.
It is designed to provide a more user friendly interface to the underlying <code>iptables</code> application.
However, it is still powerful enough to secure a system effectively.</p>
<h4 id="basic-features"><a class="header" href="#basic-features">Basic Features</a></h4>
<ul>
<li><strong>Enable/Disable Firewall</strong>:
<ul>
<li>Enable: <code>sudo ufw enable</code></li>
<li>Disable: <code>sudo ufw disable</code></li>
</ul>
</li>
<li>Allow/Deny Access:
<ul>
<li>Allow access to port 22 (<code>ssh</code>): <code>sudo ufw allow 22</code></li>
<li>Deny access to port 80 (<code>http</code>): <code>sudo ufw deny 80</code></li>
<li>Other services can be set based on the contents of the <code>/etc/services</code> file.</li>
</ul>
</li>
<li>Status and Logging:
<ul>
<li>Check <code>ufw</code> status: <code>sudo ufw status</code></li>
<li>Log firewall entries: <code>sudo ufw logging on</code></li>
<li>Change logging level: <code>sudo ufw logging low</code></li>
<li>View log entries: <code>sudo less /var/log/ufw.log</code></li>
</ul>
</li>
</ul>
<p><code>ufw</code> can also control the firewall based on a list of profiles and predefined rules.
These profiles and predefined rules are contained in the <code>/etc/ufw/applications.d</code> directory.
For example, there are three protocols for the <code>apache2</code> web server:
<strong>Apache</strong>, <strong>Apache Secure</strong>, and <strong>Apache Full</strong>.
These are defined in <code>/etc/ufw/applications.d/apache2-utils.ufw.profile</code> file:</p>
<pre><code>[Apache]
title=Web Server
description=Apache v2 is the next generation of the omnipresent Apache web server.
ports=80/tcp

[Apache Secure]
title=Web Server (HTTPS)
description=Apache v2 is the next generation of the omnipresent Apache web server.
ports=443/tcp

[Apache Full]
title=Web Server (HTTP,HTTPS)
description=Apache v2 is the next generation of the omnipresent Apache web server.
ports=80,443/tcp
</code></pre>
<p>Based on the above profile, we can set <code>ufw</code> for Apache like so:</p>
<pre><code>sudo ufw allow 'Apache Full'
</code></pre>
<p>To see other examples, read: <a href="https://ubuntu.com/server/docs/firewalls">ufw documentation</a>.
If you are using a RedHat distribution of Linux,
then checkout <a href="https://www.redhat.com/en/blog/beginners-guide-firewalld">A Beginner's Guide to firewalld in Linux</a>.</p>
<h2 id="backups"><a class="header" href="#backups">Backups</a></h2>
<p>Catastrophes (natural, physical, criminal, or out of negligence) happen.
As a systems administrator, you may be required to have backup strategies to mitigate data loss.</p>
<p>How you backup depends on the machine.
If I am managing bare metal, and I want to backup a physical disk to another physical disk,
then that requires a specific tool, like <code>rsync</code>.
However, if I am managing virtual machines, like our Google Cloud instance,
then that requires a different tool.
Therefore, in this section, I will briefly cover both scenarios.</p>
<h3 id="google-cloud-snapshots"><a class="header" href="#google-cloud-snapshots">Google Cloud Snapshots</a></h3>
<p>Since our instance on Google Cloud is a virtual machine,
we can use the Google Cloud console to create <strong>snapshots</strong> of our instance.
A <strong>snapshot</strong> is a copy of a virtual machine at the time the snapshot was taken.
What's great about taking a snapshot is that the result is basically a file of a complete operating system.
Since it's a file, it can itself be used in other projects or
used to restore a machine to the time the snapshot was taken.</p>
<p>Snapshots may also be used to document or reproduce work.
For example, if I worked with programmers, as a systems administrator,
I might help a programmer share snapshots of a virtual machine with other programmers.
Those other programmers could then restore the snapshot in their own instances, and
see and run the original work in the environment it was created in.</p>
<p>Taking snapshots in Google Cloud is very straightforward, but
since it does take up extra storage, it will accrue extra costs.
Since we want avoid that for now,
please see the following documentation for how to take a snapshot in Google Cloud:</p>
<p><a href="https://cloud.google.com/compute/docs/disks/create-snapshots">Create and manage disk snapshots</a></p>
<ol>
<li>Click on <strong>Compute Engine</strong>.</li>
<li>Click on <strong>Snapshots</strong>.</li>
<li>Click on <strong>Create Snapshot</strong>.</li>
<li>Enter a name for your snapshot.</li>
<li>Select the <strong>Source disk</strong>.</li>
<li>Select <strong>Snapshot</strong> under the <strong>Type</strong> section.</li>
<li>Select <strong>Regional</strong> under <strong>Location</strong>.
<ul>
<li>If we were concerned about a robust backup solution, we would choose <strong>Multi-regional</strong>.</li>
</ul>
</li>
<li>We don't need to add a label, but this would be prudent if we were managing multiple VMs.</li>
<li>Click on <strong>Create</strong>, if necessary:
<ul>
<li>Creating and storing snaphosts will incur additional charges.</li>
<li>If it's important to you to create a snapshot to store your progress before we start our projects, go ahead.</li>
<li>Otherwise, download any content that you want to keep.</li>
</ul>
</li>
</ol>
<h3 id="rsync"><a class="header" href="#rsync"><code>rsync</code></a></h3>
<p>If we were managing bare metal machines,
then we might use a program like <code>rsync</code> to backup physical disk drives.
<code>rsync</code> is a powerful program tha can copy disks, directories, and files.
It can copy files from one location, and send the copies, encrypted, to a remote server.</p>
<p>For example, let's say I mount an external hard drive to my filesystem at <code>/mnt/backup</code>.
To copy my home directory to <code>/mnt/backup</code>, I'd use:</p>
<pre><code>rsync -av /home/me/ /mnt/backup/
</code></pre>
<p>where <code>/home/me/</code> is the <strong>source directory</strong>, and <code>/mnt/backup/</code> is the <strong>destination directory</strong>.</p>
<p>Syntax matters here.
If I include the trailing slash on the source directory, then
<code>rsync</code> copies everything in <code>/home/me/</code> to <code>/mnt/backup/</code>.
However, if I leave the trailing slash off, like so:</p>
<pre><code>rsync -av /home/me /mnt/backup/
</code></pre>
<p>then the result will be that the directory <code>me/</code> will be copied to <code>/mnt/backup/me/</code>.</p>
<p>Let's see this in action.
Say I have two directories.
In the <code>tmp1/</code> directory, there are two files: <code>file1</code> and <code>file2</code>.
The <code>tmp2/</code> directory is empty.
To copy <code>file1</code> and <code>file2</code> to <code>tmp2</code>, then:</p>
<pre><code>ls tmp1/
file1 file2
rsync -av tmp1/ tmp2/
ls tmp2
file1 file2
</code></pre>
<p>However, if I leave that trailing slash off the source directory, then the <code>tmp1/</code> will get copied to <code>tmp2/</code>:</p>
<pre><code>ls tmp1
file1 file2
rsync -av tmp1 tmp2/
ls tmp2/
tmp1/
ls tmp2/tmp1/
file1 file2
</code></pre>
<p><code>rsync</code> can also send a source directory to a directory on a remote server, and
the directory and files being copied will be encrypted on the way.
To do this, we use <code>ssh</code> style syntax:</p>
<pre><code>rsync -av tmp1/ USER@REMOTE:~/tmp2/
</code></pre>
<p>For example:</p>
<pre><code>rsync -av tmp1 linus@222.22.33.333:~/tmp2/
</code></pre>
<h3 id="delete-option"><a class="header" href="#delete-option">Delete Option</a></h3>
<p><code>rsync</code> has a <code>--delete</code> option.
Adding this option means that <code>rsync</code> synchronizes the source directory with the destination directory.
This means that if I had already created a backup of <code>tmp1</code> to <code>tmp2</code>, and then delete <code>file1</code> in <code>tmp1</code> later,
then run <code>rsync</code> with the delete option, then <code>rsync</code> will also delete <code>file1</code> from <code>tmp2/</code>.
This is how that looks:</p>
<pre><code>ls tmp1/
file1 file2
rsync -av tmp1/ tmp2/
ls tmp2/
file1 file2
rm tmp1/file1
ls tmp1/
file2
rsync -av --delete tmp1/ tmp2/
ls tmp2
file2
</code></pre>
<p>Backups are no good if we don't know how to restore a backup to a disk.
To restore with <code>rsync</code>, we just reverse the destination directory with the source directory:</p>
<pre><code>rsync -av tmp2/ tmp1/
</code></pre>
<h2 id="conclusion-19"><a class="header" href="#conclusion-19">Conclusion</a></h2>
<p>System security involves a multi-vectored approach that includes many tasks,
from password management to log audits.
In this section, we covered firewalls and backups, and have thus addressed new vectors to protect:
firewall configuration and management and disaster recovery.</p>
<p>Since we're running an Ubuntu server on Google Cloud,
we have Google Cloud options for creating firewall rules at the network level and
for backing up disks as snapshots.
We also have Ubuntu options for creating firewall rules at the OS level using <code>ufw</code> and
for backing up disks using commands like <code>rsync</code>.
How we go about either depends entirely on our needs or on our organization's needs.
But knowing these options exist and the different reasons why we have these options,
provides quite a bit of utility.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-a-lamp-server"><a class="header" href="#creating-a-lamp-server">Creating a LAMP Server</a></h1>
<p>In this section, we learn how to set up a LAMP (Linux, Apache, MariaDB, PHP) stack.
This stack enables us to create a web server that provides extra functionality via PHP and MariaDB.
Knowing how to set up a LAMP stack is a fun and valuable, basic skill to have as a systems administrator.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installing-the-apache-web-server"><a class="header" href="#installing-the-apache-web-server">Installing the Apache Web Server</a></h1>
<p>By the end of this section, you will be able to:</p>
<ol>
<li>Install the Apache web server on an Ubuntu system and verify its status using basic commands.</li>
<li>Configure Apache to serve a basic web page, using both command line and graphical web browsers to view it.</li>
<li>Understand where Apache stores key configuration and content files, and modify the default document root to create your own custom web content.</li>
</ol>
<h2 id="getting-started-13"><a class="header" href="#getting-started-13">Getting Started</a></h2>
<p><a href="https://httpd.apache.org/">Apache</a> is an HTTP server, otherwise called web server software.
An HTTP server makes files on a computer available to others who are able to establish a connection to the computer and view the files
with a web browser.
Other HTTP server software exists and another major product is <a href="https://nginx.org/en/">nginx</a>.</p>
<p>It's important to understand the basics of an HTTP server.
Please read Apache's <a href="https://httpd.apache.org/docs/2.4/getting-started.html">Getting Started</a> page before proceeding, as it covers important basics of HTTP servers.
Each of the main sections on that page describe the important elements that make up and serve a website, including:</p>
<ul>
<li>clients, servers, and URLs</li>
<li>hostnames and DNS</li>
<li>configuration files and directives</li>
<li>web site content</li>
<li>log files and troubleshooting</li>
</ul>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>Before we install Apache, we need to update our systems first.</p>
<pre><code>sudo apt update
sudo apt -y upgrade
</code></pre>
<p>Once the machine is updated, we can install Apache2 using <code>apt</code>.
First we'll use <code>apt search</code> to identify the specific package name.
I already know that a lot of results will be returned, so let's <strong>pipe</strong> the <code>apt search</code> command through <code>head</code> to look at the initial results:</p>
<pre><code>sudo apt search apache2 | head
</code></pre>
<p>On Ubuntu, the Apache package is named <code>apache2</code>.
On other distributions, it may be named differently, such as <code>httpd</code> on Fedora.</p>
<pre><code>apt show apache2
</code></pre>
<p>Once we've confirmed that <code>apache2</code> is the package that we want, we install it with the <code>apt install</code> command.</p>
<pre><code>sudo apt install apache2
</code></pre>
<h2 id="basic-checks"><a class="header" href="#basic-checks">Basic checks</a></h2>
<p>Let's check if the server is up and running, configure some basic things, and then create a basic web site.
To start, we use <code>systemctl</code> to ensure <code>apache2</code> is enabled (starts automatically on reboot) and active (currently running):</p>
<pre><code>systemctl list-unit-files apache2.service
systemctl status apache2
</code></pre>
<p>The output shows that <code>apache2</code> is enabled, which means that it will start running automatically if the computer gets rebooted.
The output of the second command shows that <code>apache2</code> is enabled and that it is also active (running).</p>
<h2 id="creating-your-first-web-page"><a class="header" href="#creating-your-first-web-page">Creating Your First Web Page</a></h2>
<p>Since <code>apache2</code> is up and running, let's look at the default web page.
The <strong>default web page</strong> is the landing page of your server, and it is stored in the <strong>document root</strong> (<code>/var/www/html</code>) as a file named <code>index.html</code>.</p>
<p>There are two ways we can look at the default web page.
We can use a command line web browser or your regular graphical browser..
There are a number command line browsers available, such as <code>elinks</code>, <code>links2</code>, <code>lynx</code>, and <code>w3m</code> (which I prefer).</p>
<p>To check with <code>w3m</code>, we have to install it first:</p>
<pre><code>sudo apt install w3m
</code></pre>
<p>Once it's installed, we can visit our default site using the loopback IP address (aka, <code>localhost</code>).
From the command line on our server, we can run either of these two commands:</p>
<pre><code>w3m 127.0.0.1
</code></pre>
<p>Or:</p>
<pre><code>w3m localhost
</code></pre>
<p>We can also get the subnet/private IP address using the <code>ip a</code> command, and then use that with <code>w3m</code>.
For example, if <code>ip a</code> showed that my NIC has a private IP address of <strong>10.0.1.1</strong>, then I could use <code>w3m</code> with that IP address:</p>
<pre><code>w3m 10.0.1.1
</code></pre>
<p>If the <code>apache2</code> installed and started correctly, then you should see the following text at the top of the screen:</p>
<pre><code>Apache2 Ubuntu Default Page
It works!
</code></pre>
<p>To exit <code>w3m</code>, press <strong>q</strong> and then <strong>y</strong> to confirm exit.</p>
<p>To view the default web page using a regular web browser, like Firefox, Chrome, Safari, Edge, or etc., you need to get the server's public IP address.
To do that, log into the <a href="https://console.cloud.google.com/">Google Cloud Console</a>.
In the left hand navigation panel, hover your cursor over the <strong>Compute Engine</strong> link, and then click on <strong>VM instances</strong>.
You should see your <strong>External IP</strong> address in the table on that page.
You can copy that external IP address or simply click on it to open it in a new browser tab.
Then you should see the graphical version of the <strong>Apache2 Ubuntu Default Page</strong>.</p>
<p>Please take a moment to read through the text on the default page.
It provides information about where Ubuntu stores configuration files and document roots, which is where website files go.</p>
<p>Let's create our first web page.
The default page described above provides the location of the document root at <code>/var/www/html</code>.
When we navigate to that location, we'll see that there is an <code>index.html</code> file located in that directory.
This is the <strong>Apache2 Ubuntu Default Page</strong> that we described above.
Let's rename that <strong>index.html</strong> file, and create a new one:</p>
<pre><code>cd /var/www/html/
sudo mv index.html index.html.original
sudo nano index.html
</code></pre>
<p>If you know HTML, then feel free to write some basic HTML code to get started.
Otherwise, you can re-type the content below in <code>nano</code>, and then save and exit out.</p>
<pre><code>&lt;html&gt;
&lt;head&gt;
&lt;title&gt;My first web page using Apache2&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;h1&gt;Welcome&lt;/h1&gt;

&lt;p&gt;Welcome to my web site. I created this site using the Apache2 HTTP server.&lt;/p&gt;

&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>If you have our site open in your web browser, reload the page, and you should see the new text.</p>
<p>You can still view the original default page by specifying its name in the URL.
For example, if your <strong>external IP address</strong> is <strong>55.222.55.222</strong>, then you'd specify it like so:</p>
<pre><code>http://55.222.55.222/index.html.original
</code></pre>
<h2 id="conclusion-20"><a class="header" href="#conclusion-20">Conclusion</a></h2>
<p>In this section, we learned about the Apache2 HTTP server.
We learned how to install it on Ubuntu, how to use systemd (<code>systemctl</code>) commands to check its default status,
how to create a basic web page in <strong>/var/www/html</strong>,
how to view that web page using the <code>w3m</code> command line browser and with our regular graphical browser.</p>
<p>In the next section, we will install PHP to enable dynamic content, which will make our websites more interactive.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installing-and-configuring-php"><a class="header" href="#installing-and-configuring-php">Installing and Configuring PHP</a></h1>
<p>By the end of this section, you will be able to:</p>
<ol>
<li>Install and configure PHP to work with Apache2, which will enable dynamic content on your web server.</li>
<li>Provide an overview of how PHP interacts with a web server.</li>
<li>Modify Apache settings to serve PHP files as the default content.</li>
</ol>
<h2 id="getting-started-14"><a class="header" href="#getting-started-14">Getting Started</a></h2>
<p>Client-side programming languages, like JavaScript, are handled by the browser.
Major browsers like Firefox, Chrome, Safari, Edge, etc. include <a href="https://en.wikipedia.org/wiki/JavaScript_engine">JavaScript engines</a> that use just-in-time compilers
to execute the JavaScript code (Mozilla has a <a href="https://blog.mozilla.org/javascript/">nice description</a> of the process.)
From an end user's perspective, you basically install JavaScript when you install a web browser.</p>
<p><a href="https://www.php.net/">PHP</a>, on the other hand, is a server-side programming language.
This means it must be installed on the server in order to be used by the browser.
From a system administrator's perspective, this means that not only does PHP have be installed on a server,
but it must also be configured to work with the HTTP server, which in our case is Apache2.</p>
<p>The main use of PHP is to interact with databases, like MySQL, MariaDB, PostgreSQL, etc., in order to create dynamic page content.
This is our end goal.
To accomplish this, we have to:</p>
<ol>
<li>Install PHP and relevant Apache2 modules</li>
<li>Configure PHP and relevant modules to work with Apache2</li>
<li>Configure PHP and relevant modules to work with MariaDB</li>
</ol>
<h2 id="install-php"><a class="header" href="#install-php">Install PHP</a></h2>
<p>PHP allows us to create dynamic content, which means we can customize what is displayed on a web page based on user inputs or data from a database.
As normal, we will use <code>apt install</code> to install PHP and relevant modules and then restart Apache2 using the <code>systemctl</code> command:</p>
<pre><code>sudo apt install php libapache2-mod-php
sudo systemctl restart apache2
</code></pre>
<p>We can check its status and see if there are any errors:</p>
<pre><code>systemctl status apache2
</code></pre>
<h2 id="check-install"><a class="header" href="#check-install">Check Install</a></h2>
<p>To check that it's been installed and that it's working with Apache2, we can create a small PHP file in our web document root.
To do that, we navigate to the <code>/var/www/html/</code> directory, and create a file called <code>info.php</code>.
The <code>info.php</code> file allows us to verify that PHP is correctly installed and configured with Apache2.
It displays detailed information about the PHP environment on the server.</p>
<pre><code>cd /var/www/html/
sudo nano info.php
</code></pre>
<p>In that file, add the following text, then save and close the file:</p>
<pre><code>&lt;?php
phpinfo();
?&gt;
</code></pre>
<p>Now visit that file using the external IP address for your server.
For example, in Firefox, Chrome, etc, go to (<strong>be sure to replace the IP below with your IP address</strong>):</p>
<pre><code>http://55.333.55.333/info.php
</code></pre>
<p>You should see a page that provides system information about PHP, Apache2, and the server.
The top of the page should look like Figure 1 below:</p>
<figure>
<img src="images/24-phpinstall.png"
alt="PHP install page"
title="PHP install page">
<figcaption>
Fig. 1. A screenshot of the title of the PHP install page.
</figcaption>
</figure>
<h2 id="basic-configurations"><a class="header" href="#basic-configurations">Basic Configurations</a></h2>
<p>By default, Apache2 is set up to serve <a href="https://httpd.apache.org/docs/current/mod/mod_dir.html"><code>index.html</code> files first</a>, but since we are adding PHP to our setup,
we want Apache2 to prioritize PHP files to allow for dynamic content creation.</p>
<p>To prioritize PHP files, we need to edit the <code>dir.conf</code> file in the <code>/etc/apache2/mods-enabled/</code> directory.
In that file there is a line that starts with <code>DirectoryIndex</code>.
The first file in that line is <code>index.html</code>, and then there are a series of other files that Apache2 will look for in the order listed.
If any of those files exist in the document root, then Apache2 will serve those before proceeding to the next.
We simply want to put <code>index.php</code> first and let <code>index.html</code> be second on that line.</p>
<pre><code>cd /etc/apache2/mods-enabled/
sudo nano dir.conf
</code></pre>
<p>And change the line to this:</p>
<pre><code>DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm
</code></pre>
<p>Whenever we make a configuration change, we can use the <code>apachectl</code> command to check our configuration:</p>
<pre><code>apachectl configtest
</code></pre>
<p>If we get an <strong>Syntax Ok</strong> message, you can reload the Apache2 configuration and restart the service:</p>
<pre><code>sudo systemctl reload apache2
sudo systemctl restart apache2
</code></pre>
<p>If the configuration test does not return <strong>Synax Ok</strong>, check the error message for guidance, and
ensure all modifications to <code>dir.conf</code> were made correctly.</p>
<p>Now create a basic PHP page.
<code>cd</code> back to the document root directory and use <code>nano</code> to create and open and <code>index.php</code> file:</p>
<pre><code>cd /var/www/html/
sudo nano index.php
</code></pre>
<h2 id="creating-an-indexphp-file"><a class="header" href="#creating-an-indexphp-file">Creating an index.php File</a></h2>
<p>Let's now create an <strong>index.php</strong> page, and add some HTML and PHP to it.
The PHP can be a simple <a href="https://stackoverflow.com/questions/8754080/how-to-get-exact-browser-name-and-version">browser detector</a>.
This script will detect and display the browser information of whoever is visiting your site.
It uses the PHP global variable <code>$_SERVER['HTTP_USER_AGENT']</code> to print the user's browser type and version.</p>
<p>First, make sure you are in the <code>/var/www/html/</code> directory.
Use <code>sudo nano</code> to create and edit <code>index.php</code>.
Then add the following code:</p>
<pre><code>&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Browser Detector&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;You are using the following browser to view this site:&lt;/p&gt;

&lt;?php
echo $_SERVER['HTTP_USER_AGENT'] . "\n\n";

$browser = get_browser(null, true);
print_r($browser);
?&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>Next, save the file and exit <code>nano</code>.
In your browser, visit your external IP address site:</p>
<pre><code>http://55.333.55.333/
</code></pre>
<p>Although your <code>index.html</code> file still exists in your document root, Apache2 now returns the <strong>index.php</strong> file instead.
However, if for some reason the <code>index.php</code> was deleted, then Apache2 would revert to the <code>index.html</code> file
since that's listed next in the <code>dir.conf</code> <code>DirectoryIndex</code> line.</p>
<h2 id="conclusion-21"><a class="header" href="#conclusion-21">Conclusion</a></h2>
<p>In this section, we installed PHP and configured it work with Apache2.
We also created a simple PHP test page that reported our browser user agent information on our website.</p>
<p>In the next section, we'll learn how to complete the LAMP stack by adding the MariaDB relational database to our setup.
By adding a relational database, we will be able to pull data from the database and present it in the browser based on user actions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installing-and-configuring-mariadb"><a class="header" href="#installing-and-configuring-mariadb">Installing and Configuring MariaDB</a></h1>
<p>By the end of this section, you will be able to:</p>
<ol>
<li>Install and configure MariaDB as part of the LAMP stack. This will enable your server to store and manage data.</li>
<li>Create and secure a MariaDB root user, set up a regular user for day-to-day operations, and understand best practices for database security.</li>
<li>Write basic SQL commands to create tables, insert records, and run queries.</li>
<li>Integrate MariaDB with PHP to build dynamic web pages.</li>
</ol>
<h2 id="getting-started-15"><a class="header" href="#getting-started-15">Getting Started</a></h2>
<p>We started our LAMP stack when we installed Apache2, and then we added extra functionality when we installed and configured PHP to work with Apache2.
In this section, our objective is to complete the LAMP stack and install and configure <a href="https://en.wikipedia.org/wiki/MariaDB">MariaDB</a>.</p>
<p>MariaDB is a (so-far) compatible fork of the MySQL relational database.
It allows us to store, retrieve, and manage data for our websites.
This makes our web applications dynamic and capable of handling complex user interactions.
If you need a refresher on relational databases, the MariaDB website can help.
See: <a href="https://mariadb.com/kb/en/introduction-to-relational-databases/">Introduction to Relational Databases</a>.</p>
<p>It's also good to review the documentation for any technology that you use.
MariaDB has <a href="https://mariadb.org/documentation/">good documentation</a> and getting started pages.</p>
<h2 id="install-and-set-up-mariadb"><a class="header" href="#install-and-set-up-mariadb">Install and Set Up MariaDB</a></h2>
<p>In this section, we'll learn how to install, setup, secure, and configure the MariaDB relational database.
The goal it to make it work with the Apache2 web server and the PHP programming language.</p>
<p>First, let's install MariaDB Community Server, and then log into the MariaDB shell under the <strong>MariaDB root</strong> account.</p>
<pre><code>sudo apt install mariadb-server mariadb-client
</code></pre>
<p>This should also start and enable the database server, but we can check if it's running and enabled using the <code>systemctl</code> command:</p>
<pre><code>systemctl status mariadb
</code></pre>
<p>Next we need to run a post installation script called <code>mysql_secure_installation</code> that sets up the MariaDB root password and performs security checks.
To do that, run the following command, and <strong>be sure to save the MariaDB root password you create</strong>:</p>
<pre><code>sudo mysql_secure_installation
</code></pre>
<p>Again, here is where you create a root password for the MariaDB database server.
<strong>Be sure to save that and not forget it!</strong>
When you run the above script, you'll get a series of prompts to respond to like below.
Press <strong>enter</strong> for the first prompt, press <strong>Y</strong> for the prompts marked <strong>Y</strong>, and input your own password.
Since this server is exposed to the internet, be sure to use a complex password.</p>
<pre><code>Enter the current password for root (enter for none):
Set root password: Y
New Password: [YOUR-PASSWORD-HERE]
Re-enter new password: [YOUR-PASSWORD-HERE]
Remove anonymous users: Y
Disallow root login remotely: Y
Remove test database and access to it: Y
Reload privilege tables now: Y
</code></pre>
<blockquote>
<p>Removing anonymous users ensures that no one can access the database without credentials.
Disallowing remote root login reduces the risk of unauthorized remote access.</p>
</blockquote>
<p>We can login to the database to test it.
In order to do so, we have to become the <strong>root Linux user</strong>, which we can do with the following command:</p>
<pre><code>sudo su
</code></pre>
<blockquote>
<p>Note: we need to generally be careful when we enter commands on the command
line, because it's a largely unforgiving computing environment. But we need
to be especially careful when we are logged in as the Linux root user. This
user can delete anything, including files that the system needs in order to
boot and operate. Always use <code>exit</code> immediately after finishing tasks as root
to minimize the risk of accidental changes that could affect the entire
system.</p>
</blockquote>
<p>After we are root, we can login to MariaDB, run the <code>show databases;</code> command, and then exit MariaDB the <code>\q</code> command:</p>
<pre><code>root@hostname:~# mariadb -u root
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 47
Server version: 10.3.34-MariaDB-0ubuntu0.20.04.1 Ubuntu 20.04

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
+--------------------+
3 rows in set (0.002 sec)
</code></pre>
<blockquote>
<p>Note: If we are logging into the root database account as the root Linux user, we don't need to enter our password.</p>
</blockquote>
<h2 id="create-and-set-up-a-regular-user-account"><a class="header" href="#create-and-set-up-a-regular-user-account">Create and Set Up a Regular User Account</a></h2>
<p>We need to reserve the <strong>root MariaDB user</strong> for special use cases.
Instead we create a <strong>regular MariaDB user</strong>.
Using a regular user account minimizes the security risks associated with performing everyday operations.
Root privileges should be reserved for administrative tasks only!</p>
<p>To create a regular MariaDB user, we use the <code>create</code> command.
In the command below, I create a new user called <strong>webapp</strong>.
I use a complex password that I insert within the single quotes at the end:</p>
<pre><code>MariaDB [(none)]&gt; create user 'webapp'@'localhost' identified by '[YOUR-PASSWORD-HERE]';
</code></pre>
<p>If the prompt returns a <strong>Query OK</strong> message, then the new user should have been created without any issues.</p>
<h2 id="create-a-practice-database"><a class="header" href="#create-a-practice-database">Create a Practice Database</a></h2>
<p>As the root database user, let's create a new database for a regular, new user.</p>
<p>The regular user will be granted <strong>all privileges</strong> on the new database, including all its tables.
Other than granting <strong>all privileges</strong>, we could limit the user to specific privileges, including:
<strong>CREATE, DROP, DELETE, INSERT, SELECT, UPDATE, and GRANT OPTION</strong>.
Such privileges may be called operations or functions, and they allow MariaDB users to use and modify the databases, where appropriate.
For example, we may want to limit the <strong>webapp</strong> user to only be able to use <strong>SELECT</strong> commands.
It totally depends on the purpose of the database and our security risks.</p>
<pre><code>MariaDB [(none)]&gt; create database linuxdb;
MariaDB [(none)]&gt; grant all privileges on linuxdb.* to 'webapp'@'localhost';
MariaDB [(none)]&gt; show databases;
</code></pre>
<p>Exit out of the MariaDB database as the <strong>root MariaDB user</strong>.
Then exit out of the <strong>root Linux user account</strong>.
You should be back to your normal Linux user account:</p>
<pre><code>MariaDB [(none)]&gt; \q
root@hostname:~# exit
</code></pre>
<blockquote>
<p><strong>Note:</strong> relational database keywords are often written in all capital
letters. As far as I know, this is simply a convention to make the code more
readable. However, in most cases I'll write the keywords in lower case
letters. This is simply because, by convention, I'm super lazy.</p>
</blockquote>
<h2 id="logging-in-as-regular-user-and-creating-tables"><a class="header" href="#logging-in-as-regular-user-and-creating-tables">Logging in as Regular User and Creating Tables</a></h2>
<p>We can start doing MariaDB work.
As a reminder, we've created a new MariaDB user named <strong>webapp</strong> and a new database for <strong>webapp</strong> that is called <strong>linuxdb</strong>.
When we run the <code>show databases</code> command as the <strong>webapp</strong> user, we should see the <strong>linuxdb</strong> database (and only the <strong>linuxdb</strong> database).
Note below that I use the <code>-p</code> option.
This instructs MariaDB to request the password for the <strong>webapp</strong> user, which is required to log in.</p>
<pre><code>mariadb -u webapp -p
MariaDB [(none)]&gt; show databases;
MariaDB [(none)]&gt; use linuxdb;
</code></pre>
<p>A database is not worth much without data.
In the following code, I create and define a new table for our <strong>linuxdb</strong> database.
The table will be called <strong>distributions</strong>, and it will contain data about various Linux distributions.
This includes the name of distribution, distribution developer, and founding date.
Creating this kind of structure with separate fields to store essential data is a common approach for structuring data that
can be easily queried and expanded.</p>
<pre><code>MariaDB [(linuxdb)]&gt; create table distributions
    -&gt; (
    -&gt; id int unsigned not null auto_increment,
    -&gt; name varchar(150) not null,
    -&gt; developer varchar(150) not null,
    -&gt; founded date not null,
    -&gt; primary key (id)
    -&gt; );
Query OK, 0 rows affected (0.07 sec)

MariaDB [(linuxdb)]&gt; show tables;
MariaDB [(linuxdb)]&gt; describe distributions;
</code></pre>
<p>Congratulations! Now create some records for that table.</p>
<h3 id="adding-records-into-the-table"><a class="header" href="#adding-records-into-the-table">Adding records into the table</a></h3>
<p>We can populate our <strong>linuxdb</strong> database with some data.
We'll use the <code>insert</code> command to add our records into our <strong>distribution</strong> table.</p>
<pre><code>MariaDB [(linuxdb)]&gt; insert into distributions (name, developer, founded) values
    -&gt; ('Debian', 'The Debian Project', '1993-09-15'),
    -&gt; ('Ubuntu', 'Canonical Ltd.', '2004-10-20'),
    -&gt; ('Fedora', 'Fedora Project', '2003-11-06');
Query OK, 3 rows affected (0.004 sec)
Records: 3  Duplicates: 0  Warnings: 0
MariaDB [(linuxdb)]&gt; select * from distributions;
</code></pre>
<p>Success! Now let's test our table.</p>
<h3 id="testing-commands"><a class="header" href="#testing-commands">Testing Commands</a></h3>
<p>We will complete the following tasks to refresh our MySQL/MariaDB knowledge:</p>
<ul>
<li>retrieve some records or parts of records,</li>
<li>delete a record,</li>
<li>alter the table structure so that it will hold more data, and</li>
<li>add a record:</li>
</ul>
<pre><code>MariaDB [(linuxdb)]&gt; select name from distributions;
MariaDB [(linuxdb)]&gt; select founded from distributions;
MariaDB [(linuxdb)]&gt; select name, developer from distributions;
MariaDB [(linuxdb)]&gt; select name from distributions where name='Debian';
MariaDB [(linuxdb)]&gt; select developer from distributions where name='Ubuntu';
MariaDB [(linuxdb)]&gt; select * from distributions;
MariaDB [(linuxdb)]&gt; alter table distributions
    -&gt; add packagemanager char(3) after name;
MariaDB [(linuxdb)]&gt; describe distributions;
MariaDB [(linuxdb)]&gt; update distributions set packagemanager='APT' where id='1';
MariaDB [(linuxdb)]&gt; update distributions set packagemanager='APT' where id='2';
MariaDB [(linuxdb)]&gt; update distributions set packagemanager='DNF' where id='3';
MariaDB [(linuxdb)]&gt; select * from distributions;
MariaDB [(linuxdb)]&gt; delete from distributions where name='Debian';
MariaDB [(linuxdb)]&gt; insert into distributions
    -&gt; (name, packagemanager, developer, founded) values
    -&gt; ('Debian', 'APT', 'The Debian Project', '1993-09-15'),
    -&gt; ('CentOS', 'YUM', 'The CentOS Project', '2004-05-14');
MariaDB [(linuxdb)]&gt; select * from distributions;
MariaDB [(linuxdb)]&gt; select name, packagemanager
    -&gt; from distributions
    -&gt; where founded &lt; '2004-01-01';
MariaDB [(linuxdb)]&gt; select name from distributions order by founded;
MariaDB [(linuxdb)]&gt; \q
</code></pre>
<h2 id="install-php-and-mysql-support"><a class="header" href="#install-php-and-mysql-support">Install PHP and MySQL Support</a></h2>
<p>The next goal is to complete the connection between PHP and MariaDB so that we can use both for our websites.
Adding PHP support for MariaDB allows us to write scripts that can interact with the database.
This enables us to dynamically display and modify content in the web browser based on user interactions.</p>
<p>First install PHP support for MariaDB.
We're installing some modules alongside the basic support.
These may or may not be needed, but I'm installing them to demonstrate some basics.</p>
<pre><code>sudo apt install php-mysql
</code></pre>
<p>And then restart Apache2 and MariaDB:</p>
<pre><code>sudo systemctl restart apache2
sudo systemctl restart mariadb
</code></pre>
<h3 id="create-php-scripts"><a class="header" href="#create-php-scripts">Create PHP Scripts</a></h3>
<p>In order for PHP to connect to MariaDB, it needs to authenticate itself.
To do that, we will create a <strong>login.php</strong> file in <strong>/var/www/html</strong>.
We also need to change the group ownership of the file and its permissions.
Since this file contains password information, changing its permissions mean we prevent others from accessing it.</p>
<pre><code>cd /var/www/html/
sudo touch login.php
sudo chmod 640 login.php
sudo chown :www-data login.php
ls -l login.php
sudo nano login.php
</code></pre>
<p>In the file, add the following credentials.
If you used a different database name than <strong>linuxdb</strong> and a different username than <strong>webapp</strong>, then you need to substitute your names below.
You need to use your own password where I have the Xs:</p>
<pre><code>&lt;?php // login.php
$db_hostname = "localhost";
$db_database = "linuxdb";
$db_username = "webapp";
$db_password = "[YOUR-PASSWORD-HERE]";
?&gt;
</code></pre>
<p>Next we create a new PHP file for our website.
This file will display HTML but will primarily be PHP interacting with our MariaDB <strong>distributions</strong> table in our <strong>linuxdb</strong> database.</p>
<p>Create a file titled <strong>distros.php</strong>.</p>
<pre><code>sudo nano distros.php
</code></pre>
<p>Then copy over the following text.
I suggest you transcribe it, especially if you're interested in learning a bit of PHP, but you can simply copy and paste it into the <code>nano</code> buffer:</p>
<pre><code>&lt;html&gt;
&lt;head&gt;
&lt;title&gt;MySQL Server Example&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;?php

// Load MySQL credentials
require_once 'login.php';

// Establish connection
$conn = mysqli_connect($db_hostname, $db_username, $db_password) or
  die("Unable to connect");

// Open database
mysqli_select_db($conn, $db_database) or
  die("Could not open database '$db_database'");

// QUERY 1
$query1 = "show tables from $db_database";
$result1 = mysqli_query($conn, $query1);

$tblcnt = 0;
while($tbl = mysqli_fetch_array($result1)) {
  $tblcnt++;
}

if (!$tblcnt) {
  echo "&lt;p&gt;There are no tables&lt;/p&gt;\n";
}
else {
  echo "&lt;p&gt;There are $tblcnt tables&lt;/p&gt;\n";
}

// Free result1 set
mysqli_free_result($result1);

// QUERY 2
$query2 = "select name, developer from distributions";
$result2 = mysqli_query($conn, $query2);

$row = mysqli_fetch_array($result2, MYSQLI_NUM);
printf ("%s (%s)\n", $row[0], $row[1]);
echo "&lt;br/&gt;";

$row = mysqli_fetch_array($result2, MYSQLI_ASSOC);
printf ("%s (%s)\n", $row["name"], $row["developer"]);

// Free result2 set
mysqli_free_result($result2);

// Query 3
$query3 = "select * from distributions";
$result3 = mysqli_query($conn, $query3);

while($row = $result3-&gt;fetch_assoc()) {
  echo "&lt;p&gt;Owner " . $row["developer"] . " manages distribution " . $row["name"] . ".&lt;/p&gt;";
}

mysqli_free_result($result3);

$result4 = mysqli_query($conn, $query3);
while($row = $result4-&gt;fetch_assoc()) {
  echo "&lt;p&gt;Distribution " . $row["name"] . " was released on " . $row["founded"] . ".&lt;/p&gt;";
}

// Free result4 set
mysqli_free_result($result4);

/* Close connection */
mysqli_close($conn);

?&gt;

&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>Save the file and exit out of <code>nano</code>.</p>
<h3 id="test-syntax"><a class="header" href="#test-syntax">Test Syntax</a></h3>
<p>After you save the file and exit the text editor, we need to test the PHP syntax.
If there are any errors in our PHP, these commands will show the line numbers that are causing errors or leading up to errors.
Nothing will output if all is well with the first command.
If all is well with the second command, HTML should be outputted:</p>
<pre><code>sudo php -f login.php
sudo php -f distros.php
</code></pre>
<h2 id="conclusion-22"><a class="header" href="#conclusion-22">Conclusion</a></h2>
<p>Congratulations! If you've reached this far, you have successfully created a LAMP stack.
In the process, you have learned:</p>
<ul>
<li>how to install and set up MariaDB</li>
<li>how to create MariaDB root and regular user accounts</li>
<li>how to create a test database with play data for practicing, and</li>
<li>how to connect this with PHP for display on a webpage.</li>
</ul>
<p>In regular applications of these technologies, there's a lot more involved, but completing the above process is a great start to learning more.
In the next section, we will apply what we learned in the PHP and MariaDB sections to install and configure a WordPress installation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-wordpress"><a class="header" href="#install-wordpress">Install WordPress</a></h1>
<p>By the end of this section, you will be able to:</p>
<ol>
<li>Manually install and configure WordPress on your server, giving you complete control over your installation.</li>
<li>Set up a MySQL database for WordPress and link it through configuration files.</li>
<li>Understand the basics of WordPress file management, security configurations, and user setup for dynamic content management.</li>
</ol>
<h2 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h2>
<p><a href="https://en.wikipedia.org/wiki/WordPress">WordPress</a> is a free and open source content management system (CMS).
Originally, its focus was on providing a platform for blogging,
but throughout its lifespan it has become a general purpose CMS that functions as a website builder.
Two sites exist to provide access to WordPress:
<a href="https://wordpress.com">WordPress.com</a> and <a href="https://wordpress.org">Wordpress.org</a>.
WordPress.com is a hosted service where WordPress handles everything, from updates to security.
Customers are mainly responsible for content and the appearance of their sites.
Various paid plans can extend the functionality offered to WordPress.com customers.</p>
<p>WordPress.org is maintained by the <a href="https://wordpressfoundation.org/">WordPress Foundation</a>, which oversees its development and provides access to the WordPress software.
When we download the WordPress software, we download it from WordPress.org.
Unlike the hosted solution, WordPress.org is for users who want full control and responsibility over their website installation and maintenance.</p>
<p>WordPress is widely used software, and because of that, it's often the focus of attack.
Take a moment to read about the developer's efforts to protect WordPress: <a href="https://wordpress.org/about/security/">Security</a>.
We will not need to update our WordPress installs during the course of this course, but you should be familiar with the update process
in case you decide to maintain your install or an install at a future date: <a href="https://wordpress.org/documentation/article/updating-wordpress/">Updating WordPress</a>.</p>
<p>Plugins are often used with WordPress sites to offer all sorts of additional capabilities.
Currently, there are over <a href="https://wordpress.org/plugins/">60 thousand plugins</a> available for WordPress, but some are of higher quality and utility than others.
In addition to the thousands of available plugins, there are over <a href="https://wordpress.org/themes/">10 thousand free themes</a> for WordPress sites.
Plus, many businesses offer paid themes or can offer customized themes based on customer needs.
These themes can drastically alter the appearance and usability of a WordPress site.
I encourage you to explore plugins, develop, and add content to your WordPress sites, but the main goal
as a systems administrator is to set up the sites and not build out content.</p>
<h2 id="installation-1"><a class="header" href="#installation-1">Installation</a></h2>
<p>So far I have shown you how to install software using two methods:</p>
<ul>
<li>using the <code>apt</code> command</li>
<li>downloading from GitHub</li>
</ul>
<p>In this lesson, we are going to install WordPress by downloading the most recent version from WordPress.org and installing it manually.
The WordPress application is available via the <code>apt</code> command,
but the <code>apt</code> installation method often requires additional manual configuration that can be inconsistent or more difficult to troubleshoot
compared to the manual process we're using here.</p>
<p>We are going to <em>kind of</em> follow the documentation provided by WordPress.org.
You should read through the documentation <strong>before</strong> following my instructions, but then follow the process I outline here instead
because the documentation uses some different tools than we'll use.</p>
<p>Another reason we do this manually is because it builds on what we have learned when we created the <code>login.php</code> and <code>distros.php</code> pages.
That is, the two processes are similar.
In both cases, we create a specific database for our platform, we create a specific user for that database,
and we provide login credentials in a specific file.</p>
<p>First, read through <strong>but do not follow the following instructions</strong>:</p>
<p><a href="https://wordpress.org/documentation/article/how-to-install-wordpress/">How to install WordPress</a></p>
<h2 id="customized-installation-process"><a class="header" href="#customized-installation-process">Customized Installation Process</a></h2>
<p>After you have read through the WordPress.org documentation, follow the steps below to complete the manual install:</p>
<h3 id="step-1-requirements"><a class="header" href="#step-1-requirements">Step 1: Requirements</a></h3>
<p>All major software have dependencies, other software or code that it needs to run.
We used the <code>ldd</code> command to discover the dependencies of simple commands like <code>ls</code> when we created our <code>chroot</code> environments.
When we install software via <code>apt</code>, the <code>apt</code> program installs the needed dependencies for us.
Since our plan is to install WordPress outside of the <code>apt</code> ecosystem, we need to make sure that our systems
meet the requirements for our installation.
The <a href="https://wordpress.org/about/requirements/">WordPress.org Requirements</a> page states that the WordPress installation requires
at least PHP version 7.4 or greater and MariaDB version 10.5 or greater.
We can check that our systems meet these requirements with the following commands:</p>
<pre><code>php --version
mariadb --version
</code></pre>
<p>The output from <code>php --version</code> shows that our systems have PHP 8.1, which is greater than PHP 7.4.
The output from <code>mariadb --version</code> show that our systems have MariaDB 10.6.18, which is greater than MariaDB 10.5.
If your versions are below the required numbers, you will need to update PHP or MariaDB before proceeding.</p>
<p>Next, we need to add some additional PHP modules to our system to let WordPress operate at full functionality.
We can install these using the <code>apt</code> command:</p>
<pre><code>sudo apt install php-curl php-xml php-imagick php-mbstring php-zip php-intl
</code></pre>
<p>Then restart Apache2 and MariaDB:</p>
<pre><code>sudo systemctl restart apache2
sudo systemctl restart mariadb
</code></pre>
<h3 id="step-2-download-and-extract"><a class="header" href="#step-2-download-and-extract">Step 2: Download and Extract</a></h3>
<p>The next step is to download and extract the WordPress software, which is comes as a <strong>zip</strong> file.
Although we only download one file, when we extract it with the <code>zip</code> command, the extraction will result in a new directory
that contains multiple files and subdirectories.
The general instructions include:</p>
<ol>
<li>Change to the <code>/var/www/html</code> directory.</li>
<li>Download the latest version of WordPress using the <code>wget</code> program.</li>
<li>Extract the package using the <code>unzip</code> program.</li>
<li>Delete the zip file to prevent clutter in the directory. You can wait to delete this file until you've successfully installed WordPress.</li>
</ol>
<p>Specifically, this means we do the following on the command line:</p>
<pre><code>cd /var/www/html
sudo wget https://wordpress.org/latest.zip
sudo apt install unzip
sudo unzip latest.zip
sudo rm latest.zip
</code></pre>
<p>Using the <code>sudo unzip latest.zip</code> command creates a directory called <strong>wordpress</strong>, as noted in the documentation.
If we leave that alone, then the full path of our installations will located at <code>/var/www/html/wordpress</code>.</p>
<h3 id="step-3-create-the-database-and-a-user"><a class="header" href="#step-3-create-the-database-and-a-user">Step 3: Create the Database and a User</a></h3>
<p>The WordPress documentation describes how to use <a href="https://www.phpmyadmin.net/">phpMyAdmin</a> to create the WordPress database and user.
<code>phpMyAdmin</code> is a graphical front end to the MySQL/MariaDB relational database that you would access through the browser.
However, we are going to create the WordPress database and a database user using the same process we used
to create a database and user for our <code>login.php</code> and <code>distros.php</code> pages.</p>
<p>The general instructions are:</p>
<ol>
<li>Login as the root Linux user, and then</li>
<li>login as the MariaDB root user.</li>
</ol>
<p>Specifically, we do the following on the command line:</p>
<pre><code>sudo su
mariadb -u root
</code></pre>
<p>The <code>mariadb -u root</code> command puts us in the MariaDB command prompt.
The next general instructions are to:</p>
<ol>
<li>Create a new user for the WordPress database</li>
<li>Be sure to use a strong password.</li>
<li>Create a new database for WordPress</li>
<li>Grant all privileges to the new user for the new database</li>
<li>Examine the output</li>
<li>Exit the MariaDB prompt</li>
</ol>
<p>Specifically, this means the following:</p>
<pre><code>create user 'wordpress'@'localhost' identified by '[YOUR-PASSWORD-HERE]';
create database wordpress;
grant all privileges on wordpress.* to 'wordpress'@'localhost';
show databases;
\q
</code></pre>
<p>Then exit out of the Linux root account:</p>
<pre><code>exit
</code></pre>
<p>By creating a dedicated database user for WordPress, we can limit access to only what's necessary for WordPress to function.
This improves security by reducing privileges for this account.</p>
<h3 id="step-4-set-up-wp-configphp"><a class="header" href="#step-4-set-up-wp-configphp">Step 4: Set up wp-config.php</a></h3>
<p>When we created the <code>login.php</code> file that contained the name of the database (e.g. linuxdb), the name of the database user (e.g., webapp),
and the user's password, we followed the same general process that WordPress follows.
Instead of <code>login.php</code>, WordPress uses a file called <code>wp-config.php</code>.
We have to edit that file.</p>
<p>Follow these general steps:</p>
<ol>
<li>Change to the <strong>wordpress</strong> directory, if you haven't already.</li>
<li>Copy and rename the <strong>wp-config-sample.php</strong> file to <strong>wp-config.php</strong>.</li>
<li>Edit the file and add your WordPress database name, user name, and password in the fields for <strong>DB_NAME</strong>, <strong>DB_USER</strong>, and <strong>DB_PASSWORD</strong>.</li>
</ol>
<p>This means that we specifically do the following:</p>
<pre><code>cd /var/www/html/wordpress
sudo cp wp-config-sample.php wp-config.php
sudo nano wp-config.php
</code></pre>
<p>In <code>nano</code>, add your database name, user, and password in the appropriate fields, just like we did with our <code>login.php</code> file.
Double-check your entries in <code>wp-config.php</code>.
Incorrect details will prevent WordPress from connecting to the database and will result in errors during setup.</p>
<p>Additionally, we want to disable FTP uploads to the site.
To do that, navigate to the end of the <code>wp-config.php</code> file and add the following line:</p>
<pre><code>define('FS_METHOD','direct');
</code></pre>
<p>Disabling FTP uploads with the above statement allows WordPress to directly write to your filesystem.
This makes it easier to manage themes and plugins without needing FTP credentials every time.</p>
<h3 id="step-5-optional"><a class="header" href="#step-5-optional">Step 5: <strong>Optional</strong></a></h3>
<p>The WordPress files were installed at <code>/var/www/html/wordpress</code>.
This means that when our WordPress websites become public, they'll be available at the following URL:</p>
<pre><code>http://[IP ADDRESS]/wordpress
</code></pre>
<p>If you want to have a different ending to your URL, then you want to rename your <code>wordpress</code> directory to something else.
The WordPress documentation uses <strong>blog</strong> as an example.
But it could be something different, as long as it contains no spaces or special characters.
Be sure to keep the directory name lowercase (no spaces and only alphanumeric characters).
For example, if I want to change mine to <strong>blog</strong>, then:</p>
<pre><code>cd /var/www/html
sudo mv wordpress blog
</code></pre>
<h3 id="step-6-change-file-ownership"><a class="header" href="#step-6-change-file-ownership">Step 6: Change File Ownership</a></h3>
<p>WordPress will need to write to files in the base directory.
Assuming you are still in your base directory, whether that is <code>/var/www/html/wordpress</code>, <code>/var/www/html/blog</code>, or like, run the following command:</p>
<pre><code>sudo chown -R www-data:www-data *
</code></pre>
<p>Changing the file ownership ensures that the web server (<code>www-data</code>) can read and write to files as needed.
Without this, WordPress might face permission errors during installation or when uploading files.</p>
<h3 id="step-7-run-the-install-script"><a class="header" href="#step-7-run-the-install-script">Step 7: Run the Install Script</a></h3>
<p>The next part of the process takes place in the browser.
The location (URL) that you visit in the browser depends on your specific IP address and the name of the directory in <strong>/var/www/html</strong> that
we extracted WordPress to or that you renamed if you followed <strong>Step 5</strong>.
Thus, if my IP address is 11.111.111.11 and I renamed by directory to <strong>blog</strong>, then I need to visit the following URL:</p>
<pre><code>http://11.111.111.11/blog/wp-admin/install.php
</code></pre>
<p><strong>IF</strong> I kept the directory named <strong>wordpress</strong>, then this is the URL that I use:</p>
<pre><code>http://11.111.111.11/wordpress/wp-admin/install.php
</code></pre>
<h3 id="finishing-installation"><a class="header" href="#finishing-installation">Finishing installation</a></h3>
<p>From this point forward, the steps to complete the installation are exactly the steps you follow using WordPress's documentation.</p>
<p>Most importantly, you should see a <strong>Welcome</strong> screen where you enter your site's information.
The site <strong>Username</strong> and <strong>Password</strong> <em>should not</em> be the same as the username and password you used to create your WordPress database in MariaDB.
Rather, the username and password you enter here are for WordPress users; i.e., those who will add content and manage the website.
Make sure you save your password here!!</p>
<p><strong>Two things to note:</strong></p>
<p>We have not setup <strong>email</strong> on our servers.
It's quite complicated to setup an email server correctly and securely, but it wouldn't work well without having a domain name setup anyway.
So know that you probably should enter an email when setting up the user account, but it won't work.</p>
<p>Second, when visiting your site, your browser may throw an authenticaion error.
Ensure the URL starts with <code>http</code> and not <code>https</code> because some browsers try to force <code>https</code> connections.
We have not set up SSL certificates for secure connections, which would require a domain name and further configuration.
Note that <code>http</code> connections are less secure and
if you want to eventually set up a live site, you could acquire a domain name for your server and configure SSL using tools like
<a href="https://letsencrypt.org/">Let's Encrypt</a>.</p>
<h2 id="conclusion-23"><a class="header" href="#conclusion-23">Conclusion</a></h2>
<p>Congrats on setting up your WordPress library site.
Feel free to take a moment to modify your site's design or to add content.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="conclusion-24"><a class="header" href="#conclusion-24">Conclusion</a></h1>
<p>I consider this book to be a live document.
Perhaps, then, this is version 0.8, or
something like that.
In any case,
it will be continually updated throughout the year but
probably more often before and during the fall semesters
when I teach my Linux Systems Administration course.</p>
<p>This book in no way is meant to provide a comprehensive
overview of systems administration nor of Linux.
It's meant to act as a starting point for those
interested in systems administration, and
it's meant to get students,
many of whom grew up using only graphical user interfaces,
familiar with command line environments.
In that respect,
this book, and the course that I teach,
is aimed at empowering students to know their technology
and become comfortable and more experienced with it,
especially the behind the scenes stuff.
That said, I'm proud that some of my students
have gone on to become systems administrators.
Other courses in our program and their own work and internships
have probabably contributed more to that motivation, but
I know that this course has been a factor.</p>
<p>If you're not a student in our program but
have stumbled upon this book,
I hope it's helpful to you, too.
This is, in fact, why I've made it available on my website and
not simply dropped it in my course shell.</p>
<p>C. Sean Burns, PhD<br />
August 13, 2022</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
